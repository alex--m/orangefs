/* 
 * (C) 2003 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

#include <string.h>
#include <assert.h>

#include "client-state-machine.h"
#include "state-machine-fns.h"
#include "pvfs2-debug.h"
#include "job.h"
#include "gossip.h"
#include "str-utils.h"
#include "pvfs2-mgmt.h"

#include "pinode-helper.h"
#include "pint-dcache.h"
#include "pint-servreq.h"
#include "pint-bucket.h"
#include "PINT-reqproto-encode.h"

extern job_context_id pint_client_sm_context;

/* state function prototypes */
static int mgmt_perf_mon_list_setup_msgpair(PINT_client_sm *sm_p,
					job_status_s *js_p);
static int mgmt_perf_mon_list_cleanup(PINT_client_sm *sm_p,
			  job_status_s *js_p);
static int perf_mon_list_comp_fn(void* v_p, struct PVFS_server_resp* resp_p,
    int i);

%%

machine pvfs2_client_mgmt_perf_mon_list_sm(
    setup_msgpair,
    xfer_msgpair,
    cleanup)
{

    state setup_msgpair {
	run mgmt_perf_mon_list_setup_msgpair;
	success => xfer_msgpair;
	default => cleanup;
    }

    state xfer_msgpair {
	jump pvfs2_client_msgpairarray_sm;
	default => cleanup;
    }

    state cleanup {
	run mgmt_perf_mon_list_cleanup;
	default => setup_msgpair;
    }
}

%%

int PVFS_mgmt_perf_mon_list(
    PVFS_fs_id fs_id,
    PVFS_credentials credentials,
    struct PVFS_mgmt_perf_stat** perf_matrix,
    uint64_t* end_time_ms_array,
    PVFS_id_gen_t* addr_array,
    uint32_t* next_id_array,
    int server_count,
    int history_count)
{
    int ret;
    PINT_client_sm *sm_p;
    PVFS_error error;

    gossip_debug(CLIENT_DEBUG, "PVFS_mgmt_perf_mon_list entered\n");

    if(server_count < 1 || history_count < 1 || !perf_matrix || !addr_array 
	|| !end_time_ms_array)
    {
	return(-PVFS_EINVAL);
    }

    /* build PINT_client_sm structure */
    /* TODO: KEEP A CACHE OF THESE AROUND SO WE'RE NOT ALWAYS MALLOC'ING? */
    sm_p = (PINT_client_sm *) malloc(sizeof(*sm_p));
    if (sm_p == NULL) return -PVFS_ENOMEM;

    memset(sm_p, 0, sizeof(*sm_p));

    sm_p->cred_p = &credentials;
    sm_p->u.perf_mon_list.fs_id = fs_id;
    sm_p->u.perf_mon_list.perf_matrix = perf_matrix;
    sm_p->u.perf_mon_list.server_count = server_count;
    sm_p->u.perf_mon_list.history_count = history_count;
    sm_p->u.perf_mon_list.addr_array = addr_array;
    sm_p->u.perf_mon_list.next_id_array = next_id_array;
    sm_p->u.perf_mon_list.end_time_ms_array = end_time_ms_array;

    gossip_debug(CLIENT_DEBUG,
		 "PVFS_mgmt_perf_mon_list calling PINT_client_state_machine_post()\n");

    /* do something to kick off processing */
    ret = PINT_client_state_machine_post(sm_p, PVFS_MGMT_PERF_MON_LIST);
    if(ret < 0)
    {
	/* this should not fail under normal conditions */
	assert(0);
	gossip_lerr("Error: PINT_client_state_machine_post() failure.\n");
	return(ret);
    }

    /* while !done call progress function */
    while (!sm_p->op_complete && ret == 0) {
	gossip_debug(CLIENT_DEBUG,
		     "PVFS_mgmt_perf_mon_list calling PINT_client_state_machine_test()\n");
	ret = PINT_client_state_machine_test();
    }
    if(ret < 0)
    {
	gossip_lerr("Error: PINT_client_state_machine_test() failure.\n");
	return(ret);
    }

    gossip_debug(CLIENT_DEBUG, "PVFS_mgmt_perf_mon_list completed\n");

    /* save our return value */
    error = sm_p->error_code;

    /* clean up after ourselves */
    free(sm_p);
    return error;
}

static int mgmt_perf_mon_list_setup_msgpair(PINT_client_sm *sm_p,
					job_status_s *js_p)
{
    int i;
    PINT_client_sm_msgpair_state *msg_p;

    gossip_debug(CLIENT_DEBUG, "perf_mon_list state: mgmt_perf_mon_list_setup_msgpair\n");

    /* allocate memory for msgpair array */
    sm_p->msgarray_count = sm_p->u.perf_mon_list.server_count;
    sm_p->msgarray = (PINT_client_sm_msgpair_state *)
    malloc((sm_p->msgarray_count)*sizeof(PINT_client_sm_msgpair_state));
    if(!sm_p->msgarray)
    {
	js_p->error_code = -PVFS_ENOMEM;
	return(1);
    }

    /* setup msgpair array */
    for(i=0; i<sm_p->msgarray_count; i++)
    {
	msg_p = &sm_p->msgarray[i];

	PINT_SERVREQ_MGMT_PERF_MON_FILL(msg_p->req,
	    *sm_p->cred_p,
	    sm_p->u.perf_mon_list.next_id_array[i],
	    sm_p->u.perf_mon_list.history_count);

	msg_p->fs_id = sm_p->u.perf_mon_list.fs_id;
	msg_p->handle = PVFS_HANDLE_NULL;
	msg_p->comp_fn = perf_mon_list_comp_fn;
	msg_p->svr_addr = sm_p->u.perf_mon_list.addr_array[i];
    }

    /* immediate return: next state jumps to msgpairarray machine */
    js_p->error_code = 0;
    return(1);
}

static int mgmt_perf_mon_list_cleanup(PINT_client_sm *sm_p,
			  job_status_s *js_p)
{
    if(sm_p->msgarray)
	free(sm_p->msgarray);

    sm_p->error_code = js_p->error_code;
    sm_p->op_complete = 1;

    return(0);
}

static int perf_mon_list_comp_fn(void* v_p, struct PVFS_server_resp* resp_p,
    int i)
{
    int j = 0;
    PINT_client_sm* sm_p = (PINT_client_sm*)v_p;

    /* if this particular request was successful, then store the 
     * performance information in an array to be returned to caller
     */
    if(sm_p->msgarray[i].op_status == 0)
    {
	sm_p->u.perf_mon_list.next_id_array[i] = 
	    resp_p->u.mgmt_perf_mon.suggested_next_id;
	sm_p->u.perf_mon_list.end_time_ms_array[i] =
	    resp_p->u.mgmt_perf_mon.end_time_ms;
	memcpy(sm_p->u.perf_mon_list.perf_matrix[i],
	    resp_p->u.mgmt_perf_mon.perf_array,
	    resp_p->u.mgmt_perf_mon.perf_array_count
		*sizeof(struct PVFS_mgmt_perf_stat));
    }
 
    /* if this is the last response, check all of the status values and 
     * return error code if any requests failed 
     */
    if(i == (sm_p->msgarray_count -1))
    {
	for(j=0; j<sm_p->msgarray_count; j++)
	{
	    if(sm_p->msgarray[j].op_status != 0)
	    {
		return(sm_p->msgarray[j].op_status);
	    }
	}
    }
   
    return(0);
}

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 noexpandtab
 */
