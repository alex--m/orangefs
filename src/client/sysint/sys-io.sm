/* 
 * (C) 2003 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

#include <string.h>
#include <assert.h>

#include "client-state-machine.h"
#include "state-machine-fns.h"
#include "pvfs2-types-debug.h"
#include "pvfs2-debug.h"
#include "job.h"
#include "gossip.h"
#include "str-utils.h"

#include "pinode-helper.h"
#include "pint-dcache.h"
#include "pint-servreq.h"
#include "pint-bucket.h"
#include "pcache.h"
#include "PINT-reqproto-encode.h"

extern job_context_id pint_client_sm_context;

enum {
    IO_NO_DATA = 1,
    IO_DATAFILE_TRANSFERS_COMPLETE = 2
};

/* state function prototypes */
static int io_object_getattr_setup_msgpair(PINT_client_sm *sm_p,
					   job_status_s *js_p);
static int io_object_getattr_failure(PINT_client_sm *sm_p,
				     job_status_s *js_p);
static int io_datafile_setup_msgpairs(PINT_client_sm *sm_p,
				      job_status_s *js_p);
static int io_datafile_post_msgpairs(PINT_client_sm *sm_p,
				     job_status_s *js_p);
static int io_datafile_complete_msgpairs(PINT_client_sm *sm_p,
					 job_status_s *js_p);
static int io_cleanup(PINT_client_sm *sm_p,
		      job_status_s *js_p);

/* completion function prototypes */
static int io_object_getattr_comp_fn(void *v_p,
				     struct PVFS_server_resp *resp_p,
				     int index);

/* other helper functions */
static int io_find_target_datafiles(PVFS_Request io_req,
				    PVFS_offset io_req_offset, 
				    PVFS_Dist *dist_p,
				    PVFS_handle *input_handle_array,
				    int input_handle_count,
				    PVFS_handle *output_handle_array, 
				    int *handle_count_out_p);

%%

machine pvfs2_client_io_sm(object_getattr_setup_msgpair,
			   object_getattr_xfer_msgpair,
			   object_getattr_failure,
			   datafile_setup_msgpairs,
			   datafile_post_msgpairs,
			   datafile_complete_msgpairs,
			   cleanup)
{
    state object_getattr_setup_msgpair {
	run io_object_getattr_setup_msgpair;
	default => object_getattr_xfer_msgpair;
    }
    state object_getattr_xfer_msgpair {
	jump pvfs2_client_getattr_pcache_sm;
	success => datafile_setup_msgpairs;
	default => object_getattr_failure;
    }
    state object_getattr_failure {
	run io_object_getattr_failure;
	default => cleanup;
    }

    state datafile_setup_msgpairs {
	run io_datafile_setup_msgpairs;
	default => datafile_post_msgpairs;
    }
    state datafile_post_msgpairs {
	run io_datafile_post_msgpairs;
	success => datafile_complete_msgpairs;
	default => cleanup;
    }
    state datafile_complete_msgpairs {
	run io_datafile_complete_msgpairs;
	success => datafile_complete_msgpairs;
	IO_DATAFILE_TRANSFERS_COMPLETE => cleanup;
	default => datafile_complete_msgpairs;
    }

    state cleanup {
	run io_cleanup;
	default => cleanup;
    }
}

%%

/* PVFS_sys_io()
 */
int PVFS_sys_io2(PVFS_pinode_reference pinode_ref,
		 PVFS_Request          io_req,
		 PVFS_offset           io_req_offset,
		 void                 *buffer,
		 PVFS_size             buffer_size,
		 PVFS_credentials      credentials,
		 PVFS_sysresp_io      *resp_p,
		 enum PVFS_io_type     io_type)
{
    int ret;
    PINT_client_sm *sm_p;
    PVFS_error error;

    if (resp_p == NULL) {
	gossip_lerr("NULL resp pointer\n");
	return -PVFS_EINVAL;
    }

    if (io_type != PVFS_IO_READ && io_type != PVFS_IO_WRITE) {
	return -PVFS_EINVAL;
    }

    /* allocate and build PINT_client_sm structure */
    sm_p = (PINT_client_sm *) malloc(sizeof(*sm_p));
    if (sm_p == NULL) return -PVFS_ENOMEM;

    memset(sm_p, 0, sizeof(*sm_p));

    sm_p->cred_p = &credentials;
    sm_p->u.io.object_ref    = pinode_ref;
    sm_p->u.io.io_type       = io_type;
    sm_p->u.io.io_req        = io_req;
    sm_p->u.io.io_req_offset = io_req_offset;
    sm_p->u.io.buffer        = buffer;
    sm_p->u.io.buffer_size   = buffer_size;
    sm_p->u.io.io_resp_p     = resp_p;

    ret = PINT_client_state_machine_post(sm_p, PVFS_SYS_IO);
    assert(ret == 0);

    while (!sm_p->op_complete && ret == 0) {
	ret = PINT_client_state_machine_test();
    }
    assert(ret == 0);

    error = sm_p->error_code;

    free(sm_p);

    return error;
}

/*******************************************************************/

static int io_object_getattr_setup_msgpair(PINT_client_sm *sm_p,
					   job_status_s *js_p)
{
    uint32_t attrmask;

    gossip_debug(CLIENT_DEBUG,
		 "(%p) io state: io_object_getattr_setup_msgpair\n",
		 sm_p);

    /* we need datafile handles, distribution, and common attribs */
    attrmask = (PVFS_ATTR_META_DFILES |
		PVFS_ATTR_META_DIST |
		PVFS_ATTR_COMMON_ALL);

    PINT_SERVREQ_GETATTR_FILL(sm_p->msgpair.req,
			      *sm_p->cred_p,
			      sm_p->u.io.object_ref.fs_id,
			      sm_p->u.io.object_ref.handle,
			      attrmask);

    /* fill in msgpair structure components */
    sm_p->msgpair.fs_id = sm_p->u.io.object_ref.fs_id;
    sm_p->msgpair.handle = sm_p->u.io.object_ref.handle;
    sm_p->msgpair.comp_fn = io_object_getattr_comp_fn;

    /* drop through and jump to getattr_pcache state machine */
    return 1;
}

/* io_object_getattr_comp_fn()
 *
 * Called to copy data from getattr response into the io-specific portion of
 * the PINT_client_sm structure, so we can use the data after returning to
 * this state machine.
 *
 * Return value is returned in job status, so it affects the resulting state
 * coming back from the nested state machine.
 *
 * Part of me would like to not have to replicate this code in every instance
 * that we want to grab this data; this particular function was ripped from
 * the getattr state machine and then modified.  However, I'm not sure if
 * there is a good way to generalize this.
 *
 * Q: MAYBE WE SHOULD JUST PUT A COMMON PVFS_object_attr IN THE PINT_client_sm
 *    STRUCTURE AND USE THAT IN ALL CASES?  IT WOULD MAKE FOR AN UGLIER
 *    STRUCTURE BUT OVERALL CLEANER CODE I THINK. -- RobR
 *
 *    ACTUALLY, IF WE GOT THE PINODE CACHE STUFF WORKING WE COULD JUST RETURN
 *    A PINODE REFERENCE AND BE DONE WITH IT; THAT WOULD PROBABLY BE BEST.
 *
 * Returns 0 for metafiles, error for all the other types.
 */
static int io_object_getattr_comp_fn(void *v_p,
				     struct PVFS_server_resp *resp_p,
				     int index)
{
    PVFS_object_attr *r_attr_p;

    /* this is a little kludge to get around some struct definition
     * issues in the headers.  maybe fix later?
     */
    PINT_client_sm *sm_p = (PINT_client_sm *) v_p;
    
    /* sanity checks: this is a getattr response and has a valid
     * type field
     */
    assert(resp_p->op == PVFS_SERV_GETATTR);
    assert(resp_p->u.getattr.attr.mask & PVFS_ATTR_COMMON_TYPE);

    /* if we get an error, just return immediately, don't try to
     * actually fill anything in.
     */
    if (resp_p->status != 0) {
	return resp_p->status;
    }

    if (resp_p->u.getattr.attr.objtype != PVFS_TYPE_METAFILE) {
	/* invalid type - we only do I/O on files */
	return -PVFS_EINVAL;
    }

    r_attr_p = &resp_p->u.getattr.attr;

    /* sanity checks */
    assert(r_attr_p->mask & PVFS_ATTR_META_DIST);
    assert(r_attr_p->u.meta.dist_size > 0);
		
    gossip_debug(CLIENT_DEBUG,
		 "io_object_getattr_comp_fn: copying %d bytes of dist.\n",
		 r_attr_p->u.meta.dist_size);

    /* here we make a copy of the distribution information.
     *
     * KLUDGE: there is no copy function for distributions
     * right now, so we do this nasty thing.
     */

    sm_p->u.io.dist_p = (PVFS_Dist *) malloc(r_attr_p->u.meta.dist_size);
    if (sm_p->u.io.dist_p == NULL) {
	assert(0);
	return -PVFS_ENOMEM;
    }

    /* this encodes the previously decoded distribution into
     * our new space.
     */
    PINT_Dist_encode(sm_p->u.io.dist_p, r_attr_p->u.meta.dist);

    /* this does an in-place decoding of the distribution.  now
     * we have a decoded version where we want it.
     *
     * NOTE: we need to free this later.
     */
    PINT_Dist_decode(sm_p->u.io.dist_p, NULL);

    /* save the size too */
    sm_p->u.io.dist_size = r_attr_p->u.meta.dist_size;

    /* sanity checks */
    assert(r_attr_p->mask & PVFS_ATTR_META_DFILES);
    assert(r_attr_p->u.meta.dfile_count > 0);

    gossip_debug(CLIENT_DEBUG,
		 "io_object_getattr_comp_fn: %d datafiles.\n",
		 r_attr_p->u.meta.dfile_count);
		
    /* save the datafile handles prior to freeing up the
     * buffers we used for messages.  we could keep them around
     * i suppose, but we're not going to do that for now.  later
     * it is likely that this stuff will be stuck in the pcache
     * anyway, so we'll be able to just reference it from there.
     */
    sm_p->u.io.datafile_handles =
	(PVFS_handle *) malloc(r_attr_p->u.meta.dfile_count * sizeof(PVFS_handle));
    if (sm_p->u.io.datafile_handles == NULL) {
	assert(0);
    }
    sm_p->u.io.datafile_count = r_attr_p->u.meta.dfile_count;
    memcpy(sm_p->u.io.datafile_handles,
	   r_attr_p->u.meta.dfile_array,
	   r_attr_p->u.meta.dfile_count * sizeof(PVFS_handle));

    return 0;
} /* io_object_getattr_comp_fn */

/* io_datafile_setup_io()
 *
 * Sets up msgpairs to send I/O requests to servers holding datafiles
 * that (might) have data for us (unless we hit EOF).
 *
 * This function swaps the original datafile_handles array for a new
 * array that just has datafiles that we think will have our data.  It
 * updates datafile_count appropriately as well.
 *
 * We use sm_p->msgarray for this purpose.
 *
 * NOTE: we could combine this with the post_msgpairs state, but this one
 *       has gotten pretty big already, so let's not.
 *
 * TODO: MERGE A BUNCH OF THESE MALLOCS INTO LARGER SINGLE MALLOC TO SAVE
 *       TIME AND COMPLEXITY IN ERROR CASE.
 */
static int io_datafile_setup_msgpairs(PINT_client_sm *sm_p,
				      job_status_s *js_p)
{
    int i, ret;
    int target_datafile_count;
    PVFS_handle *target_datafile_array;

    struct PINT_client_io_sm *iosm_p = &sm_p->u.io; /* convenience */

    gossip_debug(CLIENT_DEBUG,
		 "(%p) io state: io_datafile_setup_io\n",
		 sm_p);

    /* NOTE: i have no idea what this function does.  presumably it has
     * some important side-effects, since it doesn't have an output
     * parameter.
     *
     * TODO: make the Dist interface make sense.
     */
    ret = PINT_Dist_lookup(iosm_p->dist_p);
    if (ret != 0) {
	assert(0);
    }

    target_datafile_array =
	(PVFS_handle *) malloc(iosm_p->datafile_count * sizeof(PVFS_handle));
    if (target_datafile_array == NULL) {
	assert(0);
    }

    ret = io_find_target_datafiles(iosm_p->io_req,
				   iosm_p->io_req_offset,
				   iosm_p->dist_p,
				   iosm_p->datafile_handles,
				   iosm_p->datafile_count,
				   target_datafile_array,
				   &target_datafile_count);
    if (ret != 0) {
	assert(0);
    }

    if (target_datafile_count == 0) {
	/* no data?  ok... */
	/* TODO: catch this earlier or something. */
	js_p->error_code = IO_NO_DATA;
	return 1;
    }

    gossip_debug(CLIENT_DEBUG,
		 "  datafile_setup_msgpairs: %d datafiles might have data\n",
		 target_datafile_count);

    /* set up space for msgarrray */
    sm_p->msgarray = (PINT_client_sm_msgpair_state *)
	malloc(target_datafile_count * sizeof(PINT_client_sm_msgpair_state));
    if (sm_p->msgarray == 0) {
	assert(0);
    }
    sm_p->msgarray_count = target_datafile_count;

    /* set up space for flows */
    iosm_p->flow_comp_ct = 0;

    /* flow descriptor array */
    iosm_p->flow_p_array = (flow_descriptor **)
	malloc(target_datafile_count * sizeof(flow_descriptor *));
    if (iosm_p->flow_p_array == NULL) {
	assert(0);
    }
    /* flow id array */
    iosm_p->flow_id_array = (job_id_t *)
	malloc(target_datafile_count * sizeof(job_id_t));
    if (iosm_p->flow_id_array == NULL) {
	assert(0);
    }
    /* flow status array */
    iosm_p->flow_status_array = (job_status_s *)
	malloc(target_datafile_count * sizeof(job_status_s));
    if (iosm_p->flow_status_array == NULL) {
	assert(0);
    }
    /* file data array */
    iosm_p->file_data_array = (PINT_Request_file_data *)
	malloc(target_datafile_count * sizeof(PINT_Request_file_data));
    if (iosm_p->file_data_array == NULL) {
	assert(0);
    }

    /* session tag array */
    iosm_p->session_tag_array = (PVFS_msg_tag_t *)
	malloc(target_datafile_count * sizeof(PVFS_msg_tag_t));
    if (iosm_p->session_tag_array == NULL) {
	assert(0);
    }

    /* set up space for final ack if we're writing */
    if (iosm_p->io_type == PVFS_IO_WRITE) {
	/* write acknowledgement array */
	iosm_p->ack_comp_ct = 0;
	iosm_p->ackarray = (PINT_client_sm_recv_state *)
	    malloc(target_datafile_count * sizeof(PINT_client_sm_recv_state));
	if (iosm_p->ackarray == NULL) {
	    assert(0);
	}
    }

    /* fill in all the I/O requests */
    for (i=0; i < target_datafile_count; i++) {
	int orig_index;
	PINT_client_sm_msgpair_state *msg_p = &sm_p->msgarray[i];

	gossip_debug(CLIENT_DEBUG,
		     "  sending I/O request for 0x%08Lx\n",
		     target_datafile_array[i]);

	/* find the original index for the handle */
	for (orig_index = 0; orig_index < iosm_p->datafile_count; orig_index++)
	{
	    if (target_datafile_array[i] == iosm_p->datafile_handles[orig_index])
		break;
	}
	assert(orig_index < iosm_p->datafile_count); /* sanity check */

	/* fill in I/O request */
	PINT_SERVREQ_IO_FILL(msg_p->req,
			     *sm_p->cred_p,
			     iosm_p->object_ref.fs_id,
			     target_datafile_array[i],
			     iosm_p->io_type,
			     FLOWPROTO_ANY,
			     orig_index,
			     target_datafile_count,
			     iosm_p->dist_p,
			     iosm_p->io_req,
			     iosm_p->io_req_offset);

	/* fill in msgpair structure components */
	msg_p->fs_id   = iosm_p->object_ref.fs_id;
	msg_p->handle  = iosm_p->datafile_handles[i];
	msg_p->comp_fn = NULL;
    }

    /*
     * Swap the new list in for the old one, freeing the old list.
     */
    free(iosm_p->datafile_handles);
    iosm_p->datafile_handles = target_datafile_array;
    iosm_p->datafile_count   = target_datafile_count;
    
    return 1;
}

/* io_datafile_post_msgpairs()
 *
 * This is basically a copy of msgpairarray.c:msgpairarray_post().
 * We need to handle the rest of the process somewhat differently though,
 * so we're going to have our own versions here.
 *
 * We use the msgarray to keep up with the initial send/recv pairs.
 *
 */
static int io_datafile_post_msgpairs(PINT_client_sm *sm_p,
				     job_status_s *js_p)
{
    int ret, i;

    gossip_debug(CLIENT_DEBUG,
		 "io_datafile_post_msgpairs state: post (%d message(s))\n",
		 sm_p->msgarray_count);

    assert(sm_p->msgarray_count > 0); /* sanity check */

    /* we don't know what this is set to prior to this function,
     * so we reset it here.
     */
    js_p->error_code = 0;

    /* set number of operations that must complete.
     *
     * NOTE: we're using the comp_ct in the first msgarray
     * entry to keep up with the count for the entire array.
     */
    sm_p->msgarray[0].comp_ct = 2 * sm_p->msgarray_count;

    /* run through array of msgpairarray to kick off */
    for (i=0; i < sm_p->msgarray_count; i++) {
	PVFS_msg_tag_t session_tag;
	PINT_client_sm_msgpair_state *msg_p = &sm_p->msgarray[i];

	/* determine server address from fs_id/handle pair.
	 * this is needed prior to encoding.
	 */
	ret = PINT_bucket_map_to_server(&msg_p->svr_addr,
					msg_p->handle,
					msg_p->fs_id);
	if (ret != 0) {
	    gossip_lerr("bucket map to server failed; probably invalid svr_addr\n");
	    assert(ret < 0); /* return value range check */
	    assert(0); /* placeholder until we have real error handling */
	}

	/* encode request. fills in encoded_req.
	 */
	ret = PINT_encode(&msg_p->req,
			  PINT_ENCODE_REQ,
			  &msg_p->encoded_req,
			  msg_p->svr_addr,
			  PINT_CLIENT_ENC_TYPE);
	if (ret != 0) {
	    gossip_lerr("pint_encode failed\n");
	    assert(ret < 0); /* return value range check */
	    assert(0); /* placeholder until we have real error handling */
	}

	/* calculate maximum response message size and allocate space.
	 * fills in max_resp_sz, encoded_resp_p
	 */
	msg_p->max_resp_sz = PINT_encode_calc_max_size(PINT_ENCODE_RESP,
						       msg_p->req.op,
						       PINT_CLIENT_ENC_TYPE);
	msg_p->encoded_resp_p = BMI_memalloc(msg_p->svr_addr,
					     msg_p->max_resp_sz,
					     BMI_RECV);
	if (msg_p->encoded_resp_p == NULL) {
	    assert(0);
	}

	/* get session tag to associate with send and receive.
	 * session tag is kept in io part of client state machine
	 * structure for use in the flow and option final ack.
	 */
	session_tag = get_next_session_tag();
	sm_p->u.io.session_tag_array[i] = session_tag;

	/* post receive of response; job_id stored in recv_id */
	ret = job_bmi_recv(msg_p->svr_addr,
			   msg_p->encoded_resp_p,
			   msg_p->max_resp_sz,
			   session_tag,
			   BMI_PRE_ALLOC,
			   sm_p,
			   &msg_p->recv_status,
			   &msg_p->recv_id,
			   pint_client_sm_context);
	if (ret < 0) {
	    gossip_lerr("post of receive failed\n");
	    assert(0);
	}
	else if (ret == 1) {
	    /* it shouldn't be possible for the receive to complete before
	     * we send the request.
	     */
	    assert(0); /* sanity check */
	}
	assert(ret == 0); /* return value range check */

	/* post send of request; job_id stored in send_id */
	ret = job_bmi_send_list(msg_p->encoded_req.dest,
				msg_p->encoded_req.buffer_list,
				msg_p->encoded_req.size_list,
				msg_p->encoded_req.list_count,
				msg_p->encoded_req.total_size,
				session_tag,
				msg_p->encoded_req.buffer_type,
				1,
				sm_p,
				&msg_p->send_status,
				&msg_p->send_id,
				pint_client_sm_context);
	if (ret < 0) {
	    gossip_lerr("post of send failed\n");
	    assert(0);
	}
	else if (ret == 1) {
	    /* send completed immediately; decrement the completion counter */
	    gossip_debug(CLIENT_DEBUG,
			 "  io_datafile_post_msgpairs: send completed immediately.\n");

	    /* 0 is the valid "completed job id" value, according to Phil */
	    msg_p->send_id = 0;

	    /* TODO: CHECK THE STATUS!!! */
	    assert(msg_p->send_status.error_code == 0);

	    /* decrement our count, since send is already done.
	     *
	     * recall we're using the comp_ct in the first array
	     * element to keep up with our count for the entire
	     * array.
	     */
	    sm_p->msgarray[0].comp_ct--;
	}
	assert(ret == 0 || ret == 1); /* return value range check */
    }

    return 0;
}

/* io_datafile_complete_msgpairs()
 *
 * This started off as a copy of msgpairarray.c:msgpairarray_complete(),
 * but we need to post flow operations as the bmi operations complete,
 * so we have some additional work to do.
 *
 * TODO: THIS FUNCTION IS TOTAL MADNESS AT THIS POINT; BREAK IT UP OR
 *       SOMETHING FOR GOD'S SAKE!!!
 */
static int io_datafile_complete_msgpairs(PINT_client_sm *sm_p,
					 job_status_s *js_p)
{
    int i, ret;
    int matched_msgpair = 0, matched_flow = 0, matched_ack = 0, recv_match = -1;

    gossip_debug(CLIENT_DEBUG, "io state: datafile_complete\n");

    /* loads of sanity checks */
    assert(sm_p->msgarray_count == sm_p->u.io.datafile_count);
    assert(sm_p->msgarray[0].comp_ct >= 0);
    assert(sm_p->u.io.flow_comp_ct >= 0);
    assert(sm_p->u.io.ack_comp_ct >= 0);

    /* if there are outstanding msgpairs to complete, try to match
     * whatever completed with something in the msgpair array
     */
    if (sm_p->msgarray[0].comp_ct > 0) {
	for (i=0; i < sm_p->msgarray_count; i++) {
	    PINT_client_sm_msgpair_state *msg_p = &sm_p->msgarray[i];

	    if (msg_p->recv_id == js_p->id) {
		matched_msgpair = 1;
		recv_match = i; /* record *which* receive we matched */

		msg_p->recv_id     = 0;
		msg_p->recv_status = *js_p;
		assert(msg_p->recv_status.error_code <= 0); /* range check */
		break;
	    }
	    else if (msg_p->send_id == js_p->id) {
		matched_msgpair = 1;

		msg_p->send_id     = 0;
		msg_p->send_status = *js_p;
		assert(msg_p->send_status.error_code <= 0); /* range check */

		break;
	    }
	}
	if (matched_msgpair) {
	    /* decrement comp_ct until all operations have completed.
	     *
	     * recall we're using the comp_ct in the first array element...
	     */
	    sm_p->msgarray[0].comp_ct--;

	    if (sm_p->msgarray[0].comp_ct == 0) {
		gossip_debug(CLIENT_DEBUG,
			     "  all msgpairs complete.\n");
	    }
	}
    }

    if (matched_msgpair && recv_match == -1) {
	gossip_debug(CLIENT_DEBUG, "  matched send to %d; continuing.\n", i);

	/* matched a completed send; just return */
	return 0;
    }

    /* if we matched a receive, then we need to decode the receive,
     * post the appropriate flow, and possibly post the receive of an ack
     * BMI message (if a write operation).
     *
     * we use the same index into the various arrays in the io part of the
     * state machine state that we used for this receive job (recv_match).
     */
    if (recv_match != -1) {
	PINT_client_sm_msgpair_state *msg_p = &sm_p->msgarray[recv_match];
	struct PINT_decoded_msg decoded_resp; /* data about decoded resp */
	struct PVFS_server_resp *resp_p; /* response structure (decoded) */

	gossip_debug(CLIENT_DEBUG, "  matched response from %d.\n", i);

	ret = PINT_serv_decode_resp(msg_p->encoded_resp_p,
				    &decoded_resp,
				    &msg_p->svr_addr,
				    msg_p->recv_status.actual_size,
				    &resp_p);
	if (ret != 0) {
	    gossip_lerr("error: io_datafile_complete_msgpairs: decode error\n");
	    assert(ret < 0); /* return value range check */
	    assert(0); /* placeholder */
	}

	assert(resp_p->status <= 0); /* parameter range checking */
	msg_p->op_status = resp_p->status; /* save status value */

	/* note: we saved the recv_status up above (before decoding) */

	if (msg_p->recv_status.error_code != 0 || msg_p->op_status != 0)
	{
	    gossip_debug(CLIENT_DEBUG,
			 "  error related to response from %d; not submitting flow.\n",
			 recv_match);
	}
	else
	{
	    flow_descriptor *fl_p;
	    struct PINT_client_io_sm *iosm_p = &sm_p->u.io;

	    gossip_debug(CLIENT_DEBUG, "  building flow for %d.\n", recv_match);

	    /* allocate flow descriptor */
	    fl_p = sm_p->u.io.flow_p_array[recv_match] = PINT_flow_alloc();
	    if (fl_p == NULL) {
		assert(0);
	    }
	    /* fill in file_data structure */
	    /* TODO: MACRO TO FILL THIS IN? */
	    fl_p->file_data            = &iosm_p->file_data_array[recv_match];
	    fl_p->file_data->fsize     = resp_p->u.io.bstream_size;
	    fl_p->file_data->dist      = iosm_p->dist_p;
	    fl_p->file_data->iod_num   = recv_match;
	    fl_p->file_data->iod_count = iosm_p->datafile_count;

	    /* this is the file datatype */
	    /* TODO: RENAME? */
	    fl_p->io_req        = iosm_p->io_req;
	    fl_p->io_req_offset = iosm_p->io_req_offset;

	    gossip_debug(CLIENT_DEBUG,
			 "    bstream_size = %Ld, datafile_nr = %d, datafile_ct = %d, io_req_off = %Ld\n",
			 fl_p->file_data->fsize,
			 fl_p->file_data->iod_num,
			 fl_p->file_data->iod_count,
			 fl_p->io_req_offset);

	    /* this is the memory datatype */
	    fl_p->mem_req = NULL;

	    /* flags -- not currently used */
	    fl_p->flags = 0;

	    /* session tag, same as the one used in the send/recv */
	    fl_p->tag = iosm_p->session_tag_array[recv_match];

	    /* this user_ptr should be left alone */
	    fl_p->user_ptr = NULL;

	    /* TODO: SAVE THE FLOWPROTO SOMEWHERE? */
	    fl_p->type = FLOWPROTO_ANY;

	    if (iosm_p->io_type == PVFS_IO_READ) {
		/* Set up read-specific values
		 * - don't keep going past EOF
		 * - data is coming from BMI and going into memory
		 * - data is coming from the same server we got the recv from
		 */
		fl_p->file_data->extend_flag = 0;
		fl_p->src.endpoint_id   = BMI_ENDPOINT;
		fl_p->src.u.bmi.address = sm_p->msgarray[recv_match].svr_addr;
		fl_p->dest.endpoint_id  = MEM_ENDPOINT;
		fl_p->dest.u.mem.buffer = iosm_p->buffer;
		fl_p->dest.u.mem.size   = iosm_p->buffer_size;
	    }
	    else {
		assert (iosm_p->io_type == PVFS_IO_WRITE); /* sanity check */

		/* do allow writes to extend the file */
		fl_p->file_data->extend_flag = 1;
		fl_p->src.endpoint_id    = MEM_ENDPOINT;
		fl_p->src.u.mem.buffer   = iosm_p->buffer;
		fl_p->src.u.mem.size     = iosm_p->buffer_size;
		fl_p->dest.endpoint_id   = BMI_ENDPOINT;
		fl_p->dest.u.bmi.address = sm_p->msgarray[recv_match].svr_addr;
	    }

	    /* post the flow:
	     * - pass sm_p in as user pointer, so we get called again
	     * - have status stored in flow status array, if we complete immed.
	     * - save id in flow id array
	     * - use recv_match as index for all this
	     */
	    ret = job_flow(fl_p,
			   sm_p, /* user pointer */
			   &iosm_p->flow_status_array[recv_match],
			   &iosm_p->flow_id_array[recv_match],
			   pint_client_sm_context);
	    if (ret < 0) {
		gossip_lerr("post of flow failed.\n");
		assert(0);
	    }
	    else if (ret == 1) {
		/* flow completed immediately; i guess this is possible... */
		gossip_debug(CLIENT_DEBUG,
			     "  flow for %d completed immediately!\n",
			     recv_match);

		/* mark as completed */
		iosm_p->flow_id_array[recv_match] = 0;
			   
		assert(iosm_p->flow_status_array[recv_match].error_code == 0);
	    }
	    else {
		assert(ret == 0); /* return value range check */

		gossip_debug(CLIENT_DEBUG,
			     "  posted flow for %d.\n",
			     recv_match);

		/* record that we have a flow that still needs to complete */
		iosm_p->flow_comp_ct++;
	    }
	}
	return 0;
    }

    /* sanity check to ensure we caught all exits above */
    assert(matched_msgpair == 0);

    /* if we didn't match to a message pair, then we completed either
     * a flow or a write ack
     */

    gossip_debug(CLIENT_DEBUG, "  trying to match to a flow or ack.\n");

    for (i=0; i < sm_p->msgarray_count; i++) {
	if (sm_p->u.io.flow_id_array[i] == js_p->id) {
	    matched_flow = 1;
	    sm_p->u.io.flow_id_array[i]     = 0;
	    sm_p->u.io.flow_status_array[i] = *js_p;
	    sm_p->u.io.flow_comp_ct--;
	    gossip_debug(CLIENT_DEBUG,
			 "  matched completed flow for %d\n",
			 i);

	    assert(sm_p->u.io.flow_comp_ct >= 0); /* sanity check */

	    break;
	}
	else if (sm_p->u.io.io_type == PVFS_IO_WRITE &&
		 sm_p->u.io.ackarray[i].recv_id == js_p->id) {
	    matched_ack = 1;
	    sm_p->u.io.ackarray[i].recv_id     = 0;
	    sm_p->u.io.ackarray[i].recv_status = *js_p;
	    sm_p->u.io.ack_comp_ct--;
	    gossip_debug(CLIENT_DEBUG,
			 "  matched completed ack for %d\n",
			 i);

	    assert(sm_p->u.io.ack_comp_ct >= 0);

	    break;
	}
    }
    
    if (sm_p->u.io.flow_comp_ct == 0 &&
	sm_p->u.io.ack_comp_ct == 0 &&
	sm_p->msgarray[0].comp_ct == 0)
    {
	gossip_debug(CLIENT_DEBUG, "  all msgpairs, flows, ack completed.\n");

	/* quit returning to this state! */
	js_p->error_code = IO_DATAFILE_TRANSFERS_COMPLETE;
	return 1;
    }
    else {
	/* still something left to transfer */
	return 0;
    }
}

static int io_object_getattr_failure(PINT_client_sm *sm_p,
				     job_status_s *js_p)
{
    gossip_debug(CLIENT_DEBUG,
		 "(%p) io state: io_object_getattr_failure\n",
		 sm_p);
    assert(0);

    return 1;
}

static int io_cleanup(PINT_client_sm *sm_p,
		      job_status_s *js_p)
{
    gossip_debug(CLIENT_DEBUG,
		 "(%p) io state: cleanup\n",
		 sm_p);

    sm_p->op_complete = 1;

    return 0;
}

/********************************************************************/

/* io_find_target_datafiles()
 *
 * determines what subset of the datafiles actually contain data that we
 * are interested in for this request
 *
 * returns 0 on success, -pvfs_error on failure
 *
 * TODO: make this step more efficient
 *
 * NOTE: this was ripped out of io.c and then modified.
 */
static int io_find_target_datafiles(PVFS_Request io_req,
				    PVFS_offset io_req_offset, 
				    PVFS_Dist *dist_p,
				    PVFS_handle *input_handle_array,
				    int input_handle_count,
				    PVFS_handle *output_handle_array, 
				    int *handle_count_out_p)
{
    int i, ret;
    struct PINT_Request_state *req_state = NULL;
    PINT_Request_file_data tmp_file_data;
    PINT_Request_result tmp_result;

    /* initialize output handle count */
    *handle_count_out_p = 0;

    req_state = PINT_New_request_state(io_req);
    if(!req_state)
    {
	return -PVFS_ENOMEM;
    }

    for (i=0; i < input_handle_count; i++)
    {
	/* NOTE: we don't have to give an accurate file size here,
	 * as long as we set the extend flag to tell the I/O req
	 * processor to continue past eof if needed
	 */
	tmp_file_data.fsize = 0;  
	tmp_file_data.dist = dist_p;
	tmp_file_data.iod_num = i;
	tmp_file_data.iod_count = input_handle_count;
	tmp_file_data.extend_flag = 1;

	/* if a file datatype offset was specified, go ahead and skip ahead 
	 * before calculating
	 */
	if (io_req_offset)
	{
	    memset(&tmp_result, 0, sizeof(PINT_Request_result));
	    tmp_result.bytemax = io_req_offset;
	    tmp_result.segmax = INT_MAX;

	    /* PINT_Process_request() returns number of bytes processed */
	    ret = PINT_Process_request(req_state,
				       NULL,
				       &tmp_file_data,
				       &tmp_result,
				       PINT_CKSIZE_LOGICAL_SKIP);
	    if (ret < 0)
	    {
		PINT_Free_request_state(req_state);
		return ret;
	    }
	    if (PINT_REQUEST_STATE_OFFSET(req_state) == -1)
	    {
		/* no data here */
		continue;
	    }
	}

	memset(&tmp_result, 0, sizeof(PINT_Request_result));
	tmp_result.bytemax = 1;
	tmp_result.segmax = 1;

	/* PINT_Process_request() returns number of bytes processed */
	ret = PINT_Process_request(req_state,
				   NULL,
				   &tmp_file_data,
				   &tmp_result,
				   PINT_CKSIZE);
	if (ret < 0)
	{
	    PINT_Free_request_state(req_state);
	    return ret;
	}

	/* did we find that any data belongs to this handle? */
	if (tmp_result.bytes != 0)
	{
	    assert(tmp_result.bytes > 0); /* parameter range checking */

	    gossip_debug(CLIENT_DEBUG,
			 "io_find_target_dfiles: datafile %d might have some data.\n",
			 i);

	    output_handle_array[*handle_count_out_p] = input_handle_array[i]; 
	    (*handle_count_out_p)++;
	}
    }
    PINT_Free_request_state(req_state);

    return 0;
} /* io_find_target_datafiles */


/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 noexpandtab
 */
