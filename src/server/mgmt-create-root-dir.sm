/*
 * (C) 2010 Clemson University
 *
 * See COPYING in top-level directory.
 */

#include <assert.h>
#include <unistd.h>

#include "pvfs2-config.h"
#include "extent-utils.h"
#include "pint-cached-config.h" 
#include "pint-perf-counter.h"
#include "pint-util.h"
#include "pvfs2-attr.h"
#include "pvfs2-internal.h"
#include "pvfs2-req-proto.h"
#include "pvfs2-server.h"
#include "pvfs2-types.h"
#include "pvfs2-util.h"
#include "security-util.h"
#include "server-config.h"
#include "dist-dir-utils.h"
#include "sid.h"
#ifdef ENABLE_SECURITY_CERT
#include "cert-util.h"
#endif

/*****
mgmt_create_root_dir.sm:
1. allocate dirdata handles for root directory.
2. create lost+found directory under the root directory.
*****/

enum
{
    NO_REQ = 100,
};

static char *lost_and_found_string = "lost+found";
static int num_retries = 0;

static int mkdir_lost_found_comp_fn(
        void *v_p,
        struct PVFS_server_resp *resp_p,
        int index);
static int crdirent_lost_found_comp_fn(
        void *v_p,
        struct PVFS_server_resp *resp_p,
        int index);
static int delete_lost_found_handle_comp_fn(
        void *v_p,
        struct PVFS_server_resp *resp_p,
        int index);
static int tree_setattr_comp_fn(
    void *v_p, struct PVFS_server_resp *resp_p, int index);


%%

machine pvfs2_mgmt_create_root_sm
{
    state check_for_request
    {
        run mgmt_create_root_check_for_request;
        NO_REQ => create_dist_dir_struct; 
        default => cleanup_noreq;    
    }

    state create_dist_dir_struct
    {
        run mgmt_create_root_create_dist_dir_struct;
        success => request_remote_dirdata_dspace;
        default => cleanup_noreq;
    }

    state request_remote_dirdata_dspace
    {
        run mgmt_create_root_request_remote_dirdata_dspace;
        success => create_local_dirdata_dspace;
        default => retry_remote_dirdata_dspace;
    }

    state retry_remote_dirdata_dspace
    {
        run mgmt_create_root_dir_retry_remote_dirdata_dspace;
        default => request_remote_dirdata_dspace;
    }

    state create_local_dirdata_dspace
    {
        run mgmt_create_root_create_local_dirdata_dspace;
        success => fill_handles_dist_dir_struct;
        default => cleanup_noreq;
    }

    state fill_handles_dist_dir_struct
    {
        run mgmt_create_root_fill_handles_dist_dir_struct;
        default => remote_dirdata_keyval_setup_msgpair;
    }

    state remote_dirdata_keyval_setup_msgpair
    {
        run mgmt_create_root_remote_dirdata_keyval_setup_msgpair;
        success => remote_dirdata_keyval_xfer_msgpair;
        default => cleanup_noreq;
    }

    state remote_dirdata_keyval_xfer_msgpair
    {
        jump pvfs2_msgpairarray_sm;
        success => write_keyval_meta_handle;
        default => cleanup_noreq;
    }
    
    state write_keyval_meta_handle
    {
        run mgmt_create_root_write_keyval_meta_handle;
        success => write_keyval_dirdata_handle;
        default => cleanup_noreq;
    }

    state write_keyval_dirdata_handle
    {
        run mgmt_create_root_write_keyval_dirdata_handle;
        success => mkdir_lost_found_setup_msgpair;
        default => cleanup_noreq;
    }

    state mkdir_lost_found_setup_msgpair
    {
        run mgmt_create_root_mkdir_lost_found_setup_msgpair;
        success => mkdir_lost_found_msg_xfer_msgpair;
        default => cleanup_noreq;

    }

    state mkdir_lost_found_msg_xfer_msgpair
    {
        jump pvfs2_msgpairarray_sm;
        success => crdirent_lost_found_setup_msgpair;
        default => cleanup_noreq;
    }

    state crdirent_lost_found_setup_msgpair
    {
        run mgmt_create_root_crdirent_lost_found_setup_msgpair;
        success => crdirent_lost_found_xfer_msgpair;
        default => cleanup_noreq;
    }

    state crdirent_lost_found_xfer_msgpair
    {
        jump pvfs2_msgpairarray_sm;
        success => cleanup_noreq;
        default => delete_lost_found_handle_setup_msgpair;
    }

    state delete_lost_found_handle_setup_msgpair
    {
        run mgmt_create_root_delete_lost_found_handle_setup_msgpair;
        success => delete_lost_found_handle_xfer_msgpair;
        default => cleanup_noreq;
    }

    state delete_lost_found_handle_xfer_msgpair
    {
        jump pvfs2_msgpairarray_sm;
        default => cleanup_noreq;
    }

    state cleanup_noreq
    {
        run mgmt_create_root_cleanup_noreq;
        default => terminate;
    }
}

%%

/*
 * Function: mgmt_create_root_check_for_request
 * Params:   server_op *b,
 *           job_status_s *js_p
 *
 * Returns:  int
 *
 * Synopsis: Check if this state machine came about from a request or 
 *           from a noreq() state machine (on server startup).
 */
static PINT_sm_action mgmt_create_root_check_for_request( 
    struct PINT_smcb *smcb, 
    job_status_s *js_p)
{

    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    server_configuration_t *user_opts = get_server_config_struct();
#ifdef ENABLE_SECURITY_CERT
    int ret;
    X509 *xcert = NULL;
    PVFS_certificate *cert = NULL;
#endif

    assert(s_op);

    if( s_op->req == NULL )
    {
        js_p->error_code = NO_REQ;
    }
    else
    {
        gossip_debug(GOSSIP_SERVER_DEBUG, "mgmt_create_root_dir: can only be called noreq, not doing anything!!\n");
        js_p->error_code = 0;
    }

    /* Create credential that will be used for requests. */
    PINT_init_credential(&s_op->u.mgmt_create_root_dir.credential);
    s_op->u.mgmt_create_root_dir.credential.userid = 0;
    s_op->u.mgmt_create_root_dir.credential.num_groups = 1;
    s_op->u.mgmt_create_root_dir.credential.group_array =
        malloc(sizeof(PVFS_gid));
    s_op->u.mgmt_create_root_dir.credential.group_array[0] = 0;
    s_op->u.mgmt_create_root_dir.credential.issuer = 
        malloc(strlen(user_opts->server_alias) + 3);
    s_op->u.mgmt_create_root_dir.credential.issuer[0] = 'S';
    s_op->u.mgmt_create_root_dir.credential.issuer[1] = ':';
    strcpy(s_op->u.mgmt_create_root_dir.credential.issuer+2,
         user_opts->server_alias);
    s_op->u.mgmt_create_root_dir.credential.timeout =
        PINT_util_get_current_time() + user_opts->credential_timeout;

#ifdef ENABLE_SECURITY_CERT
    /* use CA certificate as cert in credential */
    ret = PINT_load_cert_from_file(user_opts->ca_file, &xcert);
    if (ret != 0)
    {
        gossip_err("mgmt_create_root_dir: could not load CA "
                     "certificate: %d\n", ret);

        js_p->error_code = -PVFS_EACCES;
        return SM_ACTION_COMPLETE;
    }

    ret = PINT_X509_to_cert(xcert, &cert);
    if (ret != 0)
    {
        PINT_security_error(__func__, ret);
        js_p->error_code = -PVFS_EACCES;
        X509_free(xcert);
        return SM_ACTION_COMPLETE;
    }

    ret = PINT_copy_cert(cert, 
                         &s_op->u.mgmt_create_root_dir.credential.certificate);
    if (ret != 0)
    {
        gossip_err("mgmt_create_root_dir: could not copy certificate\n");
        js_p->error_code = -PVFS_EACCES;
        PINT_cleanup_cert(cert);
        free(cert);
        X509_free(xcert);
        return SM_ACTION_COMPLETE;
    }

    PINT_cleanup_cert(cert);
    free(cert);
    X509_free(xcert);
#endif

    PINT_sign_credential(&s_op->u.mgmt_create_root_dir.credential);

    return SM_ACTION_COMPLETE;
}


/* init dist_dir_struct in s_op->attr.u.dir and 
 * s_op->u.mgmt_create_root_dir */
static PINT_sm_action mgmt_create_root_create_dist_dir_struct(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    server_configuration_s *user_opts = get_server_config_struct();
    PVFS_object_attr *attr = NULL;
    int num_total_dirdata_servers = 0;
    int num_total_dirdata_sids = 0;
    int num_initial_dirdata_servers = 0;
    int ret = -1;
    unsigned char *c = NULL;
    int i;

    js_p->error_code = 0;
    attr = (&s_op->attr);

    /* V3 - Does this still make sense?  Can we even get the total
     * number of meta servers? Maybe this should be total number of root
     * servers for this fs?  Do Root dirs need to have so many buckets -
     * are they ever holding that many entries?  Should this be a config
     * file parameter?
     * Also need to get the number of SIDs worked out - should be a
     * default for the FS times number of servers.
     */
    /* use total # of meta servers as the num_total_dirdata_servers */
    ret = PINT_cached_config_get_num_meta(s_op->target_fs_id,
                                            &num_total_dirdata_servers);
    if(ret < 0)
    {
        gossip_err("Error: failed to get number of metadata servers\n");
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    /* Honor max # of dirdata servers from config file */
    if (user_opts->distr_dir_servers_max < num_total_dirdata_servers)
    {
        num_total_dirdata_servers = user_opts->distr_dir_servers_max;
    }

    /* set num_dirdata_servers for pre-allocation of dirdata handles */
    s_op->u.mgmt_create_root_dir.num_dirdata_servers =
                                      num_total_dirdata_servers;

    /* for root dir, use all dirdata servers */
    num_initial_dirdata_servers = num_total_dirdata_servers;

    /* init meta handle dist_dir_struct */
    ret = PINT_init_dist_dir_state(&attr->u.dir.dist_dir_attr,
                                   &attr->u.dir.dist_dir_bitmap,
                                   num_total_dirdata_servers,
                                   num_total_dirdata_sids, /* V3 is this set */
                                   0,
                                   num_initial_dirdata_servers,
                                   100);

    assert(ret == 0);
    /* Need to set mask so we will free dist dir attrs when cleaning up. */
    attr->mask |= PVFS_ATTR_DISTDIR_ATTR;

    gossip_debug(GOSSIP_SERVER_DEBUG, 
            "mgmt-create-root-dir: Init dist-dir-attr for dir meta handle %s "
            "with tree_height=%d, dirdata_count=%d, bitmap_size=%d, "
            "split_size=%d, server_no=%d and branch_level=%d\n",
            PVFS_OID_str(&s_op->target_handle),
            attr->u.dir.dist_dir_attr.tree_height,
            attr->u.dir.dist_dir_attr.dirdata_count,
            attr->u.dir.dist_dir_attr.bitmap_size,
            attr->u.dir.dist_dir_attr.split_size,
            attr->u.dir.dist_dir_attr.server_no,
            attr->u.dir.dist_dir_attr.branch_level);

    /* gossip bitmap, may adjust later */
    gossip_debug(GOSSIP_SERVER_DEBUG,
            "mgmt-create-root-dir: Init dist_dir_bitmap as:\n");
    for (i = attr->u.dir.dist_dir_attr.bitmap_size - 1;
         i >= 0; i--)
    {
        c = (unsigned char *)(attr->u.dir.dist_dir_bitmap + i);
        gossip_debug(GOSSIP_SERVER_DEBUG,
                " i=%d : %02x %02x %02x %02x\n",
                i, c[3], c[2], c[1], c[0]);
    }
    gossip_debug(GOSSIP_SERVER_DEBUG, "\n");

    /* allocate dirdata handle space, similar to create.sm */
    attr->u.dir.dirdata_handles = malloc(
            sizeof(*attr->u.dir.dirdata_handles) *
            num_total_dirdata_servers);
    s_op->u.mgmt_create_root_dir.handle_array_local = malloc(
            sizeof(*s_op->u.mgmt_create_root_dir.handle_array_local) *
            num_total_dirdata_servers);
    s_op->u.mgmt_create_root_dir.handle_array_remote = malloc(
            sizeof(*s_op->u.mgmt_create_root_dir.handle_array_remote) *
            num_total_dirdata_servers);

    if (!attr->u.dir.dirdata_handles ||
        !s_op->u.mgmt_create_root_dir.handle_array_local ||
        !s_op->u.mgmt_create_root_dir.handle_array_remote )
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }

    /* dirdata on every meta server */
    s_op->u.mgmt_create_root_dir.handle_array_local_count = 1;
    s_op->u.mgmt_create_root_dir.handle_array_remote_count = 
            s_op->u.mgmt_create_root_dir.num_dirdata_servers - 1;

    gossip_debug(GOSSIP_SERVER_DEBUG, "creating %d local dirdata files\n", 
                 s_op->u.mgmt_create_root_dir.handle_array_local_count);
    gossip_debug(GOSSIP_SERVER_DEBUG, "creating %d remote dirdata files\n", 
                 s_op->u.mgmt_create_root_dir.handle_array_remote_count);

    return SM_ACTION_COMPLETE; 
}

/* Not sure if we need this for V3 - this is a retry during FS
 * creation written for V2.
 */
static PINT_sm_action mgmt_create_root_dir_retry_remote_dirdata_dspace(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    job_id_t tmp_id;

    if (++num_retries > 3)
    {
        gossip_err("Unable to create root directory."
                   " Please ensure that all configured servers are running."
                   " Will continue to retry...\n");
        num_retries = 0;
    }
    else
    {
        gossip_debug(GOSSIP_SERVER_DEBUG,
             "Unable to obtain remote handles for root directory.\n");
    }

    gossip_debug(GOSSIP_SERVER_DEBUG,
        "Sleeping for 30 seconds before retrying.\n");

    return(job_req_sched_post_timer(
        (30*1000),
        smcb,
        0,
        js_p,
        &tmp_id,
        server_job_context));
}

/*
static PINT_sm_action mgmt_create_root_dir_request_remote_dirdata_dspace(
        struct PINT_smcb *smcb, job_status_s *js_p)
============
*/

static PINT_sm_action mgmt_create_root_request_remote_dirdata_dspace(
                                                     struct PINT_smcb *smcb,
                                                     job_status_s *js_p)
{
/* V3 no longer pools or remote requests rewrite or remove */
/* we should probably just fill in the  array with OIDs and include a
 * list of SIDs as well
 */
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int i;
/* V3 remove with belwo section */
#if 0
    int ret = -1;
#endif

    if(s_op->u.mgmt_create_root_dir.handle_array_remote_count == 0)
    {
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }
    for (i = 0;
         i < s_op->u.mgmt_create_root_dir.handle_array_remote_count;
         i++)
    {
        /* create an OID for each remote dir entry bucket */
        PVFS_OID_gen(&s_op->u.mgmt_create_root_dir.handle_array_remote[i]);
        /* need to do SIDs here too probably - or maybe in their own
         * loop
         */
    }

#if 0
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;

    if(s_op->u.mgmt_create_root_dir.handle_array_remote_count == 0)
    {
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }

    ret = job_precreate_pool_get_handles(
        s_op->target_fs_id,
        s_op->u.mgmt_create_root_dir.handle_array_remote_count,
        PVFS_TYPE_DIRDATA,
        NULL, /* server string set to NULL for now */
        s_op->u.mgmt_create_root_dir.handle_array_remote,
        0,
        smcb,
        0,
        js_p,
        &j_id,
        server_job_context,
        NULL);

    return ret;
#endif

    return SM_ACTION_COMPLETE;

}

/*
static PINT_sm_action mgmt_create_root_dir_create_local_dirdata_dspace(
        struct PINT_smcb *smcb, job_status_s *js_p)
=======
*/
static PINT_sm_action mgmt_create_root_create_local_dirdata_dspace(
                                                     struct PINT_smcb *smcb,
                                                     job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PVFS_object_attr *attr GCC_UNUSED;
    int ret = -PVFS_ENOMEM;
    job_id_t tmp_id;
    PVFS_handle *handle_array = NULL;
/*
    server_configuration_s *user_opts = get_server_config_struct();
*/

    attr = (&s_op->attr);

    assert(s_op->u.mgmt_create_root_dir.num_dirdata_servers > 0);


    if(s_op->u.mgmt_create_root_dir.handle_array_local_count == 0)
    {
        /* no local work to do */
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }

/* 
    ret = PINT_config_get_meta_handle_extent_array(user_opts,
                                                   s_op->target_fs_id,
                                                   &extent_array);
    assert(ret == 0);
    assert(extent_array.extent_count > 0);

    gossip_debug(GOSSIP_SERVER_DEBUG, " local dirdata handle(s) will "
                 "be in starting hrange[0] %s-%s\n",
                 PVFS_OID_str(&extent_array.extent_array[0].first),
                 PVFS_OID_str(&extent_array.extent_array[0].last));
 */

    /* V3 assume this generates a handle as part of the job.
     * either we need to update trove to generate handles the right way
     * or just do them here in this code - not sure of the ramifications
     * based on cost of generating UUIDs
     */
    ret = job_trove_dspace_create_list(
                          s_op->target_fs_id,
                          handle_array, /* what is this vs next arg? */
                          s_op->u.mgmt_create_root_dir.handle_array_local,
                          s_op->u.mgmt_create_root_dir.handle_array_local_count,
                          PVFS_TYPE_DIRDATA, 
                          NULL,
                          TROVE_SYNC,
                          smcb,
                          0,
                          js_p,
                          &tmp_id,
                          server_job_context, 
                          NULL);

/* V3 remove
    free(extent_array.extent_array);
*/

    return(ret);
}

static PINT_sm_action mgmt_create_root_fill_handles_dist_dir_struct(
                                                        struct PINT_smcb *smcb,
                                                        job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PVFS_object_attr *attr;
    int i;

    attr = &s_op->attr;

    gossip_debug(
        GOSSIP_SERVER_DEBUG, "  local dirdata handle (%s)\n",
        PVFS_OID_str(&s_op->u.mgmt_create_root_dir.handle_array_local[0]));

    /* fill dirdata_handles array */
    attr->u.dir.dirdata_handles[0] =
                     s_op->u.mgmt_create_root_dir.handle_array_local[0];

    for(i = 0; i < s_op->u.mgmt_create_root_dir.num_dirdata_servers - 1; i++)
    {
        attr->u.dir.dirdata_handles[i + 1] =
                         s_op->u.mgmt_create_root_dir.handle_array_remote[i];
    }

    /* V3 add SID support here */

    gossip_debug(GOSSIP_SERVER_DEBUG, 
                 "\t mgmt-create-root-dir: dirdata handles "
                 "array of root directory %s.\n",
                 PVFS_OID_str(&s_op->target_handle));

    for(i = 0; i < s_op->u.mgmt_create_root_dir.num_dirdata_servers; i++)
    {
        gossip_debug(GOSSIP_SERVER_DEBUG, 
                     "\t\tdirdata server %d: %s.\n",
                     i, PVFS_OID_str(&attr->u.dir.dirdata_handles[i]));
    }

    return SM_ACTION_COMPLETE;
}

/* Seriously??? */
static PINT_sm_action mgmt_create_root_remote_dirdata_keyval_setup_msgpair(
                                   struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PINT_sm_msgpair_state *msg_p = NULL;
    PVFS_object_attr attr;
    int ret;

    gossip_debug(GOSSIP_SERVER_DEBUG, "s_op->attr.objtype = %d\n",
                 s_op->attr.objtype);

    /* set dirdata attr, set all the static component */
/*
    PINT_copy_object_attr(&attr, &s_op->attr);
*/
    memset(&attr, 0, sizeof(PVFS_object_attr));
    attr.owner = getuid();
    attr.group = getgid();
    attr.perms = 0777;
    attr.objtype = PVFS_TYPE_DIRDATA;
    PINT_dist_dir_attr_copyto(attr.u.dir.dist_dir_attr,
                              s_op->attr.u.dir.dist_dir_attr);
    attr.u.dir.dirdata_handles = s_op->attr.u.dir.dirdata_handles;
    attr.u.dir.dist_dir_bitmap = s_op->attr.u.dir.dist_dir_bitmap;
    attr.mask = PVFS_ATTR_COMMON_ALL;
    attr.mask |= PVFS_ATTR_DISTDIR_ATTR;

    gossip_debug(
        GOSSIP_SERVER_DEBUG,
        "  SENDING attrs: [owner = %d, group = %d\n\t"
        "perms = %o, type = %d, atime = %llu, mtime = %llu\n\t"
        "ctime = %llu ]\n",
        attr.owner, attr.group, attr.perms,
        attr.objtype, llu(attr.atime),
        llu(PINT_util_mkversion_time(attr.mtime)), llu(attr.ctime));


    PINT_msgpair_init(&s_op->msgarray_op);
    msg_p = &s_op->msgarray_op.msgpair;
    PINT_serv_init_msgarray_params(s_op, s_op->target_fs_id);

    ret = PINT_server_to_server_capability(
                                &s_op->u.mgmt_create_root_dir.capability,
                                s_op->target_fs_id,
                                0,
                                NULL);
    if (ret < 0)
    {
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    PINT_SERVREQ_TREE_SETATTR_FILL(msg_p->req,
                                   s_op->u.mgmt_create_root_dir.capability,
                                   s_op->u.mgmt_create_root_dir.credential,
                                   s_op->target_fs_id,
                                   PVFS_TYPE_DIRDATA,
                                   attr,
                                   0,    /* caller handle index */
                                   s_op->attr.u.dir.dist_dir_attr.dirdata_count,
                                   s_op->attr.u.dir.dirdata_handles,
                                   s_op->attr.u.dir.dist_dir_attr.sid_count,
                                   s_op->attr.u.dir.dirdata_sids,
                                   NULL);

    msg_p->msgclass = PVFS_IO_METADATA;
    msg_p->msgdir = PVFS_IO_READ;
    msg_p->fs_id = s_op->target_fs_id;
    msg_p->handle = s_op->attr.u.dir.dirdata_handles[0];
    msg_p->sid_count = s_op->attr.u.dir.dist_dir_attr.sid_count;
    msg_p->sid_index = 0;
    msg_p->sid_array = s_op->attr.u.dir.dirdata_sids;
    msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
    msg_p->comp_fn = tree_setattr_comp_fn;

    ret = PVFS_SID_get_addr(&msg_p->svr_addr, &msg_p->sid_array[0]);
    /* V3 */
#if 0
    ret = PINT_cached_config_map_to_server(&msg_p->svr_addr,
                                           msg_p->handle,
                                           msg_p->fs_id);
#endif

    /* V3 sid array needs checking */
    /* Is this going to multiple servers? */
    ret = PVFS_SID_get_addr(&msg_p->svr_addr, &msg_p->sid_array[0]);
    if (ret)
    {
        gossip_err("Failed to map dirdata server address\n");
        PINT_free_object_attr(&(msg_p->req).u.tree_setattr.attr);
        js_p->error_code = ret;
    }

    PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);
    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action mgmt_create_root_write_keyval_meta_handle(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PVFS_object_attr *attr;
    int ret = -1;
    job_id_t j_id;

    /* total 3 keyvals,
     * PVFS_DIST_DIR_ATTR, PVFS_DIRDATA_BITMAP, PVFS_DIRDATA_HANDLES */
    int keyval_count = 3;

    /* !!!! this is to set meta handle keyval,
     * use dist_dir_attr in s_op->attr 
     */
    attr = &s_op->attr;

    s_op->key_a = malloc(sizeof(PVFS_ds_keyval) * keyval_count);
    if(!s_op->key_a)
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }

    s_op->val_a = malloc(sizeof(PVFS_ds_keyval) * keyval_count);
    if(!s_op->val_a)
    {
        free(s_op->key_a);
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }
    memset(s_op->val_a, 0, sizeof(PVFS_ds_keyval) * keyval_count);

    s_op->key_a[0].buffer = Trove_Common_Keys[DIST_DIR_ATTR_KEY].key;
    s_op->key_a[0].buffer_sz = Trove_Common_Keys[DIST_DIR_ATTR_KEY].size;

    s_op->val_a[0].buffer = &attr->u.dir.dist_dir_attr;
    s_op->val_a[0].buffer_sz = sizeof(attr->u.dir.dist_dir_attr);

    s_op->key_a[1].buffer = Trove_Common_Keys[DIST_DIRDATA_BITMAP_KEY].key;
    s_op->key_a[1].buffer_sz = Trove_Common_Keys[DIST_DIRDATA_BITMAP_KEY].size;

    s_op->val_a[1].buffer_sz = attr->u.dir.dist_dir_attr.bitmap_size * 
                               sizeof(PVFS_dist_dir_bitmap_basetype);
    s_op->val_a[1].buffer = attr->u.dir.dist_dir_bitmap;

    s_op->key_a[2].buffer = Trove_Common_Keys[DIST_DIRDATA_HANDLES_KEY].key;
    s_op->key_a[2].buffer_sz = Trove_Common_Keys[DIST_DIRDATA_HANDLES_KEY].size;

    s_op->val_a[2].buffer = attr->u.dir.dirdata_handles;
    s_op->val_a[2].buffer_sz = attr->u.dir.dist_dir_attr.dirdata_count * 
                               sizeof(*attr->u.dir.dirdata_handles);

    gossip_debug(GOSSIP_SERVER_DEBUG, 
            "  writing dist-dir-struct keyvals for meta handle: %s "
            "\t with server_no=%d and branch_level=%d \n", 
            PVFS_OID_str(&s_op->target_handle),
            attr->u.dir.dist_dir_attr.server_no,
            attr->u.dir.dist_dir_attr.branch_level);


    ret = job_trove_keyval_write_list(s_op->target_fs_id,
                                      s_op->target_handle, /* meta handle */
                                      s_op->key_a,
                                      s_op->val_a,
                                      keyval_count,
                                      TROVE_SYNC,
                                      NULL,
                                      smcb,
                                      0,
                                      js_p,
                                      &j_id,
                                      server_job_context,
                                      NULL);

    return ret;
}

static PINT_sm_action mgmt_create_root_write_keyval_dirdata_handle(
                                                        struct PINT_smcb *smcb,
                                                        job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PVFS_object_attr *attr;
    int ret = -1;
    job_id_t j_id;
    int keyval_count = 3;

    attr = &s_op->attr;

    gossip_debug(GOSSIP_SERVER_DEBUG, 
            "  writing dist-dir-struct keyvals for dirdata handle: %s "
            "\t with server_no=%d and branch_level=%d \n", 
            PVFS_OID_str(&s_op->attr.u.dir.dirdata_handles[0]),
            attr->u.dir.dist_dir_attr.server_no,
            attr->u.dir.dist_dir_attr.branch_level);


    ret = job_trove_keyval_write_list(s_op->target_fs_id,
                                      /* dirdata handle */
                                      s_op->attr.u.dir.dirdata_handles[0],
                                      s_op->key_a,
                                      s_op->val_a,
                                      keyval_count,
                                      TROVE_SYNC,
                                      NULL,
                                      smcb,
                                      0,
                                      js_p,
                                      &j_id,
                                      server_job_context,
                                      NULL);

    return ret;
}

static PINT_sm_action mgmt_create_root_mkdir_lost_found_setup_msgpair(
                                                         struct PINT_smcb *smcb,
                                                         job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -PVFS_EINVAL;
/* V3 - remove me*/
#if 0
    PVFS_handle_extent_array meta_handle_extent_array;
#endif
    PINT_sm_msgpair_state *msg_p = NULL;
    PVFS_sys_attr sys_attr;
    PVFS_sys_layout layout;

    js_p->error_code = 0;

    memset(&sys_attr, 0, sizeof(sys_attr));
    sys_attr.owner = getuid();
    sys_attr.group = getgid();
    sys_attr.perms = 0777;
    sys_attr.mask = (PVFS_ATTR_SYS_ALL_SETABLE);
    sys_attr.objtype = PVFS_TYPE_DIRECTORY;

    memset(&layout, 0, sizeof(layout));
    layout.algorithm = PVFS_SYS_LAYOUT_ROUND_ROBIN;

    gossip_debug(GOSSIP_SERVER_DEBUG,
                 " mgmt_create_root_dir: posting mkdir "
                 "req for lost+found dir.\n ");

    PINT_msgpair_init(&s_op->msgarray_op);
    msg_p = &s_op->msgarray_op.msgpair;

/* V3 WBL - need to rework this is all of the OIDs and SIDs for
 * the dir are allocated via the SID cache
 */
#if 0
    ret = PINT_cached_config_get_next_meta(s_op->target_fs_id,
                                           &msg_p->svr_addr,
                                           &meta_handle_extent_array);
#endif

    if (ret)
    {
        gossip_err("Failed to map meta server address\n");
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    PINT_SERVREQ_MKDIR_FILL(msg_p->req,
                            s_op->u.mgmt_create_root_dir.capability,
                            s_op->u.mgmt_create_root_dir.credential,
                            s_op->target_fs_id,
                            PVFS_HANDLE_NULL, /* handle */
                            PVFS_HANDLE_NULL, /* parent */
                            PVFS_SID_NULL, /* parent sid */
                            sys_attr,
                            s_op->attr.u.dir.dist_dir_attr.dirdata_count,
                            s_op->attr.u.dir.dist_dir_attr.dirdata_count,
                            s_op->attr.u.dir.dist_dir_attr.split_size,
                            layout,
                            NULL);

    msg_p->fs_id = s_op->target_fs_id;
/* V3 - remove me */
#if 0
    msg_p->handle = meta_handle_extent_array.extent_array[0].first;
#endif 
    msg_p->retry_flag = PVFS_MSGPAIR_NO_RETRY;
    msg_p->comp_fn = mkdir_lost_found_comp_fn;

    PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);
    return SM_ACTION_COMPLETE;
}

static int tree_setattr_comp_fn(void *v_p,
                                struct PVFS_server_resp *resp_p,
                                int index)
{
    PINT_smcb *smcb = v_p;
    PINT_sm_msgarray_op *mop = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PINT_sm_msgpair_state *msg_p = &mop->msgpair;;

    assert(msg_p->req.op == PVFS_SERV_TREE_SETATTR);
    PINT_free_object_attr(&(msg_p->req).u.tree_setattr.attr);
    return 0;
}

static int mkdir_lost_found_comp_fn(void *v_p,
                                        struct PVFS_server_resp *resp_p,
                                        int index)
{
    PINT_smcb *smcb = v_p;
    PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_MSGPAIR_PARENT_SM);
    
    gossip_debug(GOSSIP_SERVER_DEBUG, "mkdir_lost_found_comp_fn\n");

    assert(resp_p->op == PVFS_SERV_MKDIR);

    if (resp_p->status != 0)
    {
        return resp_p->status;
    }

    /* otherwise, just stash the newly created meta handle */
    s_op->u.mgmt_create_root_dir.lost_and_found_handle = resp_p->u.mkdir.handle;

    gossip_debug(
        GOSSIP_SERVER_DEBUG,
        "*** Got newly created dir handle %s for lost+found dir.\n",
        PVFS_OID_str(&s_op->u.mgmt_create_root_dir.lost_and_found_handle));

    return 0;
}



static PINT_sm_action mgmt_create_root_crdirent_lost_found_setup_msgpair(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -PVFS_EINVAL;
    PINT_sm_msgpair_state *msg_p = NULL;
    PVFS_dist_dir_hash_type dirdata_hash;
    int dirdata_server_index;
    int num_handles;
    PVFS_handle *handle_array = NULL;

    gossip_debug(GOSSIP_SERVER_DEBUG,
                 "mgmt-create-root-dir state: "
                 "crdirent_lost_found_setup_msgpair\n");

    js_p->error_code = 0;
    
    /* find the hash value and the dist dir bucket */
    dirdata_hash = PINT_encrypt_dirdata(lost_and_found_string);
    gossip_debug(GOSSIP_SERVER_DEBUG,
                 "mgmt-create-root-dir: encrypt dirent %s "
                 "into hash value %llu.\n",
                 lost_and_found_string,
                 llu(dirdata_hash));

    dirdata_server_index = PINT_find_dist_dir_bucket(
                                              dirdata_hash,
                                              &s_op->attr.u.dir.dist_dir_attr,
                                              s_op->attr.u.dir.dist_dir_bitmap);
    gossip_debug(GOSSIP_SERVER_DEBUG,
                 "mgmt-create-root-dir: selecting bucket No.%d "
                 "from dist_dir_bitmap.\n",
                 dirdata_server_index);

    /* Update capability to send with request. */
/* I think this is old code - so we get rid of it - V3 */
#if 0
    s_op->u.mgmt_create_root_dir.capability.num_handles = 1;
    s_op->u.mgmt_create_root_dir.capability.handle_array =
                                            malloc(sizeof(PVFS_handle));
    s_op->u.mgmt_create_root_dir.capability.handle_array[0] = s_op->target_handle;
    config = get_server_config_struct();
    s_op->u.mgmt_create_root_dir.capability.issuer = 
        (char *) malloc(strlen(config->server_alias) + 3);
    if (s_op->u.mgmt_create_root_dir.capability.issuer == NULL)
#endif
    /* first, free the one we have already been using */
    PINT_cleanup_capability(&s_op->u.mgmt_create_root_dir.capability);

    /* create new handle array with target handle and dirdata handles */
    num_handles = s_op->attr.u.dir.dist_dir_attr.dirdata_count + 1;
    handle_array = (PVFS_handle *) malloc(num_handles * sizeof(PVFS_handle));
    if (handle_array == NULL)
    {
        gossip_err("mgmt-create-root-dir: out of memory in %s\n", __func__);
        js_p->error_code = -PVFS_ENOMEM;

        return SM_ACTION_COMPLETE;
    }
    handle_array[0] = s_op->target_handle;
    memcpy((handle_array + 1),
           s_op->attr.u.dir.dirdata_handles,
           s_op->attr.u.dir.dist_dir_attr.dirdata_count * sizeof(PVFS_handle));

    /* create new capability -- note that handle_array will be freed by 
       PINT_cleanup_capability when the SM completes */
    ret = PINT_server_to_server_capability(&s_op->u.mgmt_create_root_dir.capability, 
                                           s_op->target_fs_id,
                                           num_handles,
                                           handle_array);
    if (ret != 0)
    {
        gossip_err("mgmt-create-root-dir: unable to retrieve server-to-server "
                   "capability in %s\n", __func__);
        js_p->error_code = -PVFS_EACCES;

        return SM_ACTION_COMPLETE;
    }

    gossip_debug(GOSSIP_SERVER_DEBUG,
                 " mgmt-create-root-dir: posting crdirent req\n");

    gossip_debug(GOSSIP_SERVER_DEBUG,
           "hooking dirent %s (%s) under "
           "parent handle %s, dirdata_handle %s with server_no=%d\n",
           lost_and_found_string,
           PVFS_OID_str(&s_op->u.mgmt_create_root_dir.lost_and_found_handle),
           PVFS_OID_str(&s_op->target_handle),
           PVFS_OID_str(&s_op->attr.u.dir.dirdata_handles[
                                                  dirdata_server_index]),
           dirdata_server_index);

    PINT_msgpair_init(&s_op->msgarray_op);
    msg_p = &s_op->msgarray_op.msgpair;

    PINT_SERVREQ_CRDIRENT_FILL(
                         msg_p->req,
                         s_op->u.mgmt_create_root_dir.capability,
                         s_op->u.mgmt_create_root_dir.credential,
                         s_op->target_fs_id,
    /*bucket handle*/    s_op->target_handle, 
                         0,    /* V3 sid count of bucket */
                         NULL, /* V3 sid array for target */
    /*stored name*/      lost_and_found_string,
    /*stored handle*/    s_op->attr.u.dir.dirdata_handles[dirdata_server_index],
                         NULL, /* V3 sid array for stored handle */
    /*metadata handle*/  s_op->u.mgmt_create_root_dir.lost_and_found_handle,
                         NULL, /* V3 sid array for metadata */
                         NULL);

    msg_p->fs_id = s_op->target_fs_id;
    /* send to dirdata server */
    msg_p->handle = s_op->attr.u.dir.dirdata_handles[dirdata_server_index];
    msg_p->retry_flag = PVFS_MSGPAIR_NO_RETRY;
    msg_p->comp_fn = crdirent_lost_found_comp_fn;

/* V3 SID_get_addr needs proper arguments */
#if 0
    ret = PINT_cached_config_map_to_server(&msg_p->svr_addr,
                                           msg_p->handle,
                                           s_op->target_fs_id);
#endif
    ret = PVFS_SID_get_addr(&msg_p->svr_addr, &msg_p->sid_array[0]);

    if (ret)
    {
        gossip_err("Failed to map meta server address\n");
        js_p->error_code = ret;
    }

    PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);
    return SM_ACTION_COMPLETE;
}

static int crdirent_lost_found_comp_fn(void *v_p,
                                           struct PVFS_server_resp *resp_p,
                                           int index)
{
    gossip_debug(GOSSIP_SERVER_DEBUG, "%s: enter\n", __func__);

    assert(resp_p->op == PVFS_SERV_CRDIRENT);
    return resp_p->status;
}



static PINT_sm_action mgmt_create_root_delete_lost_found_handle_setup_msgpair(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -PVFS_EINVAL;
    PVFS_BMI_addr_t metafile_server_addr;
    PINT_sm_msgpair_state *msg_p = NULL;

    gossip_debug(GOSSIP_SERVER_DEBUG, "mgmt-create-root-dir state: "
                 "delete_lost_found_handle_setup_msgpair_array\n");

    js_p->error_code = 0;

    PINT_msgpair_init(&s_op->msgarray_op);
    msg_p = &s_op->msgarray_op.msgpair;

/* V3 SID_get_addr needs proper arguments */
#if 0
    ret = PINT_cached_config_map_to_server(
                           &metafile_server_addr, 
                           s_op->u.mgmt_create_root_dir.lost_found_handle,
                           s_op->target_fs_id);
#endif
    ret = PVFS_SID_get_addr(&metafile_server_addr, &msg_p->sid_array[0]);

    if (ret)
    {
        gossip_err("Failed to map meta server address\n");
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    PINT_SERVREQ_REMOVE_FILL(msg_p->req,
                             s_op->u.mgmt_create_root_dir.capability,
                             s_op->u.mgmt_create_root_dir.credential,
                             s_op->target_fs_id,
                             s_op->u.mgmt_create_root_dir.lost_and_found_handle,
                             0,    /* V3 sid count */
                             NULL, /* V3 sid array */
                             NULL);

    msg_p->fs_id = s_op->target_fs_id;
    msg_p->handle = s_op->u.mgmt_create_root_dir.lost_and_found_handle;
    msg_p->retry_flag = PVFS_MSGPAIR_NO_RETRY;
    msg_p->comp_fn = delete_lost_found_handle_comp_fn;
    msg_p->svr_addr = metafile_server_addr;

    gossip_debug(GOSSIP_SERVER_DEBUG, " Preparing to remove "
                 "lost+found directory handle %s\n",
                 PVFS_OID_str(&msg_p->handle));

    PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);
    return SM_ACTION_COMPLETE;
}


static int delete_lost_found_handle_comp_fn(void *v_p,
                                       struct PVFS_server_resp *resp_p,
                                       int index)
{
    gossip_debug(GOSSIP_SERVER_DEBUG, "delete_lost_found_handle_comp_fn\n");

    assert(resp_p->op == PVFS_SERV_REMOVE);
    return resp_p->status;
}



/*
 * Function: mgmt_create_root_cleanup_noreq
 *
 * Params:   server_op *b,
 *           job_status_s *js_p
 *
 * Returns:  int
 *
 * Synopsis: free memory and return
 *
 */
static PINT_sm_action mgmt_create_root_cleanup_noreq(struct PINT_smcb *smcb, 
                                                         job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);

    assert(s_op);

    if (js_p->error_code != 0)
    {
        char errstr[256];
        PVFS_strerror_r(js_p->error_code, errstr, sizeof(errstr));
        gossip_err("Warning: unable to create root dir due to error: %s\n", 
                   errstr);
        gossip_err("         Your FS may be in an inconsistent state\n");
    }

    if(s_op->key_a)
    {
        free(s_op->key_a);
    }

    if(s_op->val_a)
    {
        free(s_op->val_a);
    }

    PINT_free_object_attr(&s_op->attr);

    if(s_op->u.mgmt_create_root_dir.handle_array_local)
    {
        free(s_op->u.mgmt_create_root_dir.handle_array_local);
    }

    if(s_op->u.mgmt_create_root_dir.handle_array_remote)
    {
        free(s_op->u.mgmt_create_root_dir.handle_array_remote);
    }

    PINT_cleanup_credential(&s_op->u.mgmt_create_root_dir.credential);
    PINT_cleanup_capability(&s_op->u.mgmt_create_root_dir.capability);

    return(server_state_machine_complete_noreq(smcb));
}


PINT_GET_OBJECT_REF_DEFINE(mgmt_create_root_dir);

static int perm_mgmt_create_root_dir(PINT_server_op *s_op)
{
    int ret;

    /* permission not required */
    ret = 0;

    return ret;
}

struct PINT_server_req_params pvfs2_mgmt_create_root_dir_params =
{
    .string_name = "mgmt-create-root-dir",
    .get_object_ref = PINT_get_object_ref_mgmt_create_root_dir,
    .perm = perm_mgmt_create_root_dir,
    .access_type = PINT_server_req_modify,
    .sched_policy = PINT_SERVER_REQ_SCHEDULE,
    .state_machine = &pvfs2_mgmt_create_root_sm
};

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */

