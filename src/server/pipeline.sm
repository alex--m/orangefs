/* 
 * (C) 2001 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

/*
 *  PVFS2 server state machine for driving read/write I/O operations.
 */
#define _ISOC99_SOURCE /* log2() */ 

#include <string.h>
#include <assert.h>
#include <stdlib.h>
#include <math.h> /* log2() */

#include "server-config.h"
#include "pvfs2-server.h"
#include "pvfs2-attr.h"
#include "pvfs2-request.h"
#include "pint-distribution.h"
#include "pvfs2-dist-simple-stripe.h"
#include "pint-request.h"
#include "pvfs2-internal.h"
#include "trove.h"
#include "pint-util.h"
#include "pint-cached-config.h"

#define LOOP 101
#define UNALIGNED 102
#define DO_COMP 103
#define DO_ALLREDUCE 104

static int s2s_comp_fn(
    void *v_p, struct PVFS_server_resp *resp_p, int index);

%%

nested machine pvfs2_pipeline_sm
{
    state fetch
    {
        run fetch_data;
        success => dispatch;
    }

    state dispatch
    {
        run dispatch_data;
	DO_COMP => check_align;
        success => check_pipeline;
    }

    state check_align
    {
	run check_align_fn;
	UNALIGNED => setup_s2s;
	success => do_comp;
    }

    state setup_s2s
    {
	run setup_s2s_msg;
	success => s2s_exchange;
    }

    state s2s_exchange
    {
	jump pvfs2_msgpairarray_sm;
	success => do_comp;
    }

    state do_comp
    {
	run do_comp_fn;
	DO_ALLREDUCE => setup_allreduce;
	success => check_pipeline;
    }

    state setup_allreduce
    {
	pjmp setup_allreduce_sm
	{
	    success => pvfs2_allreduce_sm;
	}
	success => cleanup_allreduce;
    }

    state cleanup_allreduce
    {
	run cleanup_allreduce_fn;
	success => check_pipeline;
    }

    state check_pipeline
    {
        run check_pipeline_done;
        LOOP => fetch;
	success => return;
    }
}

%%

/*
 * fetch data from either TROVE (in case of READ) or BMI (in case of WRITE)
 * 
 *   PINT_segpool_take_segments()
 *     => READ: job_trove_bstream_read_list()
 *     => WRITE: job_bmi_recv()
 */
static PINT_sm_action fetch_data(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PINT_segpool_handle_t seg_handle = s_op->u.pipeline.seg_handle;
    PINT_segpool_unit_id id = s_op->u.pipeline.id;
    struct server_configuration_s *user_opts = get_server_config_struct();
    int count, ret, i;
    PVFS_offset *offsets;
    PVFS_size *sizes;
    PVFS_size bytes;
    job_id_t tmp_id;

    gossip_debug(GOSSIP_IO_DEBUG, "smcb->base_frame=%d, frame_count=%d\n", 
		 smcb->base_frame, smcb->frame_count);
    s_op->u.pipeline.buffer_used = 0;
    bytes = s_op->u.pipeline.buffer_size;

    PINT_segpool_take_segments(seg_handle, id, &bytes, &count, 
			       &offsets, &sizes);
    gossip_debug(GOSSIP_IO_DEBUG, "%s: %s: bytes=%lld, count=%d\n", 
		 __func__, 
		 (s_op->u.pipeline.io_type==PVFS_IO_READ?"READ":"WRITE"),
		 lld(bytes), count);

    for(i=0; i<count; i++) {
	gossip_debug(GOSSIP_IO_DEBUG, "offsets[%d]=%lld, sizes[%d]=%lld\n",
		     i, lld(offsets[i]), i, lld(sizes[i]));
    }

    if(count == 0) {
	js_p->error_code = 0;
	//gossip_debug(GOSSIP_IO_DEBUG, "%s: count==0?\n", __func__);
	return SM_ACTION_COMPLETE;
    }

    s_op->u.pipeline.buffer_used = bytes;
    s_op->u.pipeline.offsets = offsets;
    s_op->u.pipeline.sizes = sizes;
    s_op->u.pipeline.segs = count;

    if(s_op->u.pipeline.io_type == PVFS_IO_READ) {
	
	ret = job_trove_bstream_read_list
	    (s_op->u.pipeline.fs_id,
	     s_op->u.pipeline.handle,
	     (char **)&s_op->u.pipeline.buffer,
	     (PVFS_size *)&s_op->u.pipeline.buffer_used,
	     1,
	     offsets,
	     sizes,
	     count,
	     &s_op->u.pipeline.out_size,
	     s_op->u.pipeline.trove_sync_flag,
	     NULL,
	     smcb,
	     0,
	     js_p,
	     &tmp_id,
	     server_job_context,
	     s_op->u.pipeline.hints);
    }
    else if (s_op->u.pipeline.io_type == PVFS_IO_WRITE) {
	ret = job_bmi_recv(s_op->u.pipeline.address,
		       (void *)s_op->u.pipeline.buffer,
		       s_op->u.pipeline.buffer_size,
		       s_op->u.pipeline.tag,
		       BMI_PRE_ALLOC, 
		       smcb, 
		       0, /* unsigned long status_user_tag = 0 */
		       js_p,
		       &tmp_id,
		       server_job_context,
		       user_opts->server_job_flow_timeout,
		       (bmi_hint)s_op->u.pipeline.hints);
    }

    if(ret < 0) {
	gossip_err("%s: I/O error occurred\n", __func__);
	/* FIXME */
	//handle_io_error(ret, q_item, flow_data);
	js_p->error_code = -PVFS_EIO;
	return SM_ACTION_COMPLETE;
    }

    /* immediate return */
    if(ret == 1) {
	js_p->error_code = 1;
	return SM_ACTION_COMPLETE;
    }

    if(ret == 0) {
	js_p->error_code = 0;
	return SM_ACTION_DEFERRED;
    }

    return SM_ACTION_COMPLETE;
}

/*
 * Dispatch data to either BMI (in case of READ) or TROVE (in case of WRITE)
 *
 *   => READ: job_bmi_send()
 *   => WRITE: job_trove_bstream_write_list()
 */
static PINT_sm_action dispatch_data(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret;
    job_id_t tmp_id;
    struct server_configuration_s *user_opts = get_server_config_struct();

    if(s_op->u.pipeline.segs == 0) {
	js_p->error_code = 0;
	gossip_debug(GOSSIP_IO_DEBUG, "%s: count==0?\n", __func__);
	return SM_ACTION_COMPLETE;
    }

    gossip_debug(GOSSIP_IO_DEBUG, "%s: %s: buffer_used=%lld\n", __func__,
		 (s_op->u.pipeline.io_type==PVFS_IO_READ?"READ":"WRITE"),
		 lld(s_op->u.pipeline.buffer_used));
#if 0
    gossip_debug(GOSSIP_IO_DEBUG, "%s: buffer[0]=%s\n", __func__,
		 (char *)s_op->u.pipeline.buffer);
#endif

    
    if(s_op->u.pipeline.io_type == PVFS_IO_READ) {
	assert(s_op->u.pipeline.buffer_used);

	if(s_op->u.pipeline.op != 0) { /* AS: when op is specified */
	    ret = DO_COMP; /* AS: skip sending if op is specified */ 
	    gossip_debug(GOSSIP_IO_DEBUG, "%s: parent->op != 0\n", __func__);
	    js_p->error_code = ret;
	    return SM_ACTION_COMPLETE;
	} 
	else 
	    ret = job_bmi_send(s_op->u.pipeline.address,
			       s_op->u.pipeline.buffer,
			       js_p->actual_size, 
			       s_op->u.pipeline.tag,
			       BMI_PRE_ALLOC,
			       0, /* send_unexpected */
			       smcb, /* user_ptr */
			       0, /* status_user_tag */
			       js_p,
			       &tmp_id,
			       server_job_context,
			       user_opts->server_job_bmi_timeout,
			       (bmi_hint)s_op->u.pipeline.hints);
	
    }
    else if(s_op->u.pipeline.io_type == PVFS_IO_WRITE) {
	ret = job_trove_bstream_write_list
	    (s_op->u.pipeline.fs_id,
	     s_op->u.pipeline.handle,
	     (char **)&s_op->u.pipeline.buffer,
	     (TROVE_size *)&js_p->actual_size,
	     1,
	     s_op->u.pipeline.offsets,
	     s_op->u.pipeline.sizes,
	     s_op->u.pipeline.segs,
	     &s_op->u.pipeline.out_size,
	     s_op->u.pipeline.trove_sync_flag,
	     NULL,
	     smcb,
	     0,
	     js_p,
	     &tmp_id,
	     server_job_context,
	     s_op->u.pipeline.hints);
    }

    if(ret < 0) {
	gossip_err("%s: I/O error occurred\n", __func__);
	/* FIXME !!!!!!! */
	/* handle_io_error(ret, q_item, flow_data); */
	js_p->error_code = ret;
	return SM_ACTION_COMPLETE;
    }
    
    /* immediate return */
    if(ret == 1) {
	js_p->error_code = ret;
	return SM_ACTION_COMPLETE;
    }
	
    if(ret == 0) {
	js_p->error_code = ret;
	return SM_ACTION_DEFERRED;
    }

    return SM_ACTION_COMPLETE;
}


static PINT_sm_action check_align_fn(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    js_p->error_code = 0;
    PVFS_size file_req_offset = s_op->u.pipeline.file_req_offset;
    PINT_request_file_data fdata = s_op->u.pipeline.file_data;
    PVFS_simple_stripe_params *dparam = 
	(PVFS_simple_stripe_params*)fdata.dist->params;
    PVFS_size count;
    PVFS_offset strip_boundary;

    PVFS_offset loff = fdata.dist->methods->physical_to_logical_offset(fdata.dist->params, &fdata, s_op->u.pipeline.offsets[0]);
    
    s_op->u.pipeline.loff = loff;
    gossip_debug(GOSSIP_IO_DEBUG, "loff=%lld, file_req_offset=%lld\n", lld(loff), lld(file_req_offset));

    switch(s_op->u.pipeline.datatype) {
    case ((int)0x4c000405): /* MPI_INT */
	count = (PVFS_size)(s_op->u.pipeline.buffer_used - 
			    file_req_offset)/((*PVFS_INT).ub);
	gossip_debug(GOSSIP_IO_DEBUG, "count=%lld\n", lld(count));
	strip_boundary = ((int)(loff/(dparam->strip_size)))*(dparam->strip_size);
	s_op->u.pipeline.unaligned_size = loff-strip_boundary;
	
	if (loff == strip_boundary && file_req_offset != 0) {
	    s_op->u.pipeline.unaligned_size = file_req_offset;
	}

	if (s_op->u.pipeline.unaligned_size != 0 && count != 0) {
	    js_p->error_code = UNALIGNED;
	    gossip_debug(GOSSIP_IO_DEBUG, "unaligned_size=%lld\n", 
			 lld(s_op->u.pipeline.unaligned_size));
	}
    case ((int)0x4c00080b): /* MPI_DOUBLE */
	count = (PVFS_size)(s_op->u.pipeline.buffer_used - 
			    file_req_offset)/((*PVFS_DOUBLE).ub);
	gossip_debug(GOSSIP_IO_DEBUG, "count=%lld\n", lld(count));
	strip_boundary = ((int)(loff/(dparam->strip_size)))*(dparam->strip_size); /* FIXME */
	s_op->u.pipeline.unaligned_size = loff-strip_boundary;

	if (loff == strip_boundary && file_req_offset != 0) {
	    s_op->u.pipeline.unaligned_size = file_req_offset;
	}
	
	if (s_op->u.pipeline.unaligned_size != 0 && count != 0) {
	    js_p->error_code = UNALIGNED;
	    gossip_debug(GOSSIP_IO_DEBUG, "unaligned_size=%lld\n", 
			 lld(s_op->u.pipeline.unaligned_size));
	}
    }

    return SM_ACTION_COMPLETE;
}


static PINT_sm_action setup_s2s_msg(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    PINT_sm_msgpair_state *msg_p = NULL;
    struct server_configuration_s *user_opts = get_server_config_struct();
    int regions;
    int ret;
    PVFS_credentials creds;
    int next_server_index;
    PVFS_handle next_server_handle;

    /* init msgpair */
    PINT_msgpair_init(&s_op->msgarray_op);
    msg_p = &s_op->msgarray_op.msgpair;

    s_op->msgarray_op.params.job_timeout = user_opts->client_job_bmi_timeout;
    s_op->msgarray_op.params.retry_delay = user_opts->client_retry_delay_ms;
    s_op->msgarray_op.params.retry_limit = user_opts->client_retry_limit;
    s_op->msgarray_op.params.quiet_flag = 1;

    PINT_util_gen_credentials(&creds);
    gossip_debug(GOSSIP_IO_DEBUG, "loff=%lld, buffer_used=%lld\n", lld(s_op->u.pipeline.loff), lld(s_op->u.pipeline.buffer_used));

    /* determine which server we need to talk to */
    next_server_index = (s_op->u.pipeline.dfile_index + 1)%(s_op->u.pipeline.dfile_count);
    next_server_handle = s_op->u.pipeline.dfile_array[next_server_index];

    /* build a request */
    ret = PVFS_Request_contiguous(s_op->u.pipeline.unaligned_size, 
				  PVFS_BYTE, &s_op->u.pipeline.file_req);
    
    s_op->u.pipeline.file_req_offset = (((int)(s_op->u.pipeline.loff/262144))+1)*262144; /* FIXME */
    
    regions = 1;
    gossip_debug(GOSSIP_IO_DEBUG, "s_op->u.pipeline.file_req_offset=%lld\n", lld(s_op->u.pipeline.file_req_offset));

    PINT_SERVREQ_SMALL_IO_FILL(msg_p->req,
			       creds,
			       s_op->u.pipeline.fs_id,
			       next_server_handle,
			       s_op->u.pipeline.io_type,
			       next_server_index,
			       s_op->u.pipeline.dfile_count,
			       s_op->u.pipeline.dist,
			       s_op->u.pipeline.file_req,
			       s_op->u.pipeline.file_req_offset,
			       regions,
			       s_op->u.pipeline.unaligned_size,
			       NULL /* s_op->hints */);

    msg_p->fs_id = s_op->u.pipeline.fs_id;
    msg_p->handle = next_server_handle;
    msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
    msg_p->comp_fn = s2s_comp_fn;

    ret = PINT_cached_config_map_to_server(&msg_p->svr_addr, 
					   next_server_handle, //s_op->u.pipeline.handle,
					   s_op->u.pipeline.fs_id);
    gossip_debug(GOSSIP_IO_DEBUG, "%s: msg_p->svr_addr=%llu\n", __func__,
		 llu(msg_p->svr_addr));
    if(ret < 0) {
	gossip_err("Failed to map meta server address\n");
	js_p->error_code = ret;
	return SM_ACTION_COMPLETE;
    }

    js_p->error_code = 0;

    PINT_sm_push_frame(smcb, 0, &s_op->msgarray_op);
    return SM_ACTION_COMPLETE;
}

static int s2s_comp_fn(void *v_p, struct PVFS_server_resp *resp_p,
			int index)
{
    PINT_smcb *smcb = v_p;
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_MSGPAIR_PARENT_SM);

    gossip_debug(GOSSIP_IO_DEBUG, "%s called\n", __func__);
    gossip_debug(GOSSIP_IO_DEBUG, "resp_p->status=%d\n", resp_p->status);
    gossip_debug(GOSSIP_IO_DEBUG, "small_io: result_size=%lld\n", 
		     lld(resp_p->u.small_io.result_size));

    assert(resp_p->op == PVFS_SERV_SMALL_IO);

    if (resp_p->status != 0) {
	return resp_p->status;
    }

    if(resp_p->u.small_io.result_size != 0) {
	memcpy(s_op->u.pipeline.tmp_buf, resp_p->u.small_io.buffer, 
	       resp_p->u.small_io.result_size);
    }

    return 0;
}

/* square of Euclid distance between two multi-dimensional points            */
__inline static
float euclid_dist_2(int    numdims,  /* no. dimensions */
                    float *coord1,   /* [numdims] */
                    float *coord2)   /* [numdims] */
{
  int i;
  float ans=0.0;

  for (i=0; i<numdims; i++)
    ans += (coord1[i]-coord2[i]) * (coord1[i]-coord2[i]);

  return(ans);
}

/*----< find_nearest_cluster() >---------------------------------------------*/
__inline static
int find_nearest_cluster(int     numClusters, /* no. clusters */
                         int     numCoords,   /* no. coordinates */
                         float  *object,      /* [numCoords] */
                         float **clusters)    /* [numClusters][numCoords] */
{
  int   index, i;
  float dist, min_dist;

  /* find the cluster id that has min distance to object */
  index    = 0;
  min_dist = euclid_dist_2(numCoords, object, clusters[0]);

  for (i=1; i<numClusters; i++) {
    dist = euclid_dist_2(numCoords, object, clusters[i]);
    /* no need square root */
    if (dist < min_dist) { /* find the min and its array index */
      min_dist = dist;
      index    = i;
    }
  }
  return(index);
}

static PINT_sm_action do_comp_fn(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    struct PINT_server_op *parent_s_op = PINT_sm_frame(smcb->parent_smcb, 0);
    js_p->error_code = 0;

    if(s_op->u.pipeline.buffer) {
	PVFS_size i;
	gossip_debug(GOSSIP_FLOW_PROTO_DEBUG,
		     "%s: buffer_used=%lld, op=0x%x, datatype=0x%x, actual_size=%lld\n", 
		     __func__, lld(s_op->u.pipeline.buffer_used), 
		     s_op->u.pipeline.op, 
		     s_op->u.pipeline.datatype,
		     lld(js_p->actual_size)); /* AS */

	switch(s_op->u.pipeline.datatype) {
	case ((int)0x4c000405): /* MPI_INT */
	    {
		int *a = (int*)s_op->u.pipeline.buffer;
		int result;
		PVFS_size count = (s_op->u.pipeline.buffer_used-s_op->u.pipeline.unaligned_size)/((*PVFS_INT).ub);
		int *tmp;

		if(count == 0)
		    return SM_ACTION_COMPLETE;
		/* data is not aligned perfectly, so adjust it */
		if(s_op->u.pipeline.unaligned_size != 0) {
		    memcpy(((char*)&a[count])+(((*PVFS_INT).ub)-s_op->u.pipeline.unaligned_size), s_op->u.pipeline.tmp_buf, s_op->u.pipeline.unaligned_size);
		    count++;
		}
		
		if (parent_s_op->u.io.total_transferred == 0) {
		    if (parent_s_op->u.io.tmp_buffer == NULL)
			parent_s_op->u.io.tmp_buffer = (void *)malloc(1*sizeof(int));
		    memset(parent_s_op->u.io.tmp_buffer, 0, sizeof(int));
		    parent_s_op->u.io.count = 0;
		}
		tmp = parent_s_op->u.io.tmp_buffer;
		gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "total_transferred=%lld\n", lld(parent_s_op->u.io.total_transferred));
		gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "count=%lld, tmp=%d\n", lld(count), *tmp);

		switch(s_op->u.pipeline.op) {
		case 0x58000001: /* MAX */
		    result = *a;
		    for (i=1; i<count; i++ ) {
			if (a[i] > result) {
			    result = a[i];
			}
		    }
		    a[0] = result;
		    if (parent_s_op->u.io.total_transferred == 0 ||
			result > *tmp)
			*tmp = result;
		    break;
		case 0x58000002: /* MIN */
		    result = *a;
		    for (i=1; i<count; i++ ) {
			if (a[i] < result) {
			    result = a[i];
			}
		    }
		    a[0] = result;
		    if (parent_s_op->u.io.total_transferred == 0 ||
			result < *tmp)
			*tmp = result;
		    break;
		case 0x58000003: /* SUM */
		    result = 0;
		    for (i=0; i<count; i++ ) {
			if (i<10) 
			    gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "a[%lld]=%d\n", 
					 lld(i), a[i]);
			result += a[i];
		    }
		    a[0] = result;
		    *tmp += result;
		    gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "sum=%d\n", 
				 *tmp);
		    break;
		case (0x5800000e): /* MEAN */
		    result = 0;
		    for (i=0; i<count; i++) {
			result += a[i];
		    }
		    result = result/count;
		    a[0] = result;
		    
		    if (parent_s_op->u.io.count == 0)
			*tmp = result;
		    else {
			int tmp_sum = (*tmp)*(parent_s_op->u.io.count);
			tmp_sum = tmp_sum + result*count;
			*tmp = (tmp_sum)/(parent_s_op->u.io.count+count);
		    }
		    parent_s_op->u.io.count += count;
		    gossip_debug(GOSSIP_IO_DEBUG, "mean=%d\n", *tmp);
		    break;
		default:
		    break;
		}
		s_op->u.pipeline.buffer = (void *)a;
		parent_s_op->u.io.tmp_buffer = (void *)tmp;
	    }
	    break;

	case ((int)0x4c00080b): /* MPI_DOUBLE */
	    {
		double *a = (double*)s_op->u.pipeline.buffer;
		double result;
		PVFS_size count = (s_op->u.pipeline.buffer_used-s_op->u.pipeline.unaligned_size)/((*PVFS_DOUBLE).ub);
		double *tmp;
		PVFS_offset strip_boundary = (int)(s_op->u.pipeline.loff/262144)*262144; /* FIXME */

		if (s_op->u.pipeline.buffer_used < 262144 && 
		    s_op->u.pipeline.loff != strip_boundary) { /* FIXME */
		    count = (s_op->u.pipeline.buffer_used)/((*PVFS_DOUBLE).ub);
		}
		gossip_debug(GOSSIP_IO_DEBUG, "count=%lld\n", lld(count));
		if(count < 1)
		    return SM_ACTION_COMPLETE;

		/* data is not aligned perfectly, so adjust it within the memory*/
		if(s_op->u.pipeline.unaligned_size != 0) {
		    PVFS_size adj_sz = s_op->u.pipeline.unaligned_size;
		    PVFS_size tmp_sz = ((*PVFS_DOUBLE).ub) - adj_sz;
		    
		    if(s_op->u.pipeline.loff == strip_boundary) {
			memcpy(a, (char*)&a[0]+adj_sz,
			       s_op->u.pipeline.buffer_used-adj_sz);
		    }

		    memcpy(((char*)&a[count])+tmp_sz, s_op->u.pipeline.tmp_buf, 
			   s_op->u.pipeline.unaligned_size);


		    count++;
		    
		    if(s_op->u.pipeline.buffer_used < (262144-((*PVFS_DOUBLE).ub)))
			count--;
		}

		if (parent_s_op->u.io.total_transferred == 0) {
		    if (parent_s_op->u.io.tmp_buffer == NULL)
			parent_s_op->u.io.tmp_buffer = (void *)malloc(1*sizeof(double));
		    memset( parent_s_op->u.io.tmp_buffer, 0, sizeof(double));
		    parent_s_op->u.io.count = 0;
		}
		tmp = parent_s_op->u.io.tmp_buffer;
		gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, 
			     "total_transferred=%lld\n",
			     lld(parent_s_op->u.io.total_transferred));
		gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "count=%lld, tmp=%lf\n", 
			     lld(count), *tmp);
		switch(s_op->u.pipeline.op) {
		case 0x58000001: /* MAX */
		    result = *a;
		    for (i=1; i<count; i++ ) {
			if (a[i] > result) {
			    result = a[i];
			}
		    }
		    a[0] = result;
		    if (parent_s_op->u.io.total_transferred == 0 ||
			result > *tmp)
			*tmp = result;
		    gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "max=%lf\n", *tmp);
		    break;
		case 0x58000002: /* MIN */
		    result = *a;
		    for (i=1; i<count; i++ ) {
			if (a[i] < result) {
			    result = a[i];
			}
		    }

		    a[0] = result;
		    if (parent_s_op->u.io.total_transferred == 0 ||
			result < *tmp)
			*tmp = result;
		    gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "min=%lf\n", 
				 *tmp);
		    break;
		case 0x58000003: /* SUM */
		    result = 0;
		    for (i=0; i<count; i++ ) {
			if (i<10 || i== (count-1) || i == count) gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "a[%lld]=%lf\n", lld(i), a[i]);
			result += a[i];
		    }

		    a[0] = result;
		    *tmp += result;
		    gossip_debug(GOSSIP_FLOW_PROTO_DEBUG, "sum=%lf\n", 
				 *tmp);
		    break;    
		case (0x5800000e): /* MEAN */
		    result = 0;
		    for (i=0; i<count; i++) {
			result += a[i];
		    }
		    result = result/count;
		    a[0] = result;

		    gossip_debug(GOSSIP_IO_DEBUG, "count=%lld\n", lld(parent_s_op->u.io.count));

		    if (parent_s_op->u.io.count == 0)
			*tmp = result;
		    else {
			double tmp_sum = (*tmp)*(parent_s_op->u.io.count);
			tmp_sum = tmp_sum + result*count;
			*tmp = (tmp_sum)/(parent_s_op->u.io.count+count);
		    }
		    parent_s_op->u.io.count += count;
		    gossip_debug(GOSSIP_IO_DEBUG, "mean=%lf\n", result);
		    break;
		case (0x5800000f): /* KMEANS */ {
		    int index, numObjs, j;
		    int numClusters=2, numCoords=4;
		    double delta;
		    
#if 0
		    for(i=0; i<numObjs; i++) {
			//result = a[i];
			index = find_nearest_cluster(numClusters, numCoords, a[i], clusters);
			if(membership[i] != index) delta += 1.0;
			membership[i] = index;

			newClusterSize[index]++;
			for(j=0; j<numCoords; j++)
			    newClusters[index][j] += objects[i][j];
		    }
#endif
		    js_p->error_code = DO_ALLREDUCE;
		    break;
		}
		default:
		    break;
		} /* end inner switch */
		s_op->u.pipeline.buffer = (void *)a;
		parent_s_op->u.io.tmp_buffer = (void *)tmp;
	    }
	    
	    break;
	default:
	    break;
	} /* end switch() */
    } /* end if() */

    return SM_ACTION_COMPLETE;
}

static PINT_sm_action setup_allreduce_sm(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret, tmp_id;
    struct server_configuration_s *user_opts = get_server_config_struct();
    PVFS_handle new_rank_handle;
    PVFS_BMI_addr_t svr_addr;
    struct PINT_server_op *allreduce_op;
    int i;

    allreduce_op = malloc(sizeof(*allreduce_op));
    memset(allreduce_op, 0, sizeof(*allreduce_op));
    allreduce_op->u.allreduce.fs_id = s_op->u.pipeline.fs_id;
    allreduce_op->u.allreduce.myRank = s_op->u.pipeline.dfile_index;
    allreduce_op->u.allreduce.recv_buf = (void*)malloc(5*sizeof(double));
    memset(allreduce_op->u.allreduce.recv_buf, 0, 5*sizeof(double));
    allreduce_op->u.allreduce.tree_depth = log2(s_op->u.pipeline.dfile_count);
    gossip_debug(GOSSIP_IO_DEBUG, "tree_depth=%d\n", 
		 allreduce_op->u.allreduce.tree_depth);
    allreduce_op->u.allreduce.current_depth = 0;
    allreduce_op->u.allreduce.mask = 0x1;
    allreduce_op->u.allreduce.dfile_array = s_op->u.pipeline.dfile_array;
    allreduce_op->u.allreduce.send_buf = (void*)malloc(5*sizeof(double));
    memset(allreduce_op->u.allreduce.send_buf, 0, 5*sizeof(double));

    ret = PINT_sm_push_frame(smcb, 0, allreduce_op);
    
    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action cleanup_allreduce_fn(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int task_id;
    int remaining;
    PVFS_error tmp_err;
    struct PINT_server_op *allreduce_op;

    allreduce_op = PINT_sm_pop_frame(smcb, &task_id, &tmp_err, 
            &remaining);
    gossip_debug(GOSSIP_SERVER_DEBUG, 
		 "pipeline: nested sm returned error code: %d\n", tmp_err);
    memcpy(s_op->u.pipeline.buffer, allreduce_op->u.allreduce.send_buf,
	   5*sizeof(double));
    free(allreduce_op->u.allreduce.send_buf);
    free(allreduce_op->u.allreduce.recv_buf);
    free(allreduce_op);

    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static PINT_sm_action check_pipeline_done(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    struct PINT_server_op *parent_s_op = PINT_sm_frame(smcb->parent_smcb, 0);
    PINT_segpool_handle_t h = s_op->u.pipeline.seg_handle;
    js_p->error_code = 0;

    /* FIMXE: do we really need this lock? */
    gen_mutex_lock(&parent_s_op->u.io.mutex);
    //parent_s_op->u.io.total_transferred += js_p->actual_size;
    parent_s_op->u.io.total_transferred += s_op->u.pipeline.buffer_used;
    gen_mutex_unlock(&parent_s_op->u.io.mutex);
    
    gossip_debug(GOSSIP_IO_DEBUG, "%s: total_transferred=%lld\n", __func__,
		 lld(parent_s_op->u.io.total_transferred));
    gossip_debug(GOSSIP_IO_DEBUG, "%s: actual_size=%lld\n", __func__,
		 lld(js_p->actual_size));

    /* FIXME: */
    /* unless the second condition is set, the server starts
       a new read request that is already done, and falls into
       infinite trove_read->bmi_send->check_done loop */
    if(!segpool_done(h) && s_op->u.pipeline.segs != 0) {
	gossip_debug(GOSSIP_IO_DEBUG, "%s: LOOP\n", __func__);
	js_p->error_code = LOOP;
    }
    else {
#if 0
	if(s_op->u.pipeline.op == (0x5800000f)) { /* KMEANS */
	    memcpy(parent_s_op->u.io.tmp_buffer, 
		   s_op->u.pipeline.buffer, sizeof(double));
	}
#endif
	gossip_debug(GOSSIP_IO_DEBUG, "%s: DONE\n", __func__);
    }
    
    return SM_ACTION_COMPLETE;
}

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */
