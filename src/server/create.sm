/* 
 * (C) 2001 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

#include <string.h>
#include <assert.h>

#include "server-config.h"
#include "pvfs2-server.h"
#include "pvfs2-config.h"
#include "pvfs2-attr.h"
#include "gossip.h"
#include "pvfs2-internal.h"
#include "pint-util.h"
#include "pint-cached-config.h"
#include "pint-security.h"
#include "replication-common-utils.h"
#include "pint-uid-map.h"

#define REPLACE_DONE 100

static inline void cleanup_keyval_pairs(int *nkey, PVFS_ds_keyval *key, PVFS_ds_keyval *val, int *error);

enum misc
{
    LOCAL_OPERATION    = 2,
    REMOTE_OPERATION   = 3,
    LOCAL_XATTR        = 4,
    REPLICATION_IS_OFF = 5
};

%%

machine pvfs2_create_sm
{
    state prelude
    {
        jump pvfs2_prelude_sm;
        success => create_metafile;
        default => setup_final_response;
    }

    state create_metafile
    {
        run create_metafile;
        success => check_stuffed;
        default => setup_final_response;
    }

    state check_stuffed
    {
        run check_stuffed;
        success => create_local_datafiles;
        default => setup_final_response;
    }

    state create_local_datafiles
    {
        run create_local_datafiles;
        success => setup_local_datafile_handles;
        default => remove_metafile_object;
    }

    state setup_local_datafile_handles
    {
        run setup_local_datafile_handles;
        success => request_datafiles;
        default => remove_local_datafile_handles;
    }

    state request_datafiles
    {
        run request_datafiles;
        success => write_keyvals;
        default => remove_local_datafile_handles;
    }

    state write_keyvals
    {
        run write_keyvals;
        success => check_for_replication;
        default => replace_remote_datafile_handles;
    }

    state check_for_replication
    {
        run check_for_replication;
        REPLICATION_IS_OFF => setobj_attribs;
        default => get_local_replication_datahandles;
    }

    state get_local_replication_datahandles
    {
        run get_local_replication_datahandles;
        success => get_remote_replication_datahandles;
        default => remove_keyvals;
    }

    state get_remote_replication_datahandles
    {
        run get_remote_replication_datahandles;
        success => write_replication_xattrs;
        default => remove_local_replication_datahandles;
    }

    state write_replication_xattrs
    {
        pjmp write_replication_xattrs
        {
           LOCAL_XATTR => pvfs2_pjmp_seteattr_fast_sm;
        }
        default => analyze_replication_xattrs;
    }

    state analyze_replication_xattrs
    {
        run analyze_replication_xattrs;
        success => setobj_attribs;
        default => replace_remote_replication_datahandles;
    }

    state setobj_attribs
    {
        run setattr_setobj_attribs;
        success => setup_resp;
        default => check_error_path;
    }

    state setup_resp
    {
        run setup_resp;
        default => setup_final_response;
    }

    state check_error_path
    {
        run check_for_replication;
        REPLICATION_IS_OFF => remove_keyvals;
        default => remove_replication_xattrs;
    }
    
    state remove_replication_xattrs
    {
        run remove_replication_xattrs;
        default => replace_remote_replication_datahandles;
    }

    state replace_remote_replication_datahandles
    {
        run replace_remote_replication_datahandles;
        REPLACE_DONE => remove_local_replication_datahandles;
        default => replace_remote_replication_datahandles;
    }

    state remove_local_replication_datahandles
    {
        run remove_local_replication_datahandles;
        default => remove_keyvals;
    }

    state remove_keyvals
    {
        run remove_keyvals;
        success => replace_remote_datafile_handles;
        default => setup_final_response;
    }

    state replace_remote_datafile_handles
    {
        run replace_remote_datafile_handles;
        REPLACE_DONE => remove_local_datafile_handles;
        default => replace_remote_datafile_handles;
    }

    state remove_local_datafile_handles
    {
        run remove_local_datafile_handles;
        default => remove_metafile_object;
    }


    state remove_metafile_object
    {
        run remove_metafile_object;
        default => setup_final_response;
    }


    state setup_final_response
    {
        run setup_final_response;
        default => final_response;
    }

    state final_response
    {
        jump pvfs2_final_response_sm;
        default => cleanup;
    }

    state cleanup
    {
        run cleanup;
        default => terminate;
    }
}

%%

static int setup_final_response(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);

    /* retrieve original error code if present */
    if(s_op->u.create.saved_error_code)
    {
        js_p->error_code = s_op->u.create.saved_error_code;
    }

    gossip_err("Value of stuffed (%d) returned to the client.\n"
               ,s_op->resp.u.create.stuffed);

    /* otherwise propagate the js_p->error code */
    return(SM_ACTION_COMPLETE);
}

static int create_metafile(struct PINT_smcb *smcb, job_status_s *js_p)
{

    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t i;
    PVFS_handle_extent_array meta_handle_ext_array;
    server_configuration_s *config = get_server_config_struct();

    /* first state to check in, make sure the attr mask contains the dist bit. 
     * it's required later (not sure if we have to require it) but if we don't
     * have it here, return an EINVAL */
    if( ! (s_op->req->u.create.attr.mask & PVFS_ATTR_META_DIST) )
    {
        gossip_debug(GOSSIP_SERVER_DEBUG, "%s: invalid create request, "
                     "attribute mask did not include the distribution\n",
                     __func__);
        js_p->error_code = -PVFS_EINVAL;
        return SM_ACTION_COMPLETE;
    }

    ret = PINT_cached_config_get_server(s_op->req->u.create.fs_id,
                                        config->host_id,
                                        PINT_SERVER_TYPE_META,
                                        &meta_handle_ext_array);

    ret = job_trove_dspace_create(s_op->req->u.create.fs_id,
                                  &meta_handle_ext_array,
                                  PVFS_TYPE_METAFILE,
                                  NULL,
                                  0,
                                  smcb,
                                  0,
                                  js_p,
                                  &i,
                                  server_job_context, s_op->req->hints);

    return(ret);
}

static int check_stuffed(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int server_type;
    server_configuration_s *config = get_server_config_struct();
    struct filesystem_configuration_s *fs_conf;
    PVFS_BMI_addr_t myaddr;
    PVFS_sys_layout *layout;
    int ret;
    const char* svr_name;
    int i;

    s_op->resp.u.create.metafile_handle = js_p->handle;
    gossip_err("s_op->resp.u.create.metafile_handle:%llu\n",llu(s_op->resp.u.create.metafile_handle));
    gossip_debug(
        GOSSIP_SERVER_DEBUG, "Metafile handle created: %llu\n",
        llu(js_p->handle));

    assert(config);

    layout = &s_op->req->u.create.layout;

    if(layout->algorithm == PVFS_SYS_LAYOUT_LIST)
    {
        for(i=0; i<layout->server_list.count; i++)
        {
            gossip_debug(GOSSIP_SERVER_DEBUG, "layout list server %d: %lld\n", 
                i, lld(layout->server_list.servers[i])); 
        }
    }

    fs_conf = PINT_config_find_fs_id(config, 
                                     s_op->req->u.create.fs_id);
    if(!fs_conf)
    {
        js_p->error_code = -PVFS_EINVAL;
        return(SM_ACTION_COMPLETE);
    }

    ret = BMI_addr_lookup(&myaddr, config->host_id);
    if(ret != 0)
    {
        /* we can't get our own address? */
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    /* is this metadata server also IO? */
    svr_name = PINT_cached_config_map_addr(s_op->req->u.create.fs_id,
                                           myaddr,
                                           &server_type);
    if(!svr_name)
    {
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    /* For now only support stuffing of ROUND_ROBIN layouts.
     * As a performance enhancement, don't create a stuffed
     * file when the current environment only has one server.
     * This prevents unstuffing from being called by the client sys-io machine.
    */
    if((server_type & PINT_SERVER_TYPE_IO) &&
        fs_conf->file_stuffing &&
        layout->algorithm == PVFS_SYS_LAYOUT_ROUND_ROBIN &&
        s_op->req->u.create.num_dfiles_req > 1 )
    {    
        /* we can do a stuffed create here, only one datafile */
        s_op->req->u.create.attr.u.meta.dfile_count = 1;
        s_op->resp.u.create.datafile_count = 1;
        s_op->resp.u.create.datafile_handles = malloc(sizeof(PVFS_handle));
        s_op->u.create.handle_array_local = malloc(sizeof(PVFS_handle));
        if(!s_op->resp.u.create.datafile_handles ||
           !s_op->u.create.handle_array_local)
        {
            js_p->error_code = -PVFS_ENOMEM;
            return SM_ACTION_COMPLETE;
        }

        s_op->resp.u.create.stuffed = 1;
        js_p->error_code = 0;
        return SM_ACTION_COMPLETE;
    }

    /* file will not be stuffed; need to allocate all datafiles */
    s_op->u.create.num_io_servers = s_op->req->u.create.num_dfiles_req;
    s_op->resp.u.create.datafile_handles = malloc(
                    sizeof(*s_op->resp.u.create.datafile_handles) *
                    s_op->u.create.num_io_servers);
    s_op->u.create.handle_array_local = malloc(
                    sizeof(*s_op->u.create.handle_array_local) *
                    s_op->u.create.num_io_servers);
    s_op->u.create.handle_array_remote = malloc(
                    sizeof(*s_op->u.create.handle_array_remote) *
                    s_op->u.create.num_io_servers);
    s_op->u.create.remote_io_servers = malloc(
                    sizeof(char*) *
                    s_op->u.create.num_io_servers);

    if(!s_op->resp.u.create.datafile_handles || 
        !s_op->u.create.handle_array_local ||
        !s_op->u.create.handle_array_remote ||
        !s_op->u.create.remote_io_servers)
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }

    /* gather list of servers to use, may include local server */
    ret = PINT_cached_config_get_server_list(s_op->req->u.create.fs_id,
                                         s_op->req->u.create.attr.u.meta.dist,
                                         s_op->req->u.create.num_dfiles_req,
                                         &s_op->req->u.create.layout,
                                         &s_op->u.create.io_servers,
                                         &s_op->u.create.num_io_servers);
    if(ret < 0)
    {
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    /* layout may have adjusted number of datafiles */
    s_op->req->u.create.attr.u.meta.dfile_count
                    = s_op->u.create.num_io_servers;
    s_op->resp.u.create.datafile_count 
                    = s_op->u.create.num_io_servers;
    for(i=0; i<s_op->u.create.num_io_servers; i++)
    {
        gossip_debug(GOSSIP_SERVER_DEBUG, "io_server %d: %s\n", 
                     i, s_op->u.create.io_servers[i]); 
    }

    s_op->resp.u.create.stuffed = 0;
    js_p->error_code = 0;
    return SM_ACTION_COMPLETE;
}

static int create_local_datafiles(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t tmp_id;
    PVFS_handle_extent_array data_handle_ext_array;
    server_configuration_s *config = get_server_config_struct();
    int i;
    int tmp_index = 0;

    if(s_op->resp.u.create.stuffed)
    {
        /* only one datafile, and it is local */
        s_op->u.create.handle_array_local_count = 1;
        s_op->u.create.handle_array_remote_count = 0;
    }
    else
    {
        /* figure out how many datafiles need to be local vs. remote */
        s_op->u.create.handle_array_local_count = 0;
        s_op->u.create.handle_array_remote_count = 0;
        for(i=0; i<s_op->u.create.num_io_servers; i++)
        {
            if(!strcmp(s_op->u.create.io_servers[i], config->host_id))
            {
                s_op->u.create.handle_array_local_count++;
            }
            else
            {
                s_op->u.create.handle_array_remote_count++;
                s_op->u.create.remote_io_servers[tmp_index] = 
                                    s_op->u.create.io_servers[i];
                tmp_index++;
            }
        }
    }

    gossip_debug(GOSSIP_SERVER_DEBUG, "creating %d local data files\n", 
                 s_op->u.create.handle_array_local_count);
    gossip_debug(GOSSIP_SERVER_DEBUG, "creating %d remote data files\n", 
                 s_op->u.create.handle_array_remote_count);

    if(s_op->u.create.handle_array_local_count == 0)
    {
        /* no local work to do */
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }

    /* find local extent array */
    ret = PINT_cached_config_get_server(s_op->req->u.create.fs_id,
                                        config->host_id,
                                        PINT_SERVER_TYPE_IO,
                                        &data_handle_ext_array);
    if(ret < 0)
    {
        js_p->error_code = ret;
        return(SM_ACTION_COMPLETE);
    }

    /* deliberately not setting SYNC flag, because both the attrs and
     * keyvals will be synced in later states
     */
    ret = job_trove_dspace_create_list(s_op->req->u.create.fs_id,
                                       &data_handle_ext_array,
                                       s_op->u.create.handle_array_local,
                                       s_op->u.create.handle_array_local_count,
                                       PVFS_TYPE_DATAFILE,
                                       NULL,
                                       0,
                                       smcb,
                                       0,
                                       js_p,
                                       &tmp_id,
                                       server_job_context,
                                       s_op->req->hints);

    return(ret);
}

static PINT_sm_action request_datafiles(struct PINT_smcb *smcb,
                                        job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;

    if(s_op->u.create.handle_array_remote_count == 0)
    {
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }

    ret = job_precreate_pool_get_handles(
                                    s_op->req->u.create.fs_id,
                                    s_op->u.create.handle_array_remote_count,
                                    PVFS_TYPE_DATAFILE,
                                    s_op->u.create.remote_io_servers,
                                    s_op->u.create.handle_array_remote,
                                    0,
                                    smcb,
                                    0,
                                    js_p,
                                    &j_id,
                                    server_job_context,
                                    s_op->req->hints);
    return ret;
}

static PINT_sm_action remove_metafile_object(struct PINT_smcb *smcb,
                                             job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;

    /* save the error code before we begin cleanup */
    if(!s_op->u.create.saved_error_code)
    {
        s_op->u.create.saved_error_code = js_p->error_code;
    }

    ret = job_trove_dspace_remove(s_op->req->u.create.fs_id,
                                  s_op->resp.u.create.metafile_handle,
                                  0,
                                  smcb,
                                  0,
                                  js_p,
                                  &j_id,
                                  server_job_context,
                                  s_op->req->hints);
    return ret;
}

static PINT_sm_action remove_local_datafile_handles(struct PINT_smcb *smcb,
                                                    job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;

    /* save the error code before we begin cleanup */
    if(!s_op->u.create.saved_error_code)
    {
        s_op->u.create.saved_error_code = js_p->error_code;
    }

    if(s_op->u.create.handle_array_local_count == 0)
    {
        /* nothing to do */
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }

    ret = job_trove_dspace_remove_list(s_op->req->u.create.fs_id,
                                  s_op->u.create.handle_array_local,
                                  NULL,
                                  s_op->u.create.handle_array_local_count,
                                  0,
                                  smcb,
                                  0,
                                  js_p,
                                  &j_id,
                                  server_job_context,
                                  s_op->req->hints);

    return ret;
}






static PINT_sm_action remove_local_replication_datahandles(
    struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret;
    job_id_t j_id;

    if (!s_op->u.create.saved_error_code)
    {
       s_op->u.create.saved_error_code = js_p->error_code;
    }

    js_p->error_code = 0;

    if (s_op->u.create.local_replication_handle_count == 0)
    {
       return SM_ACTION_COMPLETE;
    }

    ret = job_trove_dspace_remove_list(s_op->req->u.create.fs_id,
                                       s_op->u.create.local_replication_handles,
                                       NULL,
                                       s_op->u.create.local_replication_handle_count,
                                       0,
                                       smcb,
                                       0,
                                       js_p,
                                       &j_id,
                                       server_job_context,
                                       s_op->req->hints);    
    return ret;
}/* end remove_local_replication_datahandles */




static PINT_sm_action replace_remote_replication_datahandles(
    struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret;
    job_id_t j_id;
    PVFS_handle pool_handle=0;


    if (!s_op->u.create.saved_error_code)
    {
       s_op->u.create.saved_error_code = js_p->error_code;
    }

    js_p->error_code = 0;

    if (s_op->u.create.remote_replication_handle_count == 0)
    {
       js_p->error_code = REPLACE_DONE;
       return SM_ACTION_COMPLETE;
    }

    if (s_op->u.create.replication_servers_index < s_op->u.create.remote_replication_handle_count)
    {
       ret = job_precreate_pool_lookup_server(
               s_op->u.create.remote_replication_io_servers[s_op->u.create.replication_servers_index],
               PVFS_TYPE_DATAFILE,
               s_op->req->u.create.fs_id,
               &pool_handle);
       if (ret<0)
       {
          s_op->u.create.replication_servers_index++;
          js_p->error_code = ret;
          return SM_ACTION_COMPLETE;
       }

       /*return handle to pool*/
       ret = job_precreate_pool_fill(
               pool_handle,
               s_op->req->u.create.fs_id,
               &s_op->u.create.remote_replication_handles[s_op->u.create.replication_servers_index],
               1,
               smcb,
               0,
               js_p,
               &j_id,
               server_job_context,
               s_op->req->hints);

      s_op->u.create.replication_servers_index++;
      return ret;
    }
    else
    {
       /* all handles have been replaced */
       js_p->error_code = REPLACE_DONE;
       return SM_ACTION_COMPLETE;
    }

}/* end replace_remote_replication_datahandles */





static PINT_sm_action replace_remote_datafile_handles(
    struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;
    PVFS_handle pool_handle;

    /* save the error code before we begin cleanup */
    if(!s_op->u.create.saved_error_code)
    {
        s_op->u.create.saved_error_code = js_p->error_code;
    }

    if(s_op->u.create.handle_index < s_op->u.create.handle_array_remote_count)
    {
        /* find pool that this handle belongs to */
        ret = job_precreate_pool_lookup_server(
            s_op->u.create.remote_io_servers[s_op->u.create.handle_index],
            PVFS_TYPE_DATAFILE,
            s_op->req->u.create.fs_id,
            &pool_handle);
        if(ret < 0)
        {
            s_op->u.create.handle_index++;
            js_p->error_code = ret;
            return(SM_ACTION_COMPLETE);
        }

        /* return handle to pool */
        ret = job_precreate_pool_fill(
            pool_handle,
            s_op->req->u.create.fs_id,
            &s_op->u.create.handle_array_remote[s_op->u.create.handle_index],
            1,
            smcb,
            0,
            js_p,
            &j_id,
            server_job_context,
            s_op->req->hints);

        s_op->u.create.handle_index++;
        return(ret);
    }
    else
    {
        /* all handles have been replaced */
        js_p->error_code = REPLACE_DONE;
        return(SM_ACTION_COMPLETE);
    }
}

static PINT_sm_action remove_keyvals(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;

    /* save the error code before we begin cleanup */
    if(!s_op->u.create.saved_error_code)
    {
        s_op->u.create.saved_error_code = js_p->error_code;
    }

    s_op->error_a = calloc(s_op->keyval_count,sizeof(*s_op->error_a));
    if (!s_op->error_a)
    {
       gossip_lerr("Error allocating memory.\n");
       js_p->error_code = -PVFS_ENOMEM;
       return SM_ACTION_COMPLETE;
    }


    /* the keyval keys and vals should still be valid here */
    ret = job_trove_keyval_remove_list(s_op->req->u.create.fs_id,
                                       s_op->resp.u.create.metafile_handle,
                                       s_op->key_a,
                                       s_op->val_a,
                                       s_op->error_a,
                                       s_op->keyval_count,
                                       TROVE_SYNC,
                                       NULL,
                                       smcb,
                                       0,
                                       js_p,
                                       &j_id,
                                       server_job_context,
                                       s_op->req->hints);

    return ret;
}





static PINT_sm_action remove_replication_xattrs(struct PINT_smcb *smcb, 
                                                    job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret;
    job_id_t j_id;

    if (s_op->u.create.seteattr_nkey <= 0)
       /* no xattrs to remove */
       return SM_ACTION_COMPLETE;

    if (!s_op->u.create.saved_error_code)
    {
         s_op->u.create.saved_error_code = js_p->error_code;
    }

    js_p->error_code = 0;

    s_op->u.create.seteattr_error = calloc(s_op->u.create.seteattr_nkey,sizeof(*s_op->u.create.seteattr_error));
    if (!s_op->u.create.seteattr_error)
    {
       gossip_lerr("Error allocating memory.\n");
       return SM_ACTION_COMPLETE;
    }


    ret = job_trove_keyval_remove_list(s_op->req->u.create.fs_id,
                                       s_op->resp.u.create.metafile_handle,
                                       s_op->u.create.seteattr_key,
                                       s_op->u.create.seteattr_val,
                                       s_op->u.create.seteattr_error,
                                       s_op->u.create.seteattr_nkey,
                                       TROVE_SYNC,
                                       NULL,
                                       smcb,
                                       0,
                                       js_p,
                                       &j_id,
                                       server_job_context,
                                       NULL);

  
    return ret;

}/* end remove_replication_xattrs */





static PINT_sm_action setup_local_datafile_handles(struct PINT_smcb *smcb,
                                                   job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int i;
    int tmp_index = 0;
    server_configuration_s *config = get_server_config_struct();

    if(s_op->resp.u.create.stuffed)
    {
        s_op->resp.u.create.datafile_handles[0] = 
                        s_op->u.create.handle_array_local[0];
        js_p->error_code = 0;
        return(SM_ACTION_COMPLETE);
    }
    else
    {
        for(i=0; i<s_op->u.create.num_io_servers; i++)
        {
            /* find local server positions and set handles */
            if(!strcmp(s_op->u.create.io_servers[i], config->host_id))
            {
                s_op->resp.u.create.datafile_handles[i] = 
                                s_op->u.create.handle_array_local[tmp_index];
                tmp_index++;
            }
        }
    }

    return SM_ACTION_COMPLETE;
}

static PINT_sm_action write_keyvals(
    struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;
    int i;
    int tmp_index = 0;
    server_configuration_s *config = get_server_config_struct();
    char* tmpbuf;

    if(s_op->u.create.handle_array_remote_count)
    {
        for(i=0; i<s_op->u.create.num_io_servers; i++)
        {
            /* find remote server positions and set handles */
            if(strcmp(s_op->u.create.io_servers[i], config->host_id))
            {
                s_op->resp.u.create.datafile_handles[i] = 
                                s_op->u.create.handle_array_remote[tmp_index];
                tmp_index++;
            }
        }
    }

    /* start with 2 keyvals: the distribution and the datafile handles */
    s_op->keyval_count = 2;

    if(s_op->resp.u.create.stuffed)
    {
        /* also need to set the layout as a keyval */
        s_op->keyval_count+= 2;
    }

    s_op->key_a = malloc(sizeof(PVFS_ds_keyval) * s_op->keyval_count);
    if(!s_op->key_a)
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }
    memset(s_op->key_a,0,sizeof(PVFS_ds_keyval) * s_op->keyval_count);

    s_op->val_a = malloc(sizeof(PVFS_ds_keyval) * s_op->keyval_count);
    if(!s_op->val_a)
    {
        free(s_op->key_a);
        s_op->key_a = NULL;
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }
    memset(s_op->val_a, 0, sizeof(PVFS_ds_keyval) * s_op->keyval_count);

    s_op->key_a[0].buffer = Trove_Common_Keys[METAFILE_HANDLES_KEY].key;
    s_op->key_a[0].buffer_sz = Trove_Common_Keys[METAFILE_HANDLES_KEY].size;

    s_op->val_a[0].buffer = s_op->resp.u.create.datafile_handles;
    s_op->val_a[0].buffer_sz =
                    s_op->resp.u.create.datafile_count * sizeof(PVFS_handle);

    s_op->key_a[1].buffer = Trove_Common_Keys[METAFILE_DIST_KEY].key;
    s_op->key_a[1].buffer_sz = Trove_Common_Keys[METAFILE_DIST_KEY].size;

    s_op->val_a[1].buffer_sz = s_op->req->u.create.attr.u.meta.dist_size;
    s_op->val_a[1].buffer = malloc(s_op->val_a[1].buffer_sz);
    if(!s_op->val_a[1].buffer)
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }
    PINT_dist_encode(s_op->val_a[1].buffer,
                     s_op->req->u.create.attr.u.meta.dist);

    if(s_op->resp.u.create.stuffed)
    {
        s_op->key_a[2].buffer = Trove_Common_Keys[METAFILE_LAYOUT_KEY].key;
        s_op->key_a[2].buffer_sz = Trove_Common_Keys[METAFILE_LAYOUT_KEY].size;

        s_op->val_a[2].buffer = malloc(PVFS_REQ_LIMIT_LAYOUT);
        if(!s_op->val_a[2].buffer)
        {
            js_p->error_code = -PVFS_ENOMEM;
            return SM_ACTION_COMPLETE;
        }
        tmpbuf = s_op->val_a[2].buffer;
        encode_PVFS_sys_layout(&tmpbuf, &s_op->req->u.create.layout);

        s_op->val_a[2].buffer_sz = (tmpbuf - (char*)s_op->val_a[2].buffer);

        gossip_debug(GOSSIP_SERVER_DEBUG, 
            "create storing layout of size: %d\n", 
            s_op->val_a[2].buffer_sz);

        s_op->key_a[3].buffer = Trove_Common_Keys[NUM_DFILES_REQ_KEY].key;
        s_op->key_a[3].buffer_sz = Trove_Common_Keys[NUM_DFILES_REQ_KEY].size;

        gossip_debug(
            GOSSIP_SERVER_DEBUG, "create storing NUM_DFILES_REQ_KEY value of %d\n",
            s_op->req->u.create.num_dfiles_req);
        s_op->val_a[3].buffer = &s_op->req->u.create.num_dfiles_req;
        s_op->val_a[3].buffer_sz = sizeof(s_op->req->u.create.num_dfiles_req);
    }

    ret = job_trove_keyval_write_list(s_op->req->u.create.fs_id,
                                      s_op->resp.u.create.metafile_handle,
                                      s_op->key_a,
                                      s_op->val_a,
                                      s_op->keyval_count,
                                      TROVE_SYNC,
                                      NULL,
                                      smcb,
                                      0,
                                      js_p,
                                      &j_id,
                                      server_job_context,
                                      s_op->req->hints);
    return ret;
}

static PINT_sm_action setattr_setobj_attribs(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = -1;
    job_id_t j_id;
    PVFS_object_attr *a_p = NULL;
    PVFS_object_attr *dspace_a_p = NULL;
    PVFS_ds_attributes *ds_attr = NULL;
#ifdef ENABLE_SECURITY_CERT    
    PVFS_uid uid;
    PVFS_gid group_array[PVFS_REQ_LIMIT_GROUPS];
    uint32_t num_groups;
#endif

    dspace_a_p = &s_op->attr;
    a_p = &s_op->req->u.create.attr;

     /* 
      * Remember that mtime is versioned on disk! so convert it here..
      * It is better to do it here than change the PVFS_object_attr_overwrite_setable
      * macro, since there are many more users of it, I think.
      */
     if (a_p->mask & PVFS_ATTR_COMMON_MTIME_SET)
     {
         PVFS_time orig_mtime = a_p->mtime;
         a_p->mtime = PINT_util_mktime_version(orig_mtime);
         gossip_debug(GOSSIP_SETATTR_DEBUG, "setting version "
                 "to %llu\n\tmtime is %llu\n",
                 llu(a_p->mtime), llu(orig_mtime));
     }

     /*
        we have the attribs stored in the dspace, as well as the
        requested attribs to store.  overwrite the ones that are setable
        and specified by the mask value in the request; macro defined in
        pvfs2-storage.h
        */
     PVFS_object_attr_overwrite_setable(dspace_a_p, a_p);

#ifdef ENABLE_SECURITY_CERT
     /*                                                              
      * if owner info is missing, map from credential
      * note that user must have admin rights to set owner info
      * to another user (see perm_create() below)
      */
    num_groups = PVFS_REQ_LIMIT_GROUPS;

    ret = PINT_map_credential(&s_op->req->u.create.credential, &uid,
                              &num_groups, group_array);
    if (ret != 0)
    {
        js_p->error_code = ret;
        return SM_ACTION_COMPLETE;
    }

    dspace_a_p->owner = uid;
    dspace_a_p->group = group_array[0];
#endif

     gossip_debug(
         GOSSIP_SERVER_DEBUG,
         "[STUFFED CREATE]: WRITING attrs: [owner = %d, group = %d\n\t"
         "perms = %o, type = %d, atime = %llu, mtime = %llu\n\t"
         "ctime = %llu | dfile_count = %d | dist_size = %d]\n",
         dspace_a_p->owner, dspace_a_p->group, dspace_a_p->perms,
         dspace_a_p->objtype, llu(dspace_a_p->atime),
         llu(PINT_util_mkversion_time(dspace_a_p->mtime)), llu(dspace_a_p->ctime),
         (int)dspace_a_p->u.meta.dfile_count,
         (int)dspace_a_p->u.meta.dist_size);

     /* translate attrs to storage attr format */
     ds_attr = &(s_op->ds_attr);
     PVFS_object_attr_to_ds_attr(dspace_a_p, ds_attr);

     ret = job_trove_dspace_setattr(
         s_op->req->u.create.fs_id, s_op->resp.u.create.metafile_handle,
         ds_attr,
         TROVE_SYNC,
         smcb, 0, js_p, &j_id, server_job_context,
         s_op->req->hints);

     return ret;
}



static int check_for_replication( struct PINT_smcb *smcb, 
                                      job_status_s *js_p)
{
   struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
   uint32_t req_attr_mask = s_op->req->u.create.attr.mask;

   if (!s_op->u.create.saved_error_code)
   {
      s_op->u.create.saved_error_code = js_p->error_code;
   }

   js_p->error_code = 0;

   /* Replication is an invalid option if file stuffing is turned on and the file being created 
    * qualifies for file stuffing.  NOTE: a file does not qualify for file stuffing if the
    * metadata server is NOT also a data server.  
    */
   if ( !(req_attr_mask & PVFS_ATTR_META_REPLICATION) || s_op->resp.u.create.stuffed )
   {
       gossip_lerr("replication is off.\n");
       js_p->error_code = REPLICATION_IS_OFF;
   }

   return SM_ACTION_COMPLETE;
}/*end check_for_replication*/




static int get_local_replication_datahandles(struct PINT_smcb *smcb, 
                                                 job_status_s *js_p)
{
   struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
   uint32_t copies = s_op->req->u.create.replication_number_of_copies;
   const char ***replication_servers_2d = NULL;
   int servers_per_copy = s_op->u.create.num_io_servers;
   const char **io_servers = s_op->u.create.io_servers;

   const char **remote_array = NULL;

   PVFS_handle *local_dh_array = NULL;

   uint32_t local_array_size=0, remote_array_size=0;
            
   server_configuration_s *config = get_server_config_struct();

   int copy,server_num,i,j,ret;
   int replication_count=servers_per_copy*copies;

   job_id_t tmp_id;

   PVFS_handle_extent_array data_handle_ext_array;

   js_p->error_code = 0;


   /* Gather replication datahandles based on replication layout algorithm */
   switch( s_op->req->u.create.replication_layout.algorithm)
   {
      case PVFS_SYS_LAYOUT_ROUND_ROBIN :
      {
          /* Create a set of servers using round-robin algorithm.
           * NOTE:  this is a very simple approach using only the same set of servers
           * used for the primary datahandles.
           */

          /* create array[#-of-copies][list of servers per copy] */
          replication_servers_2d = calloc(copies,sizeof(char *));
          if (!replication_servers_2d)
          {
             gossip_lerr("Error allocating memory");
             js_p->error_code = -PVFS_ENOMEM;
             goto err_out;
          }

          for (i=0; i<copies; i++)
          {
              replication_servers_2d[i] = calloc(servers_per_copy,sizeof(char *));
              if ( !replication_servers_2d[i] )
              {
                 gossip_lerr("Error allocating memory");
                 js_p->error_code = -PVFS_ENOMEM;
                 goto err_out;
              }
          }


          /* load 2d array with the server names, in round-robin order */
          for (copy=0,server_num=1; copy<copies; copy++,server_num++)
          {
              for (i=0; i<servers_per_copy; i++)
              {
                replication_servers_2d[copy][i] = io_servers[ (server_num+i)%servers_per_copy ];
              }
          }

          gossip_err("printing the replication servers...\n");
          for (copy=0; copy<copies; copy++)
          {
             for (i=0; i<servers_per_copy; i++)
             {
                gossip_err("replication_servers[%d][%d]:%s.\n"
                          ,copy,i,replication_servers_2d[copy][i]);
             }
          }

          break;
      }
      default :
      {
          break;
      }
   }/*end switch*/

   /* Now that we have a set of replication servers, how many of each, local or remote, do we have. */
   for (copy=0; copy<copies; copy++)
   {
       for (i=0; i<servers_per_copy; i++)
       {
           if ( !strcmp(replication_servers_2d[copy][i], config->host_id) )
           {
              local_array_size++;
           }
           else
           {
              remote_array_size++;
           }
       }
   }

   local_dh_array = calloc(local_array_size,sizeof(*local_dh_array));
   remote_array   = calloc(remote_array_size,sizeof(*remote_array));

   if ( !remote_array || !local_dh_array)
   {
      gossip_lerr("Error allocating memeory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }

   /* load remote replication servers */
   for (copy=0,j=0; copy<copies; copy++)
   {
       for (i=0; i<servers_per_copy; i++)
       {
           if ( strcmp(replication_servers_2d[copy][i], config->host_id) )
           {
              remote_array[j++] = replication_servers_2d[copy][i];
           }
       }
   }

   gossip_err("Remote Array...\n");
   for (i=0; i<remote_array_size; i++)
   {
      gossip_err("remote_array[%d]:%s.\n",i,remote_array[i]);
   }

   /* save pertinent data to the frame */
   s_op->u.create.local_replication_handles       = local_dh_array;
   s_op->u.create.local_replication_handle_count  = local_array_size;
   s_op->u.create.remote_replication_io_servers   = remote_array;
   s_op->u.create.remote_replication_handle_count = remote_array_size;
   s_op->u.create.replication_servers_2d          = replication_servers_2d;
   s_op->u.create.replication_servers_count       = replication_count;
   s_op->u.create.replication_number_of_copies    = copies;

   /* Do we need any local data handles? */
   if ( local_array_size == 0 )
   {
      return SM_ACTION_COMPLETE;
   }

   /* find local extent array */
   ret = PINT_cached_config_get_server(s_op->req->u.create.fs_id,
                                       config->host_id,
                                       PINT_SERVER_TYPE_IO,
                                       &data_handle_ext_array);
   if (ret < 0)
   {
      js_p->error_code = ret;
      goto err_out;
   }


   /* call trove to get local data handles */
   ret = job_trove_dspace_create_list(s_op->req->u.create.fs_id,
                                      &data_handle_ext_array,
                                      local_dh_array,
                                      local_array_size,
                                      PVFS_TYPE_DATAFILE,
                                      NULL,
                                      0,
                                      smcb,
                                      0,
                                      js_p,
                                      &tmp_id,
                                      server_job_context,
                                      s_op->req->hints);
   return ret;

err_out:
   if (remote_array)
      free(remote_array);
   if (local_dh_array)
      free(local_dh_array);
   for (i=0; i<copies; i++)
   {
      if (replication_servers_2d[i])
         free(replication_servers_2d[i]);
   }
   if (replication_servers_2d)
      free(replication_servers_2d);

   return SM_ACTION_COMPLETE;
}/*end get_local_replication_datahandles*/




static int get_remote_replication_datahandles( struct PINT_smcb *smcb, 
                                               job_status_s *js_p)
{
   struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
   int ret = -1;
   job_id_t j_id;

   js_p->error_code = 0;

   if (s_op->u.create.remote_replication_handle_count == 0)
   {
      return SM_ACTION_COMPLETE;
   }

   /* allocate memory for remote-replication-handles */
   s_op->u.create.remote_replication_handles = calloc(s_op->u.create.remote_replication_handle_count
                                                     ,sizeof(*s_op->u.create.remote_replication_handles));
   if (!s_op->u.create.remote_replication_handles)
   {
      gossip_lerr("Error allocating memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      return SM_ACTION_COMPLETE;
   }


   /* get remote handles from the precreate pools */
   ret = job_precreate_pool_get_handles( s_op->req->u.create.fs_id,
                                         s_op->u.create.remote_replication_handle_count,
                                         PVFS_TYPE_DATAFILE,
                                         s_op->u.create.remote_replication_io_servers,
                                         s_op->u.create.remote_replication_handles,
                                         0,
                                         smcb,
                                         0,
                                         js_p,
                                         &j_id,
                                         server_job_context,
                                         s_op->req->hints);

   return ret;
}/* end get_remote_replication_datahandles */





static int write_replication_xattrs( struct PINT_smcb *smcb, 
                                         job_status_s *js_p)
{
   struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
   struct PVFS_server_req *req = s_op->req;

   struct PINT_server_op *xattr_s_op = NULL;
   struct PVFS_server_req *xattr_req = NULL;

   int key_count, rc, layout_size_index;
   PVFS_sys_layout *xattr_layout = NULL;

   enum misc request_location = LOCAL_OPERATION;

   PVFS_handle *local_handles = s_op->u.create.local_replication_handles;
   uint32_t local_count = s_op->u.create.local_replication_handle_count;

   PVFS_handle *remote_handles = s_op->u.create.remote_replication_handles;
   uint32_t remote_count = s_op->u.create.remote_replication_handle_count;

   /* this is the number of servers * the number of copies */
   uint32_t total_servers = s_op->u.create.replication_servers_count;

   /* this is the number of servers per copy */
   int servers_per_copy = s_op->u.create.num_io_servers;

   PVFS_handle *merged_handles = NULL;

   uint32_t copies = req->u.create.replication_number_of_copies;

   int i,j,k,copy;

   server_configuration_s *config = get_server_config_struct();

   const char ***replication_servers_2d = s_op->u.create.replication_servers_2d;


   js_p->error_code = 0;

   gossip_err("Local replication handles...\n");
   for (i=0; i<local_count; i++)
   {
      gossip_err("local_handles[%d]:%llu\n",i,llu(local_handles[i]));
   }
   gossip_err("Remote replication handles...\n");
   for (i=0; i<remote_count; i++)
   {
      gossip_err("remote_handles[%d]:%llu\n",i,llu(remote_handles[i]));
   }
   
   /* Create and prepare a new server frame in order to call set-eattr.sm */
   PINT_CREATE_SUBORDINATE_SERVER_FRAME( smcb
                                        ,xattr_s_op
                                        ,s_op->resp.u.create.metafile_handle
                                        ,s_op->req->u.create.fs_id
                                        ,request_location
                                        ,xattr_req
                                        ,LOCAL_XATTR
                                       );

   /* Fill in what we have of the set-eattr request. */
   PINT_SERVREQ_SETEATTR_FILL( *xattr_req
                              ,s_op->req->capability /* will not be checked */
                              ,s_op->req->u.create.fs_id
                              ,s_op->resp.u.create.metafile_handle
                              ,PVFS_XATTR_CREATE    /* Give error if values already exist. */
                              ,0    /* fill in number of keys below */
                              ,NULL /* fill in key array below */
                              ,NULL /* fill in val array below */
                              ,s_op->req->hints /* will not be checked */ 
                             );

   /* Allocate and populate the key/val pairs */
   xattr_req->u.seteattr.nkey = 6;
   key_count = 0;

   xattr_req->u.seteattr.key = calloc( xattr_req->u.seteattr.nkey, sizeof(*xattr_req->u.seteattr.key) );
   xattr_req->u.seteattr.val = calloc( xattr_req->u.seteattr.nkey, sizeof(*xattr_req->u.seteattr.val) );
   if ( !xattr_req->u.seteattr.key || !xattr_req->u.seteattr.val )
   {
      gossip_lerr("Unable to allocate memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }

   /* setup user.pvfs2.mirror.handles.  these are the replicated handles. */
   xattr_req->u.seteattr.key[key_count].buffer =    strdup(USER_PVFS2_MIRROR_HANDLES);
   xattr_req->u.seteattr.key[key_count].buffer_sz = sizeof(USER_PVFS2_MIRROR_HANDLES);


   xattr_req->u.seteattr.val[key_count].buffer = calloc(total_servers,sizeof(PVFS_handle));
   xattr_req->u.seteattr.val[key_count].buffer_sz = total_servers*sizeof(PVFS_handle);
   if ( !xattr_req->u.seteattr.key[key_count].buffer || !xattr_req->u.seteattr.val[key_count].buffer )
   {
       gossip_lerr("Unable to allocate memory.\n");
       js_p->error_code = -PVFS_ENOMEM;
       goto err_out;
   }

   /* Now, we have to merge the local and remote handle arrays based on the layout specified by the replication-servers */
   merged_handles = (PVFS_handle *)xattr_req->u.seteattr.val[key_count].buffer;
   for (copy=0,j=0,k=0; copy<copies; copy++)  
   {
       for (i=0; i<servers_per_copy; i++)
       {
           if ( !strcmp(replication_servers_2d[copy][i],config->host_id) )
           {
              gossip_err("Merging local handle into slot #%d...\n",(copy*servers_per_copy)+i);
              merged_handles[ (copy*servers_per_copy) + i ] = local_handles[j++];
           }
           else
           {
              gossip_err("Merging remote handle into slot #%d...\n",(copy*servers_per_copy)+i);
              merged_handles[ (copy*servers_per_copy) + i ] = remote_handles[k++];
           }
       }
   }

   /* save merged handles to frame */
   s_op->u.create.replication_handles_1d = merged_handles;
   gossip_err("s_op->u.create.replication_handles_1d : %p \t"
               "merged_handles : %p \t"
               "xattr_req->u.seteattr.val[key_count].buffer : %p\n"
               ,s_op->u.create.replication_handles_1d
               ,merged_handles
               ,xattr_req->u.seteattr.val[key_count].buffer);

   gossip_err("key[%d].buffer:%s \tsize:%d.\n",key_count,(char *)xattr_req->u.seteattr.key[key_count].buffer
                                               ,xattr_req->u.seteattr.key[key_count].buffer_sz);
   gossip_err("Buffer of handles...\n");
   for (i=0; i<total_servers; i++)
   {
       gossip_err("merged_handles[%d]:%llu\n",i,llu(merged_handles[i]));
       PVFS_handle tmp = ((PVFS_handle *)(xattr_req->u.seteattr.val[key_count].buffer))[i];
       gossip_err("val[%d].buffer[%d]:%llu\n",key_count,i,llu(tmp));
   }
   gossip_err("val[%d].buffer_sz:%d\n",key_count,xattr_req->u.seteattr.val[key_count].buffer_sz);


   key_count++;
   assert(key_count < xattr_req->u.seteattr.nkey);



   /* setup user.pvfs2.mirror.copies - the number of replicas to make. */
   xattr_req->u.seteattr.key[key_count].buffer = strdup(USER_PVFS2_MIRROR_COPIES);
   xattr_req->u.seteattr.key[key_count].buffer_sz = sizeof(USER_PVFS2_MIRROR_COPIES);
   xattr_req->u.seteattr.val[key_count].buffer = calloc(1,sizeof(req->u.create.replication_number_of_copies));
   xattr_req->u.seteattr.val[key_count].buffer_sz = sizeof(req->u.create.replication_number_of_copies);
   if ( !xattr_req->u.seteattr.key[key_count].buffer || !xattr_req->u.seteattr.val[key_count].buffer )
   {
      gossip_lerr("Unable to allocate memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }
   memcpy(xattr_req->u.seteattr.val[key_count].buffer, &req->u.create.replication_number_of_copies,
          sizeof(req->u.create.replication_number_of_copies));

   gossip_err("key[%d]:%s \tsize:%d\n",key_count
                                       ,(char *)xattr_req->u.seteattr.key[key_count].buffer
                                       ,xattr_req->u.seteattr.key[key_count].buffer_sz);
   gossip_err("val[%d]:%d \tsize:%d\n",key_count
                                       ,*(int *)xattr_req->u.seteattr.val[key_count].buffer
                                       ,xattr_req->u.seteattr.val[key_count].buffer_sz);

   key_count++;
   assert(key_count < xattr_req->u.seteattr.nkey);


   /* setup user.pvfs2.mirror.status - the status of each handle in the replication. */
   xattr_req->u.seteattr.key[key_count].buffer = strdup(USER_PVFS2_MIRROR_STATUS);
   xattr_req->u.seteattr.key[key_count].buffer_sz = sizeof(USER_PVFS2_MIRROR_STATUS);
   xattr_req->u.seteattr.val[key_count].buffer = calloc(total_servers,sizeof(uint64_t));
   xattr_req->u.seteattr.val[key_count].buffer_sz = total_servers*sizeof(uint64_t);
   if ( !xattr_req->u.seteattr.key[key_count].buffer || !xattr_req->u.seteattr.val[key_count].buffer )
   {
      gossip_lerr("Unable to allocate memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }

   gossip_err("key[%d]:%s \tsize:%d\n",key_count,(char *)xattr_req->u.seteattr.key[key_count].buffer
                                       ,xattr_req->u.seteattr.key[key_count].buffer_sz);
   

   key_count++;
   assert(key_count < xattr_req->u.seteattr.nkey);


   /* setup user.pvfs2.mirror.mode - set mode to MIRROR_ON_WRITE */
   xattr_req->u.seteattr.key[key_count].buffer = strdup(USER_PVFS2_MIRROR_MODE);
   xattr_req->u.seteattr.key[key_count].buffer_sz = sizeof(USER_PVFS2_MIRROR_MODE);
   xattr_req->u.seteattr.val[key_count].buffer = calloc(1,sizeof(MIRROR_ON_WRITE));
   xattr_req->u.seteattr.val[key_count].buffer_sz = sizeof(MIRROR_ON_WRITE);
   if ( !xattr_req->u.seteattr.key[key_count].buffer || !xattr_req->u.seteattr.val[key_count].buffer )
   {
      gossip_lerr("Unable to allocate memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }
   *(MIRROR_MODE *)xattr_req->u.seteattr.val[key_count].buffer = MIRROR_ON_WRITE;

   gossip_err("key[%d]:%s \tsize:%d\n",key_count,(char *)xattr_req->u.seteattr.key[key_count].buffer
                                       ,xattr_req->u.seteattr.key[key_count].buffer_sz);
   gossip_err("val[%d]:%d \tsize:%d\n",key_count,*(int *)xattr_req->u.seteattr.val[key_count].buffer
                                       ,xattr_req->u.seteattr.val[key_count].buffer_sz);

   key_count++;
   assert( key_count < xattr_req->u.seteattr.nkey);


   /* setup user.pvfs2.mirror.layout_size - this contains the total size of the layout stored 
    * in user.pvfs2.mirror.layout.  This size is needed to retrieve the layout.
    */
   xattr_req->u.seteattr.key[key_count].buffer = strdup(USER_PVFS2_MIRROR_LAYOUT_SIZE);
   xattr_req->u.seteattr.key[key_count].buffer_sz = sizeof(USER_PVFS2_MIRROR_LAYOUT_SIZE); 

   /* calculate the total size of the replication layout */
   rc = replication_calculate_layout_size( &(xattr_req->u.seteattr.val[key_count].buffer_sz)
                                          ,&(req->u.create.replication_layout)
                                         );
   if (rc)
   {
      gossip_lerr("Error calculating layout size for replication.\n");
      js_p->error_code = -PVFS_EINVAL;
      goto err_out;
   }
   
   xattr_req->u.seteattr.val[key_count].buffer = calloc(1,sizeof(xattr_req->u.seteattr.val[key_count].buffer_sz));
   if ( !xattr_req->u.seteattr.key[key_count].buffer || !xattr_req->u.seteattr.val[key_count].buffer)
   {
      gossip_lerr("Unable to allocate memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }

   memcpy(xattr_req->u.seteattr.val[key_count].buffer
         ,&xattr_req->u.seteattr.val[key_count].buffer_sz
         ,sizeof(xattr_req->u.seteattr.val[key_count].buffer_sz));

   gossip_err("key[%d]:%s \tsize:%d\n",key_count,(char *)xattr_req->u.seteattr.key[key_count].buffer
                                       ,xattr_req->u.seteattr.key[key_count].buffer_sz);

   gossip_err("val[%d]:%d \tsize:%lu\n",key_count
                                       ,*(int32_t *)xattr_req->u.seteattr.val[key_count].buffer
                                       ,sizeof(xattr_req->u.seteattr.val[key_count].buffer_sz));

   /* retain the index to user.pvfs2.mirror.layout_size */
   layout_size_index=key_count++;
   assert( key_count < xattr_req->u.seteattr.nkey);

   /* setup user.pvfs2.mirror.layout - this kev/val pair contains the layout information.
    */
   xattr_req->u.seteattr.key[key_count].buffer = strdup(USER_PVFS2_MIRROR_LAYOUT);
   xattr_req->u.seteattr.key[key_count].buffer_sz = sizeof(USER_PVFS2_MIRROR_LAYOUT);
   xattr_req->u.seteattr.val[key_count].buffer = calloc(1,xattr_req->u.seteattr.val[layout_size_index].buffer_sz); 
   xattr_req->u.seteattr.val[key_count].buffer_sz = xattr_req->u.seteattr.val[layout_size_index].buffer_sz;

   if ( !xattr_req->u.seteattr.key[key_count].buffer || !xattr_req->u.seteattr.val[key_count].buffer )
   {
      gossip_lerr("Unable to allocate memory.\n");
      js_p->error_code = -PVFS_ENOMEM;
      goto err_out;
   }

   /* this function assumes that memory for entire layout structure has already been allocated. */
   rc = replication_copy_layout( &(req->u.create.replication_layout)
                                ,xattr_req->u.seteattr.val[key_count].buffer
                               );

   xattr_layout=(PVFS_sys_layout *)xattr_req->u.seteattr.val[key_count].buffer;
   gossip_err("val[%d]:%s \tsize:%d\n",key_count
                                       ,(char *)xattr_req->u.seteattr.key[key_count].buffer
                                       ,xattr_req->u.seteattr.key[key_count].buffer_sz);
   gossip_err("val[%d]:%s \tsize:%d\n",key_count
                                       ,get_algorithm_string_value(xattr_layout->algorithm)
                                       ,xattr_req->u.seteattr.val[key_count].buffer_sz);
   
   print_sys_layout_structure( xattr_layout );


   return SM_ACTION_COMPLETE;

err_out:
   cleanup_keyval_pairs(&key_count,xattr_req->u.seteattr.key,xattr_req->u.seteattr.val,NULL);
   free(xattr_s_op);

   return SM_ACTION_COMPLETE;
}/*end write_replication_xattrs*/





static int analyze_replication_xattrs( struct PINT_smcb *smcb, 
                                           job_status_s *js_p)
{
   struct PINT_server_op *s_op       = PINT_sm_frame(smcb,PINT_FRAME_CURRENT)
                        ,*xattr_op   = NULL;
   struct PVFS_server_req *xattr_req = NULL;

   int task_id, error_code, remaining;

   /* js_p->error_code will be zero upon entering this function, so we must check error_code*/

   /* error_code will have the value returned in js_p->error_code via the
    * fast_seteattr_cleanup state in pvfs2_seteattr_fast_sm.
    */
   xattr_op = PINT_sm_pop_frame(smcb, &task_id, &error_code, &remaining);

   assert(xattr_op->req->op == PVFS_SERV_SETEATTR);

   xattr_req = xattr_op->req;

   /* zero error_code means the replication attributes were successfully set.
    * non-zero is a fatal error.
    */ 
   js_p->error_code = error_code; 

   /* save the key/val pairs in case we need to remove them later in a recovery step.
    * the "cleanup" state will deallocate the memory at the end of this state machine.
    */
   s_op->u.create.seteattr_nkey = xattr_req->u.seteattr.nkey;
   s_op->u.create.seteattr_key  = xattr_req->u.seteattr.key;
   s_op->u.create.seteattr_val  = xattr_req->u.seteattr.val;

   /* cleanup allocated memory from subordinate frame*/
   free(xattr_op); 

   /* populate create response with replication_handles */
   if ( error_code == 0 )
   {
      s_op->resp.u.create.total_number_of_replication_handles = s_op->u.create.replication_servers_count;
      s_op->resp.u.create.replication_handles = s_op->u.create.replication_handles_1d;
   }

  return SM_ACTION_COMPLETE;

}/*end analyze_replication_xattrs*/



static int setup_resp(
        struct PINT_smcb *smcb, job_status_s *js_p)
{    
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);

    if (js_p->error_code == 0)
    {
        PINT_ACCESS_DEBUG(s_op, GOSSIP_ACCESS_DEBUG,
                          "create: new metadata handle: %llu.\n",
                          llu(s_op->resp.u.create.metafile_handle));
    }
 
    return SM_ACTION_COMPLETE;
}

/*
 * Function: create_cleanup
 *
 * Params:   server_op *b, 
 *           job_status_s* js_p
 *
 * Pre:      None
 *
 * Post:     None
 *
 * Returns:  int
 *
 * Synopsis: free memory and return
 *           
 */
static int cleanup(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int i;

    /* cleanup metdata keyval pairs. 
     * NOTE: except for the pairs below, all other pairs used statically created 
     * strings instead of allocating new memory. 
     */
    for (i=0; i<s_op->keyval_count; i++)
    {
       if (i == 2 && s_op->val_a[2].buffer)
       {
          free(s_op->val_a[2].buffer);
       }

       if (i == 1 && s_op->val_a[1].buffer)
       {
          free(s_op->val_a[1].buffer);
       }
    }
    if (s_op->error_a)
    {
       free(s_op->error_a);
    }

    if(s_op->resp.u.create.datafile_handles)
    {
        free(s_op->resp.u.create.datafile_handles);
    }

    if(s_op->u.create.handle_array_remote)
    {
        free(s_op->u.create.handle_array_remote);
    }

    if(s_op->u.create.handle_array_local)
    {
        free(s_op->u.create.handle_array_local);
    }

    if(s_op->u.create.io_servers)
    {
        free(s_op->u.create.io_servers);
    }
    
    if(s_op->u.create.remote_io_servers)
    {
        free(s_op->u.create.remote_io_servers);
    }

    /* cleanup replication allocations */
    if (s_op->u.create.replication_number_of_copies > 0)
    {

       /* cleanup key/val pairs */
       cleanup_keyval_pairs(&s_op->u.create.seteattr_nkey, s_op->u.create.seteattr_key, s_op->u.create.seteattr_val,
                             s_op->u.create.seteattr_error);

       for (i=0; s_op->u.create.replication_servers_2d && i<s_op->u.create.replication_number_of_copies; i++)
       {
           if (s_op->u.create.replication_servers_2d[i])
              free(s_op->u.create.replication_servers_2d[i]);
       }
    
       if (s_op->u.create.replication_servers_2d)
          free(s_op->u.create.replication_servers_2d);

       /* replication_handles_1d is handled by cleanup_keyval_pairs */

       if (s_op->u.create.local_replication_handles)
          free(s_op->u.create.local_replication_handles);

       if (s_op->u.create.remote_replication_io_servers)
          free(s_op->u.create.remote_replication_io_servers);

       if (s_op->u.create.remote_replication_handles)
          free(s_op->u.create.remote_replication_handles);

    } /*end if replication*/


    return(server_state_machine_complete(smcb));
}


static inline void cleanup_keyval_pairs(int *nkey, PVFS_ds_keyval *key, PVFS_ds_keyval *val, int *error)
{
    int i;

    gossip_err("Executing cleanup_keyval_pairs...\n");

    /* no keyval pairs if nkey doesn't have a positive value. */
    if (*nkey <= 0)
    {
       return;
    }

    for (i=0; key && val && i<*nkey; i++)
    {
        gossip_err("i is %d.\n",i);
        if (key[i].buffer)
        {
           free(key[i].buffer);
        }
        if (val[i].buffer)
        {
           free(val[i].buffer);
        }
    }
       
    if (key)
    {
        free(key);
        key=NULL;
    }
    if (val)
    {
        free(val);
        key=NULL;
    }

    if (error)
    {
        free(error);
        error=NULL;
    }

    *nkey=0;

    return;
}/* end cleanup_keyval_pairs */


static inline int PINT_get_object_ref_create(
    struct PVFS_server_req *req, PVFS_fs_id *fs_id, PVFS_handle *handle)
{
    *fs_id = req->u.create.fs_id;
    *handle = PVFS_HANDLE_NULL;
    return 0;
};

PINT_GET_CREDENTIAL_DEFINE(create);

static int perm_create(PINT_server_op *s_op)
{
#if 0
    /*** code not needed -- see below ***/
    PVFS_object_attr *attr = &s_op->req->u.create.attr;
    PVFS_credential *cred = &s_op->req->u.create.credential;
    PVFS_uid uid;
    PVFS_gid group_array[PVFS_REQ_LIMIT_GROUPS];
    uint32_t num_groups = PVFS_REQ_LIMIT_GROUPS, i;
    int ret;
#endif

    if (!(s_op->req->capability.op_mask & PINT_CAP_CREATE))
    {
        return -PVFS_EACCES;
    }

#if 0
    /*** currently the owner/group is always loaded from 
         the credential, so this code isn't needed ***/
    /* check if allowed to create file with different owner/group */
    if (attr->mask & (PVFS_ATTR_COMMON_UID|PVFS_ATTR_COMMON_GID) &&
        !(s_op->req->capability.op_mask & PINT_CAP_ADMIN))
    {
        /* map the credential to the user info */
        ret = PINT_map_credential(cred, &uid, &num_groups, group_array);
        if (ret != 0)
        {
            return ret;
        }

        /* verify that the user has permission to change the file's owner */
        if (attr->mask & PVFS_ATTR_COMMON_UID)
        {
            if (uid != attr->owner)
            {
                return -PVFS_EPERM;
            }
        }

        /* verify that the user has permission to change the file's group */
        if (attr->mask & PVFS_ATTR_COMMON_GID)
        {
            for (i = 0; i < num_groups; i++)
            {
                if (group_array[i] == attr->group)
                {
                    break;
                }
            }
            /* no group matches */
            if (i >= num_groups)
            {
                return -PVFS_EPERM;
            }
        }
    }
#endif /* #if 0 */

    return 0;
}

struct PINT_server_req_params pvfs2_create_params =
{
    .string_name = "create",
    .get_object_ref = PINT_get_object_ref_create,
    .get_credential = PINT_get_credential_create,
    .perm = perm_create,
    .access_type = PINT_server_req_modify,
    .state_machine = &pvfs2_create_sm
};

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */
