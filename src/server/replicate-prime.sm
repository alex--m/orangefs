/* 
 * (C) 2001 Clemson University and The University of Chicago 
 *
 * See COPYING in top-level directory.
 */

/*
 *  PVFS2 server state machine for driving I/O operations (read and write).
 */

#include <string.h>
#include <assert.h>

#include "server-config.h"
#include "pvfs2-server.h"
#include "pvfs2-attr.h"
#include "pvfs2-request.h"
#include "pint-distribution.h"
#include "pint-request.h"
#include "pvfs2-internal.h"
#include "pint-cached-config.h"



enum
{
    NONE_CONTACTED_SUCCESSFULLY = 100,
    FLOWS_COMPLETED             = 200,
    PRIMARY_FLOW                = -1,
    NEXT_FLOW                   = 300
};


static int contact_replicate_comp_fn(void *v_p, struct PVFS_server_resp *resp_p, int i);

%%

machine pvfs2_replicate_prime_sm
{
    state prelude
    {
        jump pvfs2_prelude_sm;
        success => contact_replicate_servers;
        default => send_negative_ack_to_client;
    }

    state contact_replicate_servers
    {
        jump pvfs2_contact_replicate_servers_sm;
        success => send_positive_ack_to_client;
        default => send_negative_ack_to_client;
    }

    state send_positive_ack_to_client
    {
        run io_send_ack;
        success => start_flow;
        default => release;
    }

    state send_negative_ack_to_client
    {
        run io_send_ack;
        default => release;
    }

    state start_flow
    {
        run io_start_flow;
        default => check_for_completion;
    }

    state check_for_completion
    {
        run replicate_check_completion;
        FLOWS_COMPLETED => send_completion_ack_to_client;
        default => check_for_completion;
    }

    state send_completion_ack_to_client
    {
        run io_send_completion_ack;
        default => release;
    }

    state release
    {
        run io_release;
        default => cleanup;
    }

    state cleanup
    {
        run io_cleanup;
        default => terminate;
    }
}/*end machine pvfs2_replicate_sm*/


nested machine pvfs2_contact_replicate_servers_sm
{
    state setup_msgpairs
    {
        run contact_setup_msgpairs;
        default => xfer_msgpairs;
    }

    state xfer_msgpairs
    {
        jump pvfs2_msgpairarray_sm;
        default => set_status;
    }

    state set_status
    {
        run contact_set_status;
        success => start_recvs_for_completion_ack;
        default => return;
    }

    state start_recvs_for_completion_ack
    {
        /* a non-zero error_code from this state signifies that NONE of the BMI recv posts
         * were successful.  a ZERO error_code indicates that AT LEAST ONE  BMI recv post
         * was successful.
         */
        run contact_start_recvs;
        default => return;
    }

}/*end machine pvfs2_contact_replicate_servers_sm*/


%%

/*
 * Function: io_send_ack()
 *
 * Params:   server_op *s_op, 
 *           job_status_s* js_p
 *
 * Pre:      error code has been set in job status for us to
 *           report to client
 *
 * Post:     response has been sent to client
 *            
 * Returns:  int
 *
 * Synopsis: fills in a response to the I/O request, encodes it,
 *           and sends it to the client via BMI.  Note that it may
 *           send either positive or negative acknowledgements.
 *           
 */
static int io_send_ack(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    gossip_debug(GOSSIP_MIRROR_DEBUG,"Executing io_send_ack (io.sm)....\n");
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int i, err = -PVFS_EIO;
    job_id_t tmp_id;
    struct server_configuration_s *user_opts = get_server_config_struct();

    gossip_lerr("Replication Number of Copies (%d)\n",(int)s_op->req->u.io.replication_number_of_copies);
    for (i=0; i<s_op->req->u.io.replication_number_of_copies; i++)
        gossip_lerr("replication handle[%d]:(%llu)\n",i,llu(s_op->req->u.io.replication_handles[i]));   
    /* this is where we report the file size to the client before
     * starting the I/O transfer, or else report an error if we
     * failed to get the size, or failed for permission reasons
     */
    s_op->resp.status = js_p->error_code;
    if (s_op->resp.status == 0)
    {
       s_op->resp.u.io.bstream_size = s_op->ds_attr.u.datafile.b_size;
    }

    gossip_debug(GOSSIP_MIRROR_DEBUG,"\tbstream_size:%d\n"
                                    ,(int)s_op->resp.u.io.bstream_size);

    err = PINT_encode(&s_op->resp, PINT_ENCODE_RESP, &(s_op->encoded),
                      s_op->addr, s_op->decoded.enc_type);
    if (err < 0)
    {
        gossip_lerr("Server: IO SM: PINT_encode() failure.\n");
        js_p->error_code = err;
        return SM_ACTION_COMPLETE;
    }

    err = job_bmi_send_list(
        s_op->addr, s_op->encoded.buffer_list, s_op->encoded.size_list,
        s_op->encoded.list_count, s_op->encoded.total_size,
        s_op->tag, s_op->encoded.buffer_type, 0, smcb, 0, js_p,
        &tmp_id, server_job_context, user_opts->server_job_bmi_timeout,
        s_op->req->hints);

    return err;
}

/*
 * Function: io_start_flow()
 *
 * Params:   server_op *s_op, 
 *           job_status_s* js_p
 *
 * Pre:      all of the previous steps have succeeded, so that we
 *           are ready to actually perform the I/O
 *
 * Post:     I/O has been carried out
 *            
 * Returns:  int
 *
 * Synopsis: this is the most important part of the state machine.
 *           we setup the flow descriptor and post it in order to 
 *           carry out the data transfer
 *           
 */
static PINT_sm_action io_start_flow(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int err = -PVFS_EIO;
    job_id_t tmp_id;
    struct server_configuration_s *user_opts = get_server_config_struct();
    struct filesystem_configuration_s *fs_conf;
        
    s_op->u.io.flow_d = PINT_flow_alloc();
    if (!s_op->u.io.flow_d)
    {
        js_p->error_code = -PVFS_ENOMEM;
        return SM_ACTION_COMPLETE;
    }

    s_op->u.io.flow_d->hints = s_op->req->hints;

    /* we still have the file size stored in the response structure 
     * that we sent in the previous state, other details come from
     * request
     */
    s_op->u.io.flow_d->file_data.fsize = s_op->resp.u.io.bstream_size;
    s_op->u.io.flow_d->file_data.dist = s_op->req->u.io.io_dist;
    s_op->u.io.flow_d->file_data.server_nr = s_op->req->u.io.server_nr;
    s_op->u.io.flow_d->file_data.server_ct = s_op->req->u.io.server_ct;

    /* on writes, we allow the bstream to be extended at EOF */
    if (s_op->req->u.io.io_type == PVFS_IO_WRITE)
    {
        gossip_debug(GOSSIP_IO_DEBUG, "io_start_flow() issuing flow to "
                     "write data.\n");
        s_op->u.io.flow_d->file_data.extend_flag = 1;
    }
    else
    {
        gossip_debug(GOSSIP_IO_DEBUG, "io_start_flow() issuing flow to "
                     "read data.\n");
        s_op->u.io.flow_d->file_data.extend_flag = 0;
    }

    gossip_lerr("file_req_offset:%lld\n",(long long int)s_op->req->u.io.file_req_offset);
    s_op->u.io.flow_d->file_req = s_op->req->u.io.file_req;
    s_op->u.io.flow_d->file_req_offset = s_op->req->u.io.file_req_offset;
    s_op->u.io.flow_d->mem_req = NULL;
    s_op->u.io.flow_d->aggregate_size = s_op->req->u.io.aggregate_size;
    s_op->u.io.flow_d->tag = s_op->tag;
    
    s_op->u.io.flow_d->next_tag = s_op->u.io.replicate_d[0].session_tag;

    s_op->u.io.flow_d->user_ptr = NULL;
    s_op->u.io.flow_d->type = s_op->req->u.io.flow_type;
    s_op->u.io.flow_d->total_transferred = 0;

    fs_conf = PINT_config_find_fs_id(user_opts, 
                                     s_op->req->u.io.fs_id);
    if(fs_conf)
    {
        /* pick up any buffer settings overrides from fs conf */
        s_op->u.io.flow_d->buffer_size = fs_conf->fp_buffer_size;
        s_op->u.io.flow_d->buffers_per_flow = fs_conf->fp_buffers_per_flow;
    }

    gossip_debug(GOSSIP_IO_DEBUG, "flow: fsize: %lld, " 
        "server_nr: %d, server_ct: %d\n",
        lld(s_op->u.io.flow_d->file_data.fsize),
        (int)s_op->u.io.flow_d->file_data.server_nr,
        (int)s_op->u.io.flow_d->file_data.server_ct);

    gossip_debug(GOSSIP_IO_DEBUG, "      file_req_offset: %lld, "
        "aggregate_size: %lld, handle: %llu\n", 
        lld(s_op->u.io.flow_d->file_req_offset),
        lld(s_op->u.io.flow_d->aggregate_size),
        llu(s_op->req->u.io.handle));

    /* set endpoints depending on type of io requested */
    if (s_op->req->u.io.io_type == PVFS_IO_WRITE)
    {
        s_op->u.io.flow_d->src.endpoint_id = BMI_ENDPOINT;
        s_op->u.io.flow_d->src.u.bmi.address = s_op->addr;
        s_op->u.io.flow_d->dest.endpoint_id = TROVE_ENDPOINT;

        s_op->u.io.flow_d->next_dest.endpoint_id   = BMI_ENDPOINT;
        s_op->u.io.flow_d->next_dest.u.bmi.address = s_op->msgarray_op.msgarray[0].svr_addr;

        s_op->u.io.flow_d->dest.u.trove.handle = s_op->req->u.io.handle;
        s_op->u.io.flow_d->dest.u.trove.coll_id = s_op->req->u.io.fs_id;
    }
    else if (s_op->req->u.io.io_type == PVFS_IO_READ)
    {
        s_op->u.io.flow_d->src.endpoint_id = TROVE_ENDPOINT;
        s_op->u.io.flow_d->src.u.trove.handle = s_op->req->u.io.handle;
        s_op->u.io.flow_d->src.u.trove.coll_id = s_op->req->u.io.fs_id;
        s_op->u.io.flow_d->dest.endpoint_id = BMI_ENDPOINT;
        s_op->u.io.flow_d->dest.u.bmi.address = s_op->addr;
    }
    else
    {
        gossip_lerr("Server: IO SM: unknown IO type requested.\n");
        js_p->error_code = -PVFS_EINVAL;
        return SM_ACTION_COMPLETE;
    }

    gossip_debug(GOSSIP_IO_DEBUG,"\tabout to issue job_flow...\n");
    err = job_flow(s_op->u.io.flow_d, smcb, PRIMARY_FLOW, js_p, &tmp_id
                  ,server_job_context
                  ,user_opts->server_job_flow_timeout * s_op->req->u.io.replication_number_of_copies
                  ,s_op->req->hints);

    gossip_debug(GOSSIP_IO_DEBUG,"\treturn code from job_flow "
                                 "submission:%d\n"
                                ,err);

    return err;
}

/*
 * Function: io_release()
 *
 * Params:   server_op *b, 
 *           job_status_s* js_p
 *
 * Pre:      we are done with all steps necessary to service
 *           request
 *
 * Post:     operation has been released from the scheduler
 *
 * Returns:  int
 *
 * Synopsis: releases the operation from the scheduler
 */
static PINT_sm_action io_release(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int ret = 0;
    job_id_t i;

    /*
      tell the scheduler that we are done with this operation (if it
      was scheduled in the first place)
    */
    ret = job_req_sched_release(
        s_op->scheduled_id, smcb, 0, js_p, &i, server_job_context);
    return ret;
}

/*
 * Function: io_cleanup()
 *
 * Params:   server_op *b, 
 *           job_status_s* js_p
 *
 * Pre:      all jobs done, simply need to clean up
 *
 * Post:     everything is free
 *
 * Returns:  int
 *
 * Synopsis: free up any buffers associated with the operation,
 *           including any encoded or decoded protocol structures
 */
static PINT_sm_action io_cleanup(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    char status_string[64] = {0};

    PVFS_strerror_r(s_op->resp.status, status_string, 64);
    PINT_ACCESS_DEBUG(s_op, GOSSIP_ACCESS_DEBUG, "finish (%s)\n", status_string);

    if (s_op->u.io.flow_d)
    {
        PINT_flow_free(s_op->u.io.flow_d);
    }

    /* let go of our encoded response buffer, if we appear to have
     * made one
     */
    if (s_op->encoded.total_size)
    {
        PINT_encode_release(&s_op->encoded, PINT_ENCODE_RESP);
    }

    return(server_state_machine_complete(smcb));
}

/*
 * Function: io_send_completion_ack()
 *
 * Params:   server_op *s_op, 
 *           job_status_s* js_p
 *
 * Pre:      flow is completed so that we can report its status
 *
 * Post:     if this is a write, response has been sent to client
 *           if this is a read, do nothing
 *            
 * Returns:  int
 *
 * Synopsis: fills in a response to the I/O request, encodes it,
 *           and sends it to the client via BMI.  Note that it may
 *           send either positive or negative acknowledgements.
 *           
 */
static PINT_sm_action io_send_completion_ack(
        struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int i, err = -PVFS_EIO;
    job_id_t tmp_id;
    struct server_configuration_s *user_opts = get_server_config_struct();
    
    gossip_debug(GOSSIP_IO_DEBUG,"Executing io_send_completion_ack.\n");
    

    gossip_lerr("js_p->error_code:(%d)\n",js_p->error_code);


    /* we only send this trailing ack if we are working on a write
     * operation; otherwise just cut out early
     */
    if (s_op->req->u.io.io_type == PVFS_IO_READ)
    {
        js_p->error_code = 0;
        return SM_ACTION_COMPLETE;
    }

    /* release encoding of the first ack that we sent */
    PINT_encode_release(&s_op->encoded, PINT_ENCODE_RESP);

    /* zero size for safety */
    s_op->encoded.total_size = 0;

    /*
      fill in response -- status field is the only generic one we
      should have to set
    */
    s_op->resp.op = PVFS_SERV_WRITE_COMPLETION;  /* not IO */

    /* determine the status based on the primary flow with consideration
     * from the "next" flows.
     */

    gossip_lerr("Primary flow status:(%d)\n",s_op->u.io.primary_flow_error_code);
    gossip_lerr("Total Transferred(%lld)\n",(long long int)s_op->u.io.flow_d->total_transferred);
    for (i=0; i<s_op->u.io.replicate_d_count; i++)
    {
        gossip_err("Next flow(%llu) \tstatus(%d)\n",llu(s_op->u.io.replicate_d[i].handle)
                                           ,s_op->u.io.replicate_d[i].recv_status.error_code);
    }

    s_op->resp.status = s_op->u.io.primary_flow_error_code;
    s_op->resp.u.write_completion.total_completed =
        s_op->u.io.flow_d->total_transferred;

    err = PINT_encode(
        &s_op->resp, PINT_ENCODE_RESP, &(s_op->encoded),
        s_op->addr, s_op->decoded.enc_type);

    if (err < 0)
    {
        gossip_lerr("Server: IO SM: PINT_encode() failure.\n");
        js_p->error_code = err;
        return SM_ACTION_COMPLETE;
    }

    gossip_debug(GOSSIP_IO_DEBUG,"\ts_op->tag:%d\n",s_op->tag);

    err = job_bmi_send_list(
        s_op->addr, s_op->encoded.buffer_list, s_op->encoded.size_list,
        s_op->encoded.list_count, s_op->encoded.total_size, s_op->tag,
        s_op->encoded.buffer_type, 0, smcb, 0, js_p, &tmp_id,
        server_job_context, user_opts->server_job_bmi_timeout,
        s_op->req->hints);

    gossip_debug(GOSSIP_IO_DEBUG,"return code from sending ack:%d\n"
                                ,err);

    return err;
}

static PINT_sm_action contact_setup_msgpairs(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op                 = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    struct PVFS_server_req *replicate_prime_req = s_op->req;
    struct PVFS_servreq_io *io                  = &replicate_prime_req->u.io;
    PINT_sm_msgarray_op *msgarray_op            = &s_op->msgarray_op;
    PINT_sm_msgpair_state *msg_p;
    int ret,i;
 
//RAL TODO: What if one of the replicate servers is local?

    js_p->error_code = 0;

    /* create storage for the results of each msgpair */
    s_op->u.io.replicate_d = calloc(io->replication_number_of_copies,
                                    sizeof(*s_op->u.io.replicate_d));
    if (!s_op->u.io.replicate_d)
    {
       gossip_lerr("Error allocating memory for replicate_d.\n");
       js_p->error_code = -PVFS_ENOMEM;
       return SM_ACTION_COMPLETE;
    }
    s_op->u.io.replicate_d_count = io->replication_number_of_copies;

    /* initialize msgpairarray parameters */
    PINT_serv_init_msgarray_params( s_op, s_op->target_fs_id );
    
    /* initialize msgpair structures, one for each replicate server */
    ret = PINT_msgpairarray_init( msgarray_op, io->replication_number_of_copies );    
    if (ret)
    {
       gossip_lerr("Error initializing msgpairarray.\n");
       js_p->error_code = ret;
       return SM_ACTION_COMPLETE;
    }

    /* setup PVFS_SERV_REPLICATE_NEXT requests, one for each copy */
    for (i=0; i<msgarray_op->count; i++)
    {
        msg_p = &msgarray_op->msgarray[i];

        msg_p->fs_id      = s_op->target_fs_id;
        msg_p->handle     = io->replication_handles[i];
        msg_p->retry_flag = PVFS_MSGPAIR_RETRY;
        msg_p->comp_fn    = contact_replicate_comp_fn;
        
        ret=PINT_cached_config_map_to_server( &msg_p->svr_addr
                                             ,msg_p->handle
                                             ,s_op->target_fs_id);
        if (ret)
        {
           gossip_lerr("Error mapping handle(%llu) to BMI server address.\n",llu(msg_p->handle));
           js_p->error_code = ret;
           return SM_ACTION_COMPLETE;
        }

        /* pass along the data from PVFS_SERV_REPLICATE_PRIME request*/
        PINT_SERVREQ_REPLICATE_NEXT_FILL(*replicate_prime_req
                                         ,msg_p->req
                                         ,io->replication_handles[i]);

    }/*end for*/ 

    PINT_sm_push_frame(smcb,0,msgarray_op);

    gossip_lerr("Replication Number of Copies(%d).\n",(int)io->replication_number_of_copies);


    return SM_ACTION_COMPLETE;
}/*end contact_setup_msgpairs*/


static int contact_replicate_comp_fn(void *v_p, struct PVFS_server_resp *resp_p, int i)
{
    PINT_smcb *smcb = v_p;
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_MSGPAIR_PARENT_SM);
    PINT_sm_msgpair_state *msg_p = &s_op->msgarray_op.msgarray[i];

    /* Here, we will capture the response and session tag from the PVFS_SERV_REPLICATE_NEXT 
     * request.  The response pertains only to the inital ACK and start of the flow on
     * the replicate server.  We will retain the status from each response and then
     * check it when we return from msgpairarray.
     */

    /* store bstream size, status, and session tag. */

    gossip_lerr("Response %d of %d.\n",i,s_op->msgarray_op.count);
    gossip_lerr("Bstream size(%d) for handle(%llu)\n",(int)resp_p->u.io.bstream_size
                                                     ,llu(msg_p->handle));
    gossip_lerr("Response status (%d).\n",resp_p->status);
    gossip_lerr("Session tag (%d).\n",msg_p->session_tag);    
    
    s_op->u.io.replicate_d[i].resp_status = resp_p->status;
        s_op->u.io.replicate_d[i].session_tag  = msg_p->session_tag;
        s_op->u.io.replicate_d[i].svr_addr = msg_p->svr_addr;
    s_op->u.io.replicate_d[i].handle = msg_p->handle;
    if (resp_p->status==0)
    {
        s_op->u.io.replicate_d[i].bstream_size = resp_p->u.io.bstream_size;
    }

    resp_p->status=0;

    return (0);
}/*end contact_replicate_comp_fn*/


static PINT_sm_action contact_set_status(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int i;

    /* If we have at least ONE replicate server respond successfully, then 
     * we will continue normal processing.  If NONE of the replicate servers
     * respond successfully, then we have a CATASTROPHIC situation.
     */
    for (i=0; i<s_op->u.io.replicate_d_count; i++)
    {
        if (s_op->u.io.replicate_d[i].resp_status == 0)
        {
            js_p->error_code = 0;
            return SM_ACTION_COMPLETE;
        }
    }

    js_p->error_code = NONE_CONTACTED_SUCCESSFULLY;
   
    return SM_ACTION_COMPLETE;
}/*end contact_set_status*/





static PINT_sm_action contact_start_recvs(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    int max_resp_sz=0;
    struct server_configuration_s *server_opts = get_server_config_struct();
    struct filesystem_configuration_s *fs_config;
    int i, ret;


    fs_config = PINT_config_find_fs_id(server_opts,s_op->target_fs_id);

    max_resp_sz = PINT_encode_calc_max_size( PINT_ENCODE_RESP
                                            ,PVFS_SERV_WRITE_COMPLETION
                                            ,fs_config->encoding );
    js_p->error_code = 0;

    /* for each server that was contacted successfully, post a BMI RECV, which waits for an
     * acknowledgement that the flow completed or failed.
     */
    for (i=0; i<s_op->u.io.replicate_d_count && s_op->u.io.replicate_d[i].resp_status == 0; i++)
    {
        s_op->u.io.replicate_d[i].encoded_resp_p = BMI_memalloc( s_op->u.io.replicate_d[i].svr_addr
                                                                ,max_resp_sz
                                                                ,BMI_RECV );
        if (!s_op->u.io.replicate_d[i].encoded_resp_p)
        {
            gossip_lerr("Error allocating memory for encoded response.\n");
            js_p->error_code = -PVFS_ENOMEM;
            return SM_ACTION_COMPLETE;
        }
        ret = job_bmi_recv(s_op->u.io.replicate_d[i].svr_addr,
                           s_op->u.io.replicate_d[i].encoded_resp_p,
                           max_resp_sz,
                           s_op->u.io.replicate_d[i].session_tag,
                           BMI_PRE_ALLOC,
                           smcb,
                           NEXT_FLOW + i, /*the status_user_tag will identify the replicate server in our list*/
                           &s_op->u.io.replicate_d[i].recv_status,
                           &s_op->u.io.replicate_d[i].recv_job_id,
                           server_job_context,
                           server_opts->server_job_flow_timeout * s_op->req->u.io.replication_number_of_copies,
                           s_op->req->hints);
        if (ret == 1 && s_op->u.io.replicate_d[i].recv_status.error_code)
        {
           /* error posting job */
           js_p->error_code = s_op->u.io.replicate_d[i].recv_status.error_code;
           continue;;
        }
        else if (ret == 1)
        {
           /* immediate completion.  since we haven't started the flows yet, something is */
           /* wrong with this picture!                                                    */
           js_p->error_code = s_op->u.io.replicate_d[i].recv_status.error_code = -PVFS_EINVAL;
           continue;
        }
        else if (ret != 0)
        {
           /* error adding job to job mgr */
           js_p->error_code = s_op->u.io.replicate_d[i].recv_status.error_code = ret;
           continue;
        }
    }/*end for*/

    if (js_p->error_code == 0)
    {
       /* ALL bmi recvs posted successfully */
       return SM_ACTION_COMPLETE;
    } 
    else 
    {
       /* At least ONE bmi recv posted unsuccessfully.  Were there others that DID complete successfully? */
       /* If so, then continue on with its processing.                                                    */
       for (i=0; i<s_op->u.io.replicate_d_count && s_op->u.io.replicate_d[i].resp_status == 0; i++)
       {
           if ( s_op->u.io.replicate_d[i].recv_status.error_code == 0 )
           {
              js_p->error_code = 0;
              return SM_ACTION_COMPLETE;
           }
       }/*end for*/
    }/*end if*/

    return SM_ACTION_COMPLETE;
}/*end contact_start_recvs*/




static PINT_sm_action replicate_check_completion(struct PINT_smcb *smcb, job_status_s *js_p)
{
    struct PINT_server_op *s_op = PINT_sm_frame(smcb, PINT_FRAME_CURRENT);
    struct PINT_decoded_msg decoded_resp;
    struct PVFS_server_resp *resp;
    int index, ret;

    /* Which job just finished? */
    if (js_p->status_user_tag == PRIMARY_FLOW)
    {
       /* all "next" flows should be done and we are ready to ack back to the client */
       gossip_lerr("Primary flow has completed....\n");
       for (index=0; index<s_op->u.io.replicate_d_count && s_op->u.io.replicate_d[index].resp_status == 0; index++)
       {
           if ( !s_op->u.io.replicate_d[index].received )
           {
              gossip_lerr("Primary flow completed BEFORE next flows (%llu).\n"
                         ,llu(s_op->u.io.replicate_d[index].handle));
           }
       }
       s_op->u.io.primary_flow_error_code = js_p->error_code;
       js_p->error_code = FLOWS_COMPLETED;
       return SM_ACTION_COMPLETE;
    }
    else
    {
      /* we received an ack from a replicate server, indicating that the flow has completed */
      for (index=0; index<s_op->u.io.replicate_d_count && s_op->u.io.replicate_d[index].resp_status == 0; index++)
      {
          if ( (js_p->status_user_tag - NEXT_FLOW) == index)
          {
             /* we have identified the replicate server */
             s_op->u.io.replicate_d[index].recv_status = *js_p;
             s_op->u.io.replicate_d[index].received = 1;
             break;
          }
      }/*end for*/
    }/*end if*/
    

    /* decode repsonse from "next" server */
    ret = PINT_serv_decode_resp( s_op->target_fs_id
                                ,s_op->u.io.replicate_d[index].encoded_resp_p
                                ,&decoded_resp
                                ,&s_op->u.io.replicate_d[index].svr_addr
                                ,s_op->u.io.replicate_d[index].recv_status.actual_size
                                ,&resp );
    if (ret != 0)
    {
       gossip_lerr("Error decoding resp from NEXT server for handle (%llu).\n"
                  ,llu(s_op->u.io.replicate_d[index].handle));
       PVFS_perror_gossip("replicate-prime decoding error",ret);
       s_op->u.io.replicate_d[index].recv_status.error_code = ret;       
    }

    if (resp->status != 0)
    {
       s_op->u.io.replicate_d[index].recv_status.error_code = resp->status;
       PVFS_perror_gossip("Replicate-prime received an error from replicate-next.\n",resp->status);
    }

    gossip_lerr("Completion ACK returned from NEXT server for handle(%llu).\n"
               ,llu(s_op->u.io.replicate_d[index].handle));
    gossip_err("Amount of data transferred(%lld).\n",(long long int)resp->u.write_completion.total_completed);


    /* not sure if this is necessary; check on it */
    PINT_decode_release(&decoded_resp, PINT_ENCODE_RESP);


   js_p->error_code = 0;
   return SM_ACTION_DEFERRED;
}/*end replicate_check_completion*/




static int perm_io(PINT_server_op *s_op)
{
    int ret = -PVFS_EINVAL;
    int mask = 0;
    enum PVFS_io_type type = s_op->req->u.io.io_type;

    if (type == PVFS_IO_READ)
    {
        mask = PINT_CAP_READ;
    }
    else if (type == PVFS_IO_WRITE)
    {
        mask = PINT_CAP_WRITE;
    }

    if (s_op->req->capability.op_mask & mask)
    {
        ret = 0;
    }
    else
    {
        ret = -PVFS_EACCES;
    }

    return ret;
}

static enum PINT_server_req_access_type PINT_server_req_access_io(
    struct PVFS_server_req *req)
{
    if(req->u.io.io_type == PVFS_IO_READ)
    {
        return PINT_SERVER_REQ_READONLY;
    }
    return PINT_SERVER_REQ_MODIFY;
}

PINT_GET_OBJECT_REF_DEFINE(io);

struct PINT_server_req_params pvfs2_replicate_prime_params =
{
    .string_name = "replicate-prime",
    .perm = perm_io,
    .access_type = PINT_server_req_access_io,
    .sched_policy = PINT_SERVER_REQ_SCHEDULE,
    .get_object_ref = PINT_get_object_ref_io,
    .state_machine = &pvfs2_replicate_prime_sm
};

/*
 * Local variables:
 *  mode: c
 *  c-indent-level: 4
 *  c-basic-offset: 4
 * End:
 *
 * vim: ft=c ts=8 sts=4 sw=4 expandtab
 */
