General (critical)
-----------------------

Implement a list i/o compatibility layer in top level bmi code.  If a
module does not implement list functionality, then the behavior should
be emulated somehow (naive approach is to just pack buffers).

Implement unpost() function for cancelling operations: 
http://www.beowulf-underground.org/pipermail/pvfs2-internal/2002-April/000060.html

Add a hint that indicates when a bmi address is "ok to get rid of".
This would set a bit on the address interally and allow us to do things
like close sockets when we start running into resource limits.  This bit
would get cleared any time we use the address, and the hint doesn't
necessarily take any action right away.

Make sure that an overall pvfs2 error encoding scheme solidifies,
and adopt it in the BMI code.  Right now the error handling in BMI
is inconsisent and relies on using -errno for error codes even
when it does do the right thing.

Update GM module to level of TCP module.  The option to build it
was removed from configure.in on Jan 3, 2002 because overall BMI
changes needed to be made and we don't have the time or test
platform to propigate the changes to GM at the moment.  So far,
the changes needed to GM will be removal of expected_size field in
sends and the addition of a timeout parameter to the wait
functions.
- note: when we remove the expected_size field in GM, we have to
  be able to cancel rendezvous receives because there won't be any
  way to determine if an eager send matches an eager or rend.
  receive.

General (portability)
-----------------------

Get rid of dynamic array declarations that are all over the BMI
code!  This is a stupid hack that only gcc allows.

Try building with some different compilers (at least gcc 3.2).

Replace void* type for memory regions with PVFS_byte or BMI_byte
types.  Audit code to make sure that buffers are indexed like
this: (type)((BMI_byte)buffer + offset)

Fix the linking of the gm module code; right now it requires that libgm.a
be copied into the bmi/bmi_gm directory for it to work right.  It
is also using gcc/ld specific linking flags.

General (non critical)
-----------------------

do a better implementation of the testsome and testunexpected
functions, so that they are more clever about multiplexing between
multiple modules and splitting up the max_idle_time (right now
each module is called once with 1/n idle time)

come up with some decent defaults for BMI timeouts and give them
symbolic names to use throughout the pvfs2 code

replace the use of llist in the reference list with quicklist

we can probably redo op_list_search as a simpler function - I'm not sure
we need so much flexibility any more, so maybe we can skip passing
a whole key into search.

Consider adding _optional_ argument checking code, in particular look
for stuff like sum of size_list == size in list calls, size >
expected size, etc.

Document what stuff in the method_op structure must be filled in by
methods for correct BMI operation, and what is just there for convenience

consider using a special return value from testsome and waitsome to
indicate if any ops completed in error.  That way if zero is returned,
there is no need to check status of every op.
- UPDATE: actually we should make sure the semantics of this match
  trove as well - not settled yet.

Audit code to verify that if errors happen at post_send() or
post_recv() time that they get propigated out at test() time.
Otherwise we may lose error code information.

Clean up hash table used in bmi_tcp method and apply it to the
bmi_gm method also.

Optimize the locking, etc. so that we are more efficient in multi
threaded environments.  For now we just grab one massive lock at
the top of each API call.

Implement some fairness in BMI_waitunexpected and BMI_testunexpected.
The current implementation would allow starvation if a faster module is
busy enough.

Clean up names of structs and struct typedefs?  Should there be some
sort of convention here?  (this is really a global PVFS2 problem)

Implement a mechanism for throttling the amount of eager or unexpected
messages that a method is allowed to receive at a time.  Right now one
could stream a huge number of such messages to use up memory buffers
on a system if the receiver was not posting receives or checking for
unexpected messages fast enough.

TCP module:
-----------------------

Do something better than the "enqueue_operation" function - it's
list of arguments has gotten out of hand, I think...

Audit code and check for EINTR on _all_ system calls.  This was burning
me on a poll() call recently.

Note what behavior is for segments now (never send more than one
segment at a time per test in list calls).  This should be
optimized later (see below).

Come back later and implement send list and recv list optimization
of using readv and writev.  Probably requires checking buffer
space on socket before calling to avoid handling partical
completion of list stuff on nonblocking socket (maybe use blocking
readv or writev if buffers big enough, would avoid nasty cleanup
and probably not really block)

Do something about extra mallocs at beginning of post_send and
post_recv.

Look over places where error_code is set; try to pass more information
out when system calls fail.  This is really blocking on the
definition of a consistent PVFS2 error scheme, though.

There are more oportunities for immediate completion on receives
(specifically, look at the end of tcp_post_recv_rend() when we add to the
completion queue, and the bottom of tcp_post_recv_eager()).
We should try to immediately complete towards the end of
post_recv_rend also (see TODO in comments).

The tcp module does a terrible job of detecting closed sockets.
Fix it :)

Redo tcp_do_work_recv().  It is huge.

Duh.  The tcp_msg_header, of all things, should have a magic
number.  We need to check this before routing recv operations, notably
in tcp_do_work_recv() function.

The data reception portions of tcp_post_recv_eager and
tcp_post_recv_rend could be shared (maybe a separate function also used
within poll?).

Think of a way to make polling fairer so it doesn't favor certain
sockets.

Implement better fd management in the TCP module.  It should detect when
we are running out of sockets and make efforts to free some up as
needed.  We already have the means to reconnect if needed- we could scan
after operations are taken out of the completion queue to look for
sockets to close without too much difficulty now.  It would rely on a
hint (see ideas at top of this file) from the caller, however, to know
when it is safe to kill sockets.
(look at code from pvfs1:)

	if (getrlimit(RLIMIT_NOFILE, &lim) < 0) {
		/* not something to die over */
		LOG("notice: could not discover maximum # of fds.  continuing.\n");
		my_nofile = -1;
	}
	else {
		my_nofile = lim.rlim_cur;
		LOG1("open file limit is %d\n", my_nofile);
	}

GM module:
-----------------------

Implement BMI_CHECK_MAXSIZE get_info() option.

Make sure that GM can handle 0 byte messages; the flow code may trigger
these occasionally.

Look into possibility of using lookaside list for method_op
allocation.

Consider doing a malloc() followed by register as opposed to
dma_malloc() for control buffers- this would be more space efficient and
would only slow down initialization, not communication (see GM
FAQ).

There is a segfault in the gm method if initialization does not succeed.
The easiest way to trigger it is to run test_bmi_client_gm while
test_bmi_server_gm is running on the same machine.

Look at mpich-gm (gmpriv.c) and the way that send callbacks are used.
It looks like (in some cases) that sends are considered completed after
posting, rather than waiting for callback.  This would explain some of
the mpi gm client bandwidth (for small messages).

Look into the following projects on top of GM: via, sockets, and opiom

Need to handle erroneous messages in recv cycle (what if not peer, for
example?).

Eventually need to make the GM method capable of using different ports
so that more than one BMI application can run per node.  Probably
best if we automatically chose ports, like the GM sockets and
mpich code does now.

Settle on the best gm xfer method and make it the default in
autoconf.

Benchmarking:
-----------------------

Fix the stupid buffer verification.  It fails sometimes for MPI and
sometimes for BMI when I run this test:
mpirun -np 16
/home/pcarns/working/pvfs2/src/io/bmi/benchmark/driver_bw_multi -m
bmi_tcp -l 100000 -t 10000000 -s 8
It's always off by 34816 in the middle of a message...
for now I am just commenting out the buffer verification.

Figure out why aggregate bandwidth appears to be dropping off as go
from 2 clients and 2 servers to 3 clients and 3 servers.  is the
calculation correct?

Remember to compile out gossip and turn off locking when doing
serious BMI benchmarking.

Look at difference between using test and wait calls in
benchmarks.

Maybe measure impact of immediate completion (turn on and off).

Try altering post order in latency benchmark to see if that makes
any difference.

Try writing bw benchmark that doesn't post all at once before
doing any testing.

Try playing with socket buffer sizes, at least to demonstrate that
this is something we should work on later.

Measure the impact of interleaving buffers.

Consider forcing an ack after streaming data rather than just
measuring time on one side.

Try removing tcp option calls to see if they impact performance 
(could all benches- especially latency).

Remember to look at the recv mode option to mpich-gm:
	./mpirun.ch_gm --recv-mode polling -np 4 foo.x
	./mpirun.ch_gm --recv-mode blocking -np 4 foo.x
	./mpirun.ch_gm --recv-mode hybrid -np 4 foo.x

