Index: src/io/trove/trove-dbpf/dbpf-bstream-aio.c
===================================================================
RCS file: /projects/cvsroot/pvfs2/src/io/trove/trove-dbpf/dbpf-bstream-aio.c,v
retrieving revision 1.24.6.5
retrieving revision 1.24.6.7
diff -r1.24.6.5 -r1.24.6.7
6a7
> #ifdef __PVFS2_USE_AIO__
15,16d15
< #ifdef __PVFS2_USE_AIO__
< 
31,43c30,33
< int dbpf_bstream_listio_convert(
<                 int fd,
<                 int op_type,
<                 char **mem_offset_array,
<                 TROVE_size *mem_size_array,
<                 int mem_count,
<                 TROVE_offset *stream_offset_array,
<                 TROVE_size *stream_size_array,
<                 int stream_count,
<                 struct aiocb *aiocb_array,
<                 int *aiocb_count,
<                 struct bstream_listio_state *lio_state
<                 );
---
> /**
>  * Init new aio callback structure
>  */
> static int dbpf_bstream_aiocb_init(struct aiocb ** new_aiocb_p);
52a43,95
> static int dbpf_bstream_listio_convert(
>     int fd,
>     int op_type,
>     char **mem_offset_array,
>     TROVE_size *mem_size_array,
>     int mem_count,
>     TROVE_offset *stream_offset_array,
>     TROVE_size *stream_size_array,
>     int stream_count,
>     struct aiocb *aiocb_array,
>     int *aiocb_count,
>     struct bstream_listio_state *lio_state);
> 
> /**
>  * Issue or delay the queued operation.  If the AIO operations currently
>  * in progress are less than the max (dbpf_ios_in_progress_max), the
>  * operation is posted (call lio_listio), otherwise, put the operation
>  * back on the dbpf op queue.
>  */
> static int dbpf_bstream_aio_issue_or_delay(
>     dbpf_queued_op_t * cur_op,
>     struct aiocb **aiocb_ptr_array,
>     int aiocb_inuse_count,
>     struct sigevent *sig,
>     int dec_first);
> 
> /**
>  * If we haven't reached max number of IO operations, we post the
>  * next IO from the dbpf op queue.
>  */
> static void dbpf_bstream_aio_start_delayed(void);
> 
> /**
>  * Setup and post the next AIO operation for the given dbpf queued op
>  */
> static int dbpf_bstream_aio_setup_next_op(dbpf_queued_op_t * q_op_p,
>                                           struct aiocb * aiocb_p);
> 
> /**
>  * Check the progress of current AIO operations.  This uses
>  * the aio_error and aio_return functions to check progress.
>  * This function takes a dbpf_op and only checks the progress
>  * of AIO operations associated with that op.
>  */
> static int dbpf_bstream_aio_check_progress(struct dbpf_op * op_p);
> 
> /**
>  * Finish does a sync of the AIO write operation
>  * (if this is a write operation), returns the open
>  * file handle to the open cache and starts any other delayed
>  * operations.
>  */
> static int dbpf_bstream_aio_finish(struct dbpf_op * op_p);
58c101
< #define DBPF_MAX_IOS_IN_PROGRESS  16
---
> static int s_dbpf_ios_in_progress_max = 512;
60,61d102
< static gen_mutex_t s_dbpf_io_mutex = GEN_MUTEX_INITIALIZER;
< dbpf_op_queue_s  s_dbpf_io_ready_queue;
63,70c104,115
< static int issue_or_delay_io_operation(
<     dbpf_queued_op_t * cur_op,
<     struct aiocb **aiocb_ptr_array,
<     int aiocb_inuse_count,
<     struct sigevent *sig,
<     int dec_first);
< static void start_delayed_ops_if_any(
<     int dec_first);
---
> int dbpf_bstream_aio_set_max_progress(int progress_max)
> {
>     s_dbpf_ios_in_progress_max = progress_max;
>     return 0;
> }
> 
> static char *list_proc_state_strings[] = {
>     "LIST_PROC_INITIALIZED",
>     "LIST_PROC_INPROGRESS ",
>     "LIST_PROC_ALLCONVERTED",
>     "LIST_PROC_ALLPOSTED",
> };
104a150
> extern pthread_cond_t dbpf_op_completed_cond;
109,115d154
< static char *list_proc_state_strings[] = {
<     "LIST_PROC_INITIALIZED",
<     "LIST_PROC_INPROGRESS ",
<     "LIST_PROC_ALLCONVERTED",
<     "LIST_PROC_ALLPOSTED",
< };
< 
140,145c179,180
<     /*
<        we should iterate through the ops here to determine the
<        error/return value of the op based on individual request
<        error/return values.  they're ignored for now, however.
<      */
<     for (i = 0; i < op_p->u.b_rw_list.aiocb_array_count; i++)
---
>     ret = dbpf_bstream_aio_check_progress(op_p);
>     if(ret < 0)
147,179c182
<         if (aiocb_p[i].aio_lio_opcode == LIO_NOP)
<         {
<             continue;
<         }
< 
<         /* aio_error gets the "errno" value of the individual op */
<         ret = aio_error(&aiocb_p[i]);
<         if (ret == 0)
<         {
<             /* aio_return gets the return value of the individual op */
<             ret = aio_return(&aiocb_p[i]);
< 
<             gossip_debug(GOSSIP_TROVE_DEBUG, "%s: %s complete: "
<                          "aio_return() says %d [fd = %d]\n",
<                          __func__,
<                          ((op_p->type == BSTREAM_WRITE_LIST) ||
<                           (op_p->type == BSTREAM_WRITE_AT) ?
<                           "WRITE" : "READ"), ret, op_p->u.b_rw_list.fd);
< 
<             *(op_p->u.b_rw_list.out_size_p) += ret;
< 
<             /* mark as a NOP so we ignore it from now on */
<             aiocb_p[i].aio_lio_opcode = LIO_NOP;
<         }
<         else
<         {
<             gossip_debug(GOSSIP_TROVE_DEBUG, "error %d (%s) from "
<                          "aio_error/aio_return on block %d; "
<                          "skipping\n", ret, strerror(ret), i);
< 
<             ret = -trove_errno_to_trove_error(ret);
<             goto final_threaded_aio_cleanup;
<         }
---
>         dbpf_bstream_aio_finish(op_p);
186,200c189
<       final_threaded_aio_cleanup:
<         if ((op_p->type == BSTREAM_WRITE_AT) ||
<             (op_p->type == BSTREAM_WRITE_LIST))
<         {
<             DBPF_AIO_SYNC_IF_NECESSARY(op_p, op_p->u.b_rw_list.fd, ret);
<         }
< 
<         dbpf_open_cache_put(&op_p->u.b_rw_list.open_ref);
<         op_p->u.b_rw_list.fd = -1;
< 
<         gossip_debug(GOSSIP_TROVE_DEBUG, "*** starting delayed ops if any "
<                      "(state is %s)\n",
<                      list_proc_state_strings[op_p->u.b_rw_list.
<                                              list_proc_state]);
< 
---
>         dbpf_bstream_aio_finish(op_p);
205,206c194
< 
<         start_delayed_ops_if_any(1);
---
>         dbpf_bstream_aio_start_delayed();
215,237d202
<         /* no operations in progress; convert and post some more */
<         op_p->u.b_rw_list.aiocb_array_count = AIOCB_ARRAY_SZ;
<         op_p->u.b_rw_list.aiocb_array = aiocb_p;
< 
<         /* convert listio arguments into aiocb structures */
<         aiocb_inuse_count = op_p->u.b_rw_list.aiocb_array_count;
<         ret = dbpf_bstream_listio_convert(op_p->u.b_rw_list.fd,
<                                           op_p->u.b_rw_list.opcode,
<                                           op_p->u.b_rw_list.mem_offset_array,
<                                           op_p->u.b_rw_list.mem_size_array,
<                                           op_p->u.b_rw_list.mem_array_count,
<                                           op_p->u.b_rw_list.stream_offset_array,
<                                           op_p->u.b_rw_list.stream_size_array,
<                                           op_p->u.b_rw_list.stream_array_count,
<                                           aiocb_p,
<                                           &aiocb_inuse_count,
<                                           &op_p->u.b_rw_list.lio_state);
< 
<         if (ret == 1)
<         {
<             op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLCONVERTED;
<         }
< 
244,268c209,211
<         /* mark the unused with LIO_NOPs */
<         for (i = aiocb_inuse_count;
<              i < op_p->u.b_rw_list.aiocb_array_count; i++)
<         {
<             /* mark these as NOPs and we'll ignore them */
<             aiocb_p[i].aio_lio_opcode = LIO_NOP;
<         }
< 
<         for (i = 0; i < aiocb_inuse_count; i++)
<         {
<             aiocb_ptr_array[i] = &aiocb_p[i];
<         }
< 
<         assert(cur_op == op_p->u.b_rw_list.sigev.sigev_value.sival_ptr);
< 
<         if (op_p->u.b_rw_list.list_proc_state == LIST_PROC_ALLCONVERTED)
<         {
<             op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLPOSTED;
<         }
< 
<         ret =
<             issue_or_delay_io_operation(cur_op, aiocb_ptr_array,
<                                         aiocb_inuse_count,
<                                         &op_p->u.b_rw_list.sigev, 1);
< 
---
>         /* no operations in progress; convert and post some more */
>         dbpf_bstream_aio_setup_next_op(
>             op_p->u.b_rw_list.queued_op_ptr, aiocb_p);
271c214
<             gossip_lerr("issue_or_delay_io_operation() returned " "%d\n", ret);
---
>             gossip_lerr("dbpf_bstream_setup_next_op() returned " "%d\n", ret);
277,278c220
< static void start_delayed_ops_if_any(
<     int dec_first)
---
> static void dbpf_bstream_aio_start_delayed(void)
285,289c227
<     gen_mutex_lock(& s_dbpf_io_mutex);
<     if (dec_first)
<     {
<         s_dbpf_ios_in_progress--;
<     }
---
>     gen_mutex_lock(&dbpf_op_queue_mutex[OP_QUEUE_IO]);
293c231
<     assert(& s_dbpf_io_ready_queue);
---
>     assert(& dbpf_op_queue[OP_QUEUE_IO]);
295c233
<     if (!dbpf_op_queue_empty(& s_dbpf_io_ready_queue))
---
>     if (!dbpf_op_queue_empty(& dbpf_op_queue[OP_QUEUE_IO]))
297c235
<         cur_op = dbpf_op_pop_front_nolock( & s_dbpf_io_ready_queue);
---
>         cur_op = dbpf_op_pop_front_nolock(& dbpf_op_queue[OP_QUEUE_IO]);
307c245
<         assert(s_dbpf_ios_in_progress < (DBPF_MAX_IOS_IN_PROGRESS + 1));
---
>         assert(s_dbpf_ios_in_progress < (s_dbpf_ios_in_progress_max + 1));
351d288
< 
371c308
<         dbpf_queued_op_queue(cur_op, & dbpf_op_queue[OP_QUEUE_IO]);
---
>         dbpf_queued_op_queue_nolock(cur_op, & dbpf_op_queue[OP_QUEUE_IO]);
376c313
<     gen_mutex_unlock(& s_dbpf_io_mutex);
---
>     gen_mutex_unlock(&dbpf_op_queue_mutex[OP_QUEUE_IO]);
379c316
< static int issue_or_delay_io_operation(
---
> static int dbpf_bstream_aio_issue_or_delay(
386c323
<     int ret = -TROVE_EINVAL, op_delayed = 0;
---
>     int ret = -TROVE_EINVAL;
390,425c327
<     gen_mutex_lock(& s_dbpf_io_mutex);
<     if (dec_first)
<     {
<         s_dbpf_ios_in_progress--;
<     }
<     if (s_dbpf_ios_in_progress < DBPF_MAX_IOS_IN_PROGRESS)
<     {
<         s_dbpf_ios_in_progress++;
<     }
<     else
<     {
<         assert(& s_dbpf_io_ready_queue);
<         dbpf_op_queue_add(& s_dbpf_io_ready_queue, cur_op);
< 
<         op_delayed = 1;
< #ifndef __PVFS2_TROVE_AIO_THREADED__
<         /*
<            setting this state flag tells the caller not to re-add this
<            operation to the normal dbpf-op queue because it will be
<            started automatically (internally) on completion of other
<            I/O operations
<          */
<         dbpf_op_change_status(cur_op, OP_INTERNALLY_DELAYED);
< #endif
< 
<         gossip_debug(GOSSIP_TROVE_DEBUG, "delayed I/O operation %p "
<                      "(%d already in progress)\n",
<                      cur_op, s_dbpf_ios_in_progress);
<     }
< 
<     gossip_debug(GOSSIP_TROVE_DEBUG, "DBPF I/O ops in progress: %d\n",
<                  s_dbpf_ios_in_progress);
< 
<     gen_mutex_unlock(& s_dbpf_io_mutex);
< 
<     if (!op_delayed)
---
>     if (s_dbpf_ios_in_progress < s_dbpf_ios_in_progress_max)
429d330
< 
448d348
<             s_dbpf_ios_in_progress--;
452a353,354
>         s_dbpf_ios_in_progress++;
> 
455a358,380
>         gossip_debug(GOSSIP_TROVE_DEBUG, "DBPF I/O ops in progress: %d\n",
>                      s_dbpf_ios_in_progress);
>     }
>     else
>     {
>         gen_mutex_lock(&dbpf_op_queue_mutex[OP_QUEUE_IO]);
>         assert(& dbpf_op_queue[OP_QUEUE_IO]);
>         dbpf_op_queue_add(& dbpf_op_queue[OP_QUEUE_IO], cur_op);
>         gen_mutex_unlock(&dbpf_op_queue_mutex[OP_QUEUE_IO]);
> 
> #ifndef __PVFS2_TROVE_AIO_THREADED__
>         /*
>            setting this state flag tells the caller not to re-add this
>            operation to the normal dbpf-op queue because it will be
>            started automatically (internally) on completion of other
>            I/O operations
>          */
>         dbpf_op_change_status(cur_op, OP_INTERNALLY_DELAYED);
> #endif
> 
>         gossip_debug(GOSSIP_TROVE_DEBUG, "delayed I/O operation %p "
>                      "(%d already in progress)\n",
>                      cur_op, s_dbpf_ios_in_progress);
456a382,383
> 
> 
1026,1047d952
<     op_p = &q_op_p->op;
< 
<     /*
<        instead of queueing the op like most other trove operations,
<        we're going to issue the system aio calls here to begin being
<        serviced immediately.  We'll check progress in the
<        aio_progress_notification callback method; this array is freed
<        in dbpf-op.c:dbpf_queued_op_free
<      */
<     aiocb_p = (struct aiocb *) malloc((AIOCB_ARRAY_SZ * sizeof(struct aiocb)));
<     if (aiocb_p == NULL)
<     {
<         dbpf_open_cache_put(&q_op_p->op.u.b_rw_list.open_ref);
<         return -TROVE_ENOMEM;
<     }
< 
<     memset(aiocb_p, 0, (AIOCB_ARRAY_SZ * sizeof(struct aiocb)));
<     for (i = 0; i < AIOCB_ARRAY_SZ; i++)
<     {
<         aiocb_p[i].aio_lio_opcode = LIO_NOP;
<         aiocb_p[i].aio_sigevent.sigev_notify = SIGEV_NONE;
<     }
1049,1051c954,959
<     op_p->u.b_rw_list.aiocb_array_count = AIOCB_ARRAY_SZ;
<     op_p->u.b_rw_list.aiocb_array = aiocb_p;
<     op_p->u.b_rw_list.list_proc_state = LIST_PROC_INPROGRESS;
---
>     /* setup aio event notification */
>     q_op_p->op.u.b_rw_list.sigev.sigev_notify = SIGEV_THREAD;
>     q_op_p->op.u.b_rw_list.sigev.sigev_notify_attributes = NULL;
>     q_op_p->op.u.b_rw_list.sigev.sigev_notify_function = 
>         aio_progress_notification;
>     q_op_p->op.u.b_rw_list.sigev.sigev_value.sival_ptr = (void *) q_op_p;
1053,1067c961,962
<     /* convert listio arguments into aiocb structures */
<     aiocb_inuse_count = op_p->u.b_rw_list.aiocb_array_count;
<     ret = dbpf_bstream_listio_convert(op_p->u.b_rw_list.fd,
<                                       op_p->u.b_rw_list.opcode,
<                                       op_p->u.b_rw_list.mem_offset_array,
<                                       op_p->u.b_rw_list.mem_size_array,
<                                       op_p->u.b_rw_list.mem_array_count,
<                                       op_p->u.b_rw_list.stream_offset_array,
<                                       op_p->u.b_rw_list.stream_size_array,
<                                       op_p->u.b_rw_list.stream_array_count,
<                                       aiocb_p,
<                                       &aiocb_inuse_count,
<                                       &op_p->u.b_rw_list.lio_state);
< 
<     if (ret == 1)
---
>     ret = dbpf_bstream_aiocb_init(&aiocb_p);
>     if(ret < 0)
1069,1085c964
<         op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLCONVERTED;
<     }
< 
<     op_p->u.b_rw_list.sigev.sigev_notify = SIGEV_THREAD;
<     op_p->u.b_rw_list.sigev.sigev_notify_attributes = NULL;
<     op_p->u.b_rw_list.sigev.sigev_notify_function = aio_progress_notification;
<     op_p->u.b_rw_list.sigev.sigev_value.sival_ptr = (void *) q_op_p;
< 
<     /* mark unused with LIO_NOPs */
<     for (i = aiocb_inuse_count; i < op_p->u.b_rw_list.aiocb_array_count; i++)
<     {
<         aiocb_p[i].aio_lio_opcode = LIO_NOP;
<     }
< 
<     for (i = 0; i < aiocb_inuse_count; i++)
<     {
<         aiocb_ptr_array[i] = &aiocb_p[i];
---
>         return ret;
1088,1090c967,968
<     assert(q_op_p == op_p->u.b_rw_list.sigev.sigev_value.sival_ptr);
< 
<     if (op_p->u.b_rw_list.list_proc_state == LIST_PROC_ALLCONVERTED)
---
>     ret = dbpf_bstream_aio_setup_next_op(q_op_p, aiocb_p);
>     if(ret < 0)
1092c970,971
<         op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLPOSTED;
---
>         dbpf_open_cache_put(&q_op_p->op.u.b_rw_list.open_ref);
>         return ret;
1100,1107d978
<     ret =
<         issue_or_delay_io_operation(q_op_p, aiocb_ptr_array, aiocb_inuse_count,
<                                     &op_p->u.b_rw_list.sigev, 0);
< 
<     if (ret)
<     {
<         return ret;
<     }
1150,1151c1021
< static int dbpf_bstream_rw_list_op_svc(
<     struct dbpf_op *op_p)
---
> static int dbpf_bstream_rw_list_op_svc(struct dbpf_op *op_p)
1153,1156c1023,1024
<     int ret = -TROVE_EINVAL, i = 0, aiocb_inuse_count = 0;
<     int op_in_progress_count = 0;
<     struct aiocb *aiocb_p = NULL, *aiocb_ptr_array[AIOCB_ARRAY_SZ];
< 
---
>     struct aiocb * aiocb_p;
>     int ret = -TROVE_EINVAL;
1159,1161c1027,1028
<         /*
<            first call; need to allocate aiocb array and ptr array;
<            this array is freed in dbpf-op.c:dbpf_queued_op_free
---
>         /* The rw_list has just been posted and no lio_listio operations
>          * have been posted yet, so we do that and return
1163,1178d1029
<         aiocb_p = malloc(AIOCB_ARRAY_SZ * sizeof(struct aiocb));
<         if (aiocb_p == NULL)
<         {
<             return -TROVE_ENOMEM;
<         }
< 
<         memset(aiocb_p, 0, AIOCB_ARRAY_SZ * sizeof(struct aiocb));
<         for (i = 0; i < AIOCB_ARRAY_SZ; i++)
<         {
<             aiocb_p[i].aio_lio_opcode = LIO_NOP;
<             aiocb_p[i].aio_sigevent.sigev_notify = SIGEV_NONE;
<         }
< 
<         op_p->u.b_rw_list.aiocb_array_count = AIOCB_ARRAY_SZ;
<         op_p->u.b_rw_list.aiocb_array = aiocb_p;
<         op_p->u.b_rw_list.list_proc_state = LIST_PROC_INPROGRESS;
1180,1184d1030
<     }
<     else
<     {
<         /* operations potentially in progress */
<         aiocb_p = op_p->u.b_rw_list.aiocb_array;
1186,1187c1032,1033
<         /* check to see how we're progressing on previous operations */
<         for (i = 0; i < op_p->u.b_rw_list.aiocb_array_count; i++)
---
>         ret = dbpf_bstream_aiocb_init(&aiocb_p);
>         if(ret < 0)
1189,1238c1035
<             if (aiocb_p[i].aio_lio_opcode == LIO_NOP)
<             {
<                 continue;
<             }
< 
<             /* gets the "errno" value of the individual op */
<             ret = aio_error(&aiocb_p[i]);
<             if (ret == 0)
<             {
<                 /*
<                    this particular operation completed w/out error.
<                    gets the return value of the individual op
<                  */
<                 ret = aio_return(&aiocb_p[i]);
< 
<                 gossip_debug(GOSSIP_TROVE_DEBUG, "%s: %s complete: "
<                              "aio_return() ret %d (fd %d)\n",
<                              __func__,
<                              ((op_p->type == BSTREAM_WRITE_LIST) ||
<                               (op_p->type == BSTREAM_WRITE_AT) ?
<                               "WRITE" : "READ"), ret, op_p->u.b_rw_list.fd);
< 
<                 /* aio_return doesn't seem to return bytes read/written if 
<                  * sigev_notify == SIGEV_NONE, so we set the out size 
<                  * from what's requested.  For reads we just leave as zero,
<                  * which ends up being OK,
<                  * since the amount read (if past EOF its less than requested)
<                  * is determined from the bstream size.
<                  */
<                 if (op_p->type == BSTREAM_WRITE_LIST ||
<                     op_p->type == BSTREAM_WRITE_AT)
<                 {
<                     *(op_p->u.b_rw_list.out_size_p) += aiocb_p[i].aio_nbytes;
<                 }
< 
<                 /* mark as a NOP so we ignore it from now on */
<                 aiocb_p[i].aio_lio_opcode = LIO_NOP;
<             }
<             else if (ret != EINPROGRESS)
<             {
<                 gossip_err("%s: aio_error on block %d, skipping: %s\n",
<                            __func__, i, strerror(ret));
<                 ret = -trove_errno_to_trove_error(ret);
<                 goto final_aio_cleanup;
<             }
<             else
<             {
<                 /* otherwise the operation is still in progress; skip it */
<                 op_in_progress_count++;
<             }
---
>             return ret;
1239a1037,1040
> 
>         ret = dbpf_bstream_aio_setup_next_op(
>             (dbpf_queued_op_t *)op_p->u.b_rw_list.queued_op_ptr, aiocb_p);
>         return ret;
1242,1243c1043,1044
<     /* if we're not done with the last set of operations, break out */
<     if (op_in_progress_count > 0)
---
>     ret = dbpf_bstream_aio_check_progress(op_p);
>     if(ret == EINPROGRESS)
1247c1048
<     else if (op_p->u.b_rw_list.list_proc_state == LIST_PROC_ALLPOSTED)
---
>     else if(ret < 0)
1249,1262c1050
<         /* we've posted everything, and it all completed */
<         ret = 1;
< 
<       final_aio_cleanup:
<         if ((op_p->type == BSTREAM_WRITE_AT) ||
<             (op_p->type == BSTREAM_WRITE_LIST))
<         {
<             DBPF_AIO_SYNC_IF_NECESSARY(op_p, op_p->u.b_rw_list.fd, ret);
<         }
< 
<         dbpf_open_cache_put(&op_p->u.b_rw_list.open_ref);
<         op_p->u.b_rw_list.fd = -1;
< 
<         start_delayed_ops_if_any(1);
---
>         dbpf_bstream_aio_finish(op_p);
1265,1279d1052
<     else
<     {
<         /* no operations in progress; convert and post some more */
<         aiocb_inuse_count = op_p->u.b_rw_list.aiocb_array_count;
<         ret = dbpf_bstream_listio_convert(op_p->u.b_rw_list.fd,
<                                           op_p->u.b_rw_list.opcode,
<                                           op_p->u.b_rw_list.mem_offset_array,
<                                           op_p->u.b_rw_list.mem_size_array,
<                                           op_p->u.b_rw_list.mem_array_count,
<                                           op_p->u.b_rw_list.stream_offset_array,
<                                           op_p->u.b_rw_list.stream_size_array,
<                                           op_p->u.b_rw_list.stream_array_count,
<                                           aiocb_p,
<                                           &aiocb_inuse_count,
<                                           &op_p->u.b_rw_list.lio_state);
1281,1320c1054,1057
<         if (ret == 1)
<         {
<             op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLCONVERTED;
<         }
< 
<         /* mark unused with LIO_NOPs */
<         for (i = aiocb_inuse_count;
<              i < op_p->u.b_rw_list.aiocb_array_count; i++)
<         {
<             aiocb_p[i].aio_lio_opcode = LIO_NOP;
<         }
< 
<         for (i = 0; i < aiocb_inuse_count; i++)
<         {
<             aiocb_ptr_array[i] = &aiocb_p[i];
<         }
< 
<         if (op_p->u.b_rw_list.list_proc_state == LIST_PROC_ALLCONVERTED)
<         {
<             op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLPOSTED;
<         }
< 
<         /*
<            we use a reverse mapped ptr for I/O operations in order to
<            access the queued op from the op.  this is only useful for
<            the delayed io operation scheme.  it's initialized in
<            dbpf_bstream_rw_list
<          */
<         assert(op_p->u.b_rw_list.queued_op_ptr);
< 
<         ret = issue_or_delay_io_operation((dbpf_queued_op_t *) op_p->u.
<                                           b_rw_list.queued_op_ptr,
<                                           aiocb_ptr_array, aiocb_inuse_count,
<                                           &op_p->u.b_rw_list.sigev, 1);
< 
<         if (ret)
<         {
<             return ret;
<         }
<         return 0;
---
>     if (op_p->u.b_rw_list.list_proc_state == LIST_PROC_ALLPOSTED)
>     {
>         /* we've posted everything, and it all completed */
>         dbpf_bstream_aio_finish(op_p);
1321a1059
>     return 1;
1512a1251,1425
> 
> static int dbpf_bstream_aiocb_init(struct aiocb ** new_aiocb_p)
> {
>     int i;
>     struct aiocb * aiocb_p;
> 
>     aiocb_p = malloc(AIOCB_ARRAY_SZ * sizeof(struct aiocb));
>     if(aiocb_p == NULL)
>     {
>         return -TROVE_ENOMEM;
>     }
>     memset(aiocb_p, 0, AIOCB_ARRAY_SZ * sizeof(struct aiocb));
>     for (i = 0; i < AIOCB_ARRAY_SZ; i++)
>     {
>         aiocb_p[i].aio_lio_opcode = LIO_NOP;
>         aiocb_p[i].aio_sigevent.sigev_notify = SIGEV_NONE;
>     }
> 
>     return 0;
> }
>     
> static int dbpf_bstream_aio_setup_next_op(dbpf_queued_op_t * q_op_p,
>                                           struct aiocb * aiocb_p)
> {
>     struct aiocb * aiocb_ptr_array[AIOCB_ARRAY_SZ];
>     int aiocb_inuse_count;
>     int ret, i;
>     struct dbpf_op * op_p;
> 
>     op_p = &q_op_p->op;
> 
>     op_p->u.b_rw_list.aiocb_array_count = AIOCB_ARRAY_SZ;
>     op_p->u.b_rw_list.aiocb_array = aiocb_p;
>     op_p->u.b_rw_list.list_proc_state = LIST_PROC_INPROGRESS;
> 
>     /* convert listio arguments into aiocb structures */
>     aiocb_inuse_count = op_p->u.b_rw_list.aiocb_array_count;
>     ret = dbpf_bstream_listio_convert(op_p->u.b_rw_list.fd,
>                                       op_p->u.b_rw_list.opcode,
>                                       op_p->u.b_rw_list.mem_offset_array,
>                                       op_p->u.b_rw_list.mem_size_array,
>                                       op_p->u.b_rw_list.mem_array_count,
>                                       op_p->u.b_rw_list.stream_offset_array,
>                                       op_p->u.b_rw_list.stream_size_array,
>                                       op_p->u.b_rw_list.stream_array_count,
>                                       aiocb_p,
>                                       &aiocb_inuse_count,
>                                       &op_p->u.b_rw_list.lio_state);
> 
>     if (ret == 1)
>     {
>         op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLCONVERTED;
>     }
> 
>     /* mark unused with LIO_NOPs */
>     for (i = aiocb_inuse_count; i < op_p->u.b_rw_list.aiocb_array_count; i++)
>     {
>         aiocb_p[i].aio_lio_opcode = LIO_NOP;
>     }
> 
>     for (i = 0; i < aiocb_inuse_count; i++)
>     {
>         aiocb_ptr_array[i] = &aiocb_p[i];
>     }
> 
>     if (op_p->u.b_rw_list.list_proc_state == LIST_PROC_ALLCONVERTED)
>     {
>         op_p->u.b_rw_list.list_proc_state = LIST_PROC_ALLPOSTED;
>     }
> 
>     ret =
>         dbpf_bstream_aio_issue_or_delay(
>             q_op_p, aiocb_ptr_array, aiocb_inuse_count,
>             &op_p->u.b_rw_list.sigev, 0);
> 
>     return ret;
> }
> 
> static int dbpf_bstream_aio_check_progress(struct dbpf_op * op_p)
> {
>     int i, ret, op_in_progress_count;
>     struct aiocb * aiocb_p;
> 
>     /* operations potentially in progress */
>     aiocb_p = op_p->u.b_rw_list.aiocb_array;
> 
>      /*
>        we should iterate through the ops here to determine the
>        error/return value of the op based on individual request
>        error/return values.  they're ignored for now, however.
>      */
>     for (i = 0; i < op_p->u.b_rw_list.aiocb_array_count; i++)
>     {
>         if (aiocb_p[i].aio_lio_opcode == LIO_NOP)
>         {
>             continue;
>         }
> 
>         /* aio_error gets the "errno" value of the individual op */
>         ret = aio_error(&aiocb_p[i]);
>         if(ret == EINPROGRESS)
>         {
>             op_in_progress_count++;
>             continue;
>         }
>         else if(ret < 0)
>         {
>             gossip_debug(GOSSIP_TROVE_DEBUG, "error %d (%s) from "
>                          "aio_error/aio_return on block %d; "
>                          "skipping\n", ret, strerror(ret), i);
> 
>             ret = -trove_errno_to_trove_error(ret);
>             return ret;
>         }
> 
>         /* ret == 0 so we assume aio op completed. */
>         s_dbpf_ios_in_progress--;
> 
>         /* aio_return gets the return value of the individual op */
>         ret = aio_return(&aiocb_p[i]);
> 
>         gossip_debug(GOSSIP_TROVE_DEBUG, "%s: %s complete: "
>                      "aio_return() says %d [fd = %d]\n",
>                      __func__,
>                      ((op_p->type == BSTREAM_WRITE_LIST) ||
>                       (op_p->type == BSTREAM_WRITE_AT) ?
>                       "WRITE" : "READ"), ret, op_p->u.b_rw_list.fd);
> 
>         if(op_p->u.b_rw_list.sigev.sigev_notify == SIGEV_NONE)
>         {
>             /* aio_return doesn't seem to return bytes read/written if 
>              * sigev_notify == SIGEV_NONE, so we set the out size 
>              * from what's requested.  For reads we just leave as zero,
>              * which ends up being OK,
>              * since the amount read (if past EOF its less than requested)
>              * is determined from the bstream size.
>              */
>             if (op_p->type == BSTREAM_WRITE_LIST ||
>                 op_p->type == BSTREAM_WRITE_AT)
>             {
>                 *(op_p->u.b_rw_list.out_size_p) += aiocb_p[i].aio_nbytes;
>             }
>         }
>         else
>         {
>             *(op_p->u.b_rw_list.out_size_p) += ret;
>         }
> 
>         /* mark as a NOP so we ignore it from now on */
>         aiocb_p[i].aio_lio_opcode = LIO_NOP;
>     }
> 
>     if(op_in_progress_count)
>     {
>         return EINPROGRESS;
>     }
>     return 0;
> }
> 
> static int dbpf_bstream_aio_finish(struct dbpf_op * op_p)
> {
>     int ret;
>     DBPF_AIO_SYNC_IF_NECESSARY(op_p, op_p->u.b_rw_list.fd, ret);
> 
>     dbpf_open_cache_put(&op_p->u.b_rw_list.open_ref);
>     op_p->u.b_rw_list.fd = -1;
> 
>     gossip_debug(GOSSIP_TROVE_DEBUG, "*** starting delayed ops if any "
>                  "(state is %s)\n",
>                  list_proc_state_strings[op_p->u.b_rw_list.
>                  list_proc_state]);
> 
>     return ret;
> }
> 
