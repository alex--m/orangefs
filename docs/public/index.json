[
{
	"uri": "/quickstart/",
	"title": "Quickstart Guides",
	"tags": [],
	"description": "",
	"content": "Quickstart Guides\n          "
},
{
	"uri": "/quickstart/quickstart-package/",
	"title": "Quickstart Package Installation Guide",
	"tags": [],
	"description": "",
	"content": " Packages for OrangeFS are available in the Fedora repositories. Packages for CentOS are available in Fedora\u0026rsquo;s EPEL (Extra Packages for Enterprise Linux) repository. The packages are available on Fedora 27 and later and CentOS 7 and later.\nA number of packages are available. The OrangeFS package provides the client and the orangefs-server package provides the server. The orangefs-devel package is required to build additional programs against OrangeFS. There is also an orangefs-fuse package providing FUSE support, which is not described by this guide.\nThe kernel module is not provided by any of the above packages. It is now available in mainline Linux. In Fedora, it is installed by the kernel-core package, which means it is installed by default. On CentOS, it is not available with the default kernel. A newer kernel can be obtained from theELRepo project.\nThe kernel module requires a userspace client (often called the pvfs2-client-core). This is provided by the OrangeFS package. The userspace client is not required to run non-kernel OrangeFS clients, such as the administrative programs also provided by the OrangeFS package.\nInstall the Packages Install on Fedora To install on Fedora, issue the following command:\ndnf -y install orangefs orangefs-server\nInstall on CentOS To install on CentOS, issue the following commands:\nyum -y install epel-release\nyum -y install orangefs orangefs-server\nInstall the ELRepo Kernel If the kernel module will be used on CentOS, the ELRepo kernel must be installed. To install the ELRepo kernel, issue the following commands:\nrpm \u0026ndash;import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\nrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm\nyum -y \u0026ndash;enablerepo=elrepo-kernel install kernel-ml\nAdd Servers To add servers, complete the following steps:\n Install the necessary packages on each machine as described above. An example server configuration is provided in /etc/orangefs/orangefs.conf. It will suffice for a single-server installation. If necessary, the default hostname localhost should be changed. Otherwise, if multiple servers will be used, generate a configuration using:\npvfs2-genconfig\n Copy the configuration to each server machine.\nscp -pr hostname:/etc/orangefs/orangefs.conf /etc/orangefs/orangefs.conf\n Initialize the filesystem and start on each machine.\npvfs2-server -f /etc/orangefs/orangefs.conf\nsystemctl start orangefs-server\nNote The filesystem should only be initialized once.  In the future each server can be started manually.\nsystemctl start orangefs-server\n Start the server at boot.\nsystemctl enable orangefs-server\n  Add Clients To add clients, complete the following steps:\n Install the necessary packages on each machine as described above. An example client configuration is provided in /etc/pvfs2tab. It is commented by default. Uncomment it by removing the leading \u0026lsquo;#\u0026rsquo;, then change the hostname if necessary.  Change the default mount point, /orangefs, if necessary. Copy the client configuration to each client machine.\nscp -pr hostname:/etc/pvfs2tab /etc/pvfs2tab\n Test connectivity to the server\npvfs2-ping -m /orangef\n If everything is working correctly, the pvfs2-ping utility will output similar to the following.\n​(1) Parsing tab file\u0026hellip;\n(2) Initializing system interface\u0026hellip;\n(3) Initializing each file system found in tab file: /etc/pvfs2tab\u0026hellip;\nPVFS2 servers: tcp://localhost:3334\nStorage name: orangefs Local mount point: /orangefs\n/orangefs: Ok\n(4) Searching for /orangefs in pvfstab\u0026hellip;\nPVFS2 servers: tcp://localhost:3334\nStorage name: orangefs\nLocal mount point: /pvfsmnt\nmeta servers:\ntcp://localhost:3334\ndata servers:\ntcp://localhost:3334\n(5) Verifying that all servers are responding\u0026hellip;\nmeta servers:\ntcp://localhost:3334 Ok\ndata servers:\ntcp://localhost:3334 Ok\n(6) Verifying that fsid 1 is acceptable to all servers\u0026hellip;\nOk; all servers understand fs_id 1\n(7) Verifying that root handle is owned by one server\u0026hellip;\nRoot handle: 1048576\nOk; root handle is owned by exactly one server.\n=============================================================\nThe PVFS2 filesystem at /pvfsmnt appears to be correctly configured.\n    If the kernel module will not be used, OrangeFS is now installed; otherwise, the kernel module will be used. To load the kernel module, issue the following command:\nmodprobe orangefs\n Start the client with the following command:\nsystemctl start orangefs-client\n Next, mount the filesystem. Change the hostname and mountpoint if necessary.\nmount -t pvfs2 tcp://localhost:3334/orangefs /pvfsmnt\n  The filesystem is now mounted.\n         "
},
{
	"uri": "/quickstart/quickstart-build/",
	"title": "Quickstart Source Build Guide",
	"tags": [],
	"description": "",
	"content": " This topic provides an example of a complete installation of OrangeFS from source in a single procedure. It can also be used as a Quick Start reference for experienced users who wish to bypass the more detailed and segmented instructions in the earlier topics of this manual.\nNotes Most of the following steps require that you have root permissions.\nIf your distro includes the OrangeFS kernel module, you may skip tasks related to building and installing the kernel module. To determine if your distro includes the OrangeFS kernel module, issue this command: modprobe orangefs You must install OrangeFS every time you update the kernel.\nAssumptions The following assumptions apply to this example installation:\n Network protocol is TCP/IP\n Uses Default security mode\n Any firewall must be configured to allow clients and servers to communicate.\n  Build OrangeFS Prerequisites Prerequisites for RHEL, SUSE and Ubuntu are documented below.\nRHEL The system on which you build OrangeFS requires eight additional Linux software packages. Following are the names for these packages on a system running RHEL:\n gcc - bison - libattr-devel - perl flex - openssl-devel - kernel-devel - make   To automatically install these packages, enter the following command:\nyum -y install gcc flex bison openssl-devel libattr-devel kernel-devel perl make\n SUSE Following are the names for the packages required on a system running SUSE:\n automake - bison - kernel-source - libopenssl-devel gcc - flex - kernel-syms - libattr-devel   To automatically install these packages, enter the following command using zypper:\nzypper install automake gcc bison flex kernel-source kernel-syms libopenssl-devel libattr-devel\n Additionally, for SUSE, you must prepare the kernel source using the following commands:\ncp /boot/config-`uname -r` /usr/src/linux-`uname -r | sed s/-[\\d].*//`/.config\ncd /usr/src/linux-`uname -r | sed s/-[\\d].*//`\nmake oldconfig\nmake modules_prepare\nmake prepare\nln -s /lib/modules/`uname -r`/build/Module.symvers /lib/modules/`uname -r`/source\nNote Ensure SELinux is set to \u0026ldquo;permissive\u0026rdquo; or \u0026ldquo;disabled\u0026rdquo;\nUbuntu Following are the names for the packages required on a system running Ubuntu:\n automake - bison - libattr-devel build-essential - flex - libattrl   To automatically install these packages, enter the following command using apt:\napt install automake build-essential bison flex libattr1 libattr1-dev\nInstallation Steps To build OrangeFS, complete the following steps:\n Download and extract the OrangeFS software:   Download the source from http://orangefs.com/download/.\n Extract the source tar archive:\n  tar -xzf orangefs-version.tar.gz\n Change Directory (cd) to the extracted directory:  cd orangefs-version\n Configure the OrangeFS installation location and the path of the system kernel:  Notes If using a distro which includes the upstream OrangeFS kernel module, omit \u0026ndash;with-kernel=kernel_path\nEvery update will require rebuilding.\n./configure \u0026ndash;prefix=/opt/orangefs \u0026ndash;with-kernel=kernel_path \\\n\u0026ndash;with-db-backend=lmdb\nwhere\u0026hellip;\nkernel_path = path to kernel source\n RHEL Example: /lib/modules/`uname -r`/build\nSUSE Example: /lib/modules/`uname -r`/source\nUbuntu 16.04 or earlier Example: /lib/modules/`uname -r`/build\n Build and install the software:  make\nmake install\nIf using a distro which does not include the upstream OrangeFS kernel module, type the following additional commands:\nmake kmod\nmake kmod_prefix=/opt/orangefs kmod_install\n Create a server configuration file by running the automatic file generation program (pvfs2-genconfig) and answering the prompts.  /opt/orangefs/bin/pvfs2-genconfig /opt/orangefs/etc/orangefs-server.conf\nNotes During the pvfs2-genconfig process: ● Use the directories you created in Step 3 for your storage and log file locations.\n● Each host you specify should be the value returned by the hostname command.\nThis places a server configuration file (named orangefs-server.conf in this example) in the etc directory.\nAdd Clients (Kernel Module)  To add the software required for an OrangeFS Linux client interface, Change Directory (cd) to /opt on the Client system and copy the /opt/orangefs directory from the Build system:  scp -rp hostname:/opt/orangefs /opt\nwhere\u0026hellip;\nhostname = host name of the build system\n Insert the client kernel module.  This module (pvfs2.ko) resides in the OrangeFS installation directory several directory layers deep. To insert the module without specifying a long path, include this find statement: insmod ‘find /opt/orangefs -name pvfs2.ko‘\nNote If using a distro which includes OrangeFS, omit Step 2.\n Start the client process on each Client system:  /opt/orangefs/sbin/pvfs2-client\n Create a directory in the Client system\u0026rsquo;s /mnt directory through which the client will mount OrangeFS:  mkdir /mnt/orangefs\n Determine the URL of the OrangeFS server you will mount.  You can retrieve this information from the orangefs-server.conf file. For example, the first server URL listed in that file can be extracted with the following command:\ngrep \u0026ldquo;Alias \u0026rdquo; /opt/orangefs/etc/orangefs-server.conf | awk \u0026lsquo;{ print \\$3 }\u0026rsquo; | head -n 1\nThe format to use for server URL is protocol://hostname:port.\nExample: tcp://server1:3334\n Create a file named pvfs2tab in the Client system\u0026rsquo;s /etc directory that tells the system how to mount OrangeFS. Assign read access to the file.  echo \u0026ldquo;tcp://server1:3334/orangefs /mnt/orangefs pvfs2\u0026rdquo; \u0026gt;\u0026gt;\n/etc/pvfs2tab\nAdd Servers  To add the required software to an OrangeFS server, Change Directory (cd) to /opt on the Server system and copy the /opt/orangefs directory from the Build system:  scp -rp hostname:/opt/orangefs /opt\nwhere\u0026hellip;\nhostname = host name of the build system\n Initialize the server storage space on each server:  /opt/orangefs/sbin/pvfs2-server -f /opt/orangefs/etc/orangefs-server.conf -a \u0026lt;alias name\u0026gt;\n Start the server processes on each server:  /opt/orangefs/sbin/pvfs2-server /opt/orangefs/etc/orangefs-server.conf -a \u0026lt;alias name\u0026gt;\nMount the File System Mount OrangeFS through the server URL you retrieved earlier:\nmount -t pvfs2 tcp://server1:3334/orangefs /mnt/orangefs\n          "
},
{
	"uri": "/build-configure/",
	"title": "Build and Configure",
	"tags": [],
	"description": "",
	"content": "Build and Configure\n          "
},
{
	"uri": "/build-configure/setup_security_build/",
	"title": "Build Security Setup",
	"tags": [],
	"description": "",
	"content": "              After you build the OrangeFS installation directory, you must continue setup and configuration if you select either the key-based or certificate-based mode of security. Much of this work can be done once on the build system, then copied to your servers and clients. In future versions of OrangeFS, security will be simplified.    In the Procedure section of the previous topic, you specified a security mode when running ./configure (see step 3 in Build OrangeFS).\nDepending on the mode you chose (default, key-based or certificate-based), refer to the appropriate sections in this topic for additional security setup for the Build system:\n Default_Mode Key-Based_Mode Certificate-Based_Mode  Default Mode If security is not a priority, you might have selected the default mode for optimal performance and faster installation. This mode does not require any additional setup, so you can go to the next topic, Create OrangeFS Configuration File.\nKey-Based Mode If you selected the key-based mode, you must create your security keys and a keystore file in a temporary directory on the Build system. You must then copy the keystore file to the OrangeFS installation directory.\nNotes To complete this procedure, you must know the host names of your OrangeFS servers and clients. This procedure assumes the use of an automated script provided with your OrangeFS files. To learn how to create your security keys and keystore manually, see the Administration Guide.\nProcedure The following steps set up the Build system for key-based security. They assume the OrangeFS source is in /tmp/src/orangefs-version.\n Create a temporary directory on the Build system, located outside the /tmp/src/orangefs-version source directory:  cd /opt\nmkdir ofs_keys\nNote Later, after you have distributed key pairs to your OrangeFS servers and clients, you should either delete or limit access to this directory. If you keep this directory for future changes, secure it appropriately using best practices.\n  Change Directory (cd) to the new directory and copy two script files from /tmp/src/orangefs-version/examples/keys:  cd ofs_keys\ncp /tmp/src/orangefs-version/examples/keys/*.sh .\nNote You will use only one of these scripts now. You will use the second one when you add OrangeFS servers later.\n  With the script named pvfs2-gen-keys.sh, use the following command line format to generate private keys for servers and clients, as well as the keystore:  ./pvfs2-gen-keys.sh [-a] [-s servers] [-c clients]\nwhere\u0026hellip;\nservers = server hostname(s), each separated by a space\nExample: orangefs01 orangefs02 orangefs03\n clients = client hostname(s), each separated by a space\nExample: orangefs01 client01 client02\nNote As this example suggests, an OrangeFS server can also be a client.\n Example of full command:\n./pvfs2-gen-keys.sh -s orangefs01 orangefs02 -c orangefs01 orangefs02\n The executed script will generate:\nThe keystore, named orangefs-keystore by default, is a text file that contains the public keys for each server and client.\nKey File Type File Name Format Example Server orangefs-serverkey-hostname.pem orangefs-serverkey-orangefs01.pem Client pvfs2-clientkey-hostname.pem pvfs2-clientkey-client01.pem\nNote The -a option shown in the command line format does not apply during initial installation. Include this option only if you want the public keys to be appended to an existing keystore (named keystore by default).\n  Copy the keystore to the etc directory in your OrangeFS installation directory:  cp keystore /opt/orangefs/etc\nNote This is the default location for the keystore on all OrangeFS servers. If you specify a different location in the above copy command, you must reflect that change later when you create the OrangeFS configuration file.\n Generating Keys for Many Systems The command line format used in step 3 above can be modified for large numbers of servers and clients, using shell expansion. For example, the following command generates server keys for orangefs-server01 to orangefs-server04 and client keys for orangefs-client01 to orangefs-client40:\n./pvfs2-gen-keys.sh -s orangefs-server0{1..4} -c orangefs-client0{1..9} orangefs-client{10..40}\nSee your shell documentation for more information.\nCertificate-Based Mode If you selected the certificate-based mode of security, you must add a CA certificate to the OrangeFS directory on the Build system.\nIf you already have one you want to use, simply copy the certificate file, along with its private key file, to /opt/orangefs/etc. Each of the files should be in PEM format (see OpenSSL documentation).\nIf you need to create a CA certificate, the OrangeFS installation files include some tools to simplify the process. You must have a working knowledge of OpenSSL to tailor your certificate settings beyond the basic procedure that follows.\nProcedure OpenSSL references a configuration file when it creates certificates, including CA certificates.\nNote This file is specifically tied to OpenSSL; it is different from the OrangeFS configuration file.\n The default location for this file on the Build system is /etc/ssl/openssl.cnf, but the following procedure uses an alternative configuration file named orangefs.cnf. That file is located in /opt/orangefs/examples/certs, and it includes basic \u0026ldquo;quick start\u0026rdquo; settings that you can modify as needed.\nNote For complete information on the OpenSSL configuration file format, see the config(5ssl) Linux man page.\n To create a CA certificate (using the example configuration file):\n Change Directory (cd) to the directory where the example configuration file is located:  cd /tmp/src/orangefs-version/examples/certs\n  If necessary, customize the settings in the configuration file (orangefs.cnf) to reflect the security settings and policies of your organization. Enter the following command:  openssl req -config orangefs.cnf -new -x509 -outform PEM -out orangefs-ca-cert.pem -keyout orangefs-ca-cert-key.pem -nodes -days 1825\nNotes You can use different file names. You can also select a different expiration; the above example expires in 5 years (1825 days)\nThe documentation for this command is in the req(1) Linux man page.\nYou are prompted for configuration values after entering this command.\n  Enter the elements of the CA certificate subject.  The configuration file will prompt you for country, state, locality, organization, organizational unit and common name. You and your security administrator might want to discuss the values any existing certificates use and follow a similar format.\nWhen you submit the entries, the CA certificate and private key you specified (orangefs-ca-cert.pem and orangefs-ca-cert-key.pm in the example above) will be generated in the current directory.\n Move the CA certificate and private key files to the etc subdirectory in your OrangeFS installation directory:  mv *.pem /opt/orangefs/etc\n Using the Script File The examples/certs directory in your OrangeFS source directory also includes a script (pvfs2-cert-ca.sh) to streamline the above procedure. Its command line format includes a single optional parameter for any characters you want to add to the certificate file names.\nFor example, to achieve the same results as in the above procedure, you would enter:\n./pvfs2-cert-ca.sh orangefs\n Restricting Access Be sure to use chmod to restrict access to the CA key.\n      "
},
{
	"uri": "/build-configure/build_orangefs/",
	"title": "Build OrangeFS",
	"tags": [],
	"description": "",
	"content": " Building OrangeFS involves downloading the source software from orangefs.org onto a system preconfigured with several standard Linux packages. On this system you will extract and build OrangeFS into a portable directory named /opt/orangefs.\nThis topic provides the procedure for building OrangeFS.\nSystem Requirements In addition to a supported distribution of Linux, the OrangeFS Build system requires eight more Linux software packages. The names for these packages vary from one Linux distribution to another. For example, following are the package names you would require on a system running RHEL:\n gcc - bison - db4-devel - perl flex - openssl-devel - kernel-devel - make libattr-devel\n  The method for installing these packages varies among Linux distributions. For example, to automatically install the required packages on a system running RHEL, you could enter the following command:\nyum -y install gcc flex bison openssl-devel db4-devel kernel-devel perl make openldap-devel libattr-devel\n *Notes *If you do not plan to use certificate-based security, omit the option (openldap-devel) from the command.\nFor more details about supported Linux distributions and other required Linux packages, see Preview System Requirements.\nProcedure Important Because clients have different requirements for the OrangeFS build system, please read through all installation instructions for the client(s) you plan to use BEFORE you build OrangeFS.\nTo build OrangeFS, follow these steps:\n Go to www.orangefs.org and download the compressed tar file into the /tmp/src directory (or similar directory for temporary storage). The tar file is named as follows:  orangefs-version.tar.gz\nwhere\u0026hellip;\nversion = version number of the OrangeFS distribution release\nExample: orangefs-2.9.tar.gz\n  Change Directory (cd) to /tmp/src, and extract the compressed tar file, then change to the newly created orangefs directory:  tar -xzf orangefs-version.tar.gz\ncd orangefs-version\nFollowing is a sample listing of initial directories and files in the orangefs download directory:\n/tmp/src/orangefs-version \\$ ls\naclocal.m4 COPYING Makefile.in SecuritySetup\nAUTHORS CREDITS module.mk.in src\nautom4te.cache doc patches test\ncert-utils examples prepare windows\nChangeLog include pvfs2-config.h.in\nconfigure INSTALL README\nconfigure.in maint README.name_change\n Build a Makefile for OrangeFS that includes the installation location and the path of the system kernel, using the following command line format:  ./configure \u0026ndash;prefix=/opt/orangefs \u0026ndash;with-kernel=kernel_path protocol_options security_mode_option\nwhere\u0026hellip;\nkernel_path = path to kernel source\nExamples: /usr/src/kernels/2.6.18-194.17.1.el5-x86_64/\n/lib/modules/`uname -r`/build\nNote In the second example, `uname -r` will return the kernel version.\n protocol_options = one of the following:\nIf your network protocol is\u0026hellip; Include these options: TCP None, enabled by default IB, using Mellanox IB libraries \u0026ndash;with-ib=/usr \u0026ndash;without-bmi-tcp IB, using OFED \u0026ndash;with-openib=/usr \u0026ndash;without-bmi-tcp MX \u0026ndash;with-mx/user=/usr \u0026ndash;without-bmi-tcp GM \u0026ndash;with-gm=/usr \u0026ndash;without-bmi-tcp\n*Note *If you must run OrangeFS on more than one network protocol, please contact Technical Support.\n security_mode_option = one of the following:\nTo use this security mode\u0026hellip; Include this option: Default None, enabled by default Key-based \u0026ndash;enable-security-key Certificate-based \u0026ndash;enable-security-cert\n with_db_backend = one of the following:\nTo use this security mode\u0026hellip; Include this option: Berkeley DB None, enabled by default LMDB \u0026ndash;with-db-backend=lmdb\nNote LMDB is a newer database backend option but is not yet the default. It will work only for new installs, so you cannot upgrade from existing Berkeley DB installations.\nExample:\n./configure \u0026ndash;prefix=/opt/orangefs \u0026ndash;with-kernel=/lib/modules/`uname -r`/build \u0026ndash;enable-security-cert Important When using the Upstream Kernel Module, omit \u0026ndash;with-kernel=/lib/modules/`uname -r`/build from the above command.\n Continue with the standard Linux commands to build and run an executable program:  make\nmake install\n Compile and install the kernel module that your OrangeFS Linux clients will need later.  Important When using the Upstream Kernel Module, do not include the following code.\nmake kmod\nmake kmod_prefix=/opt/orangefs kmod_install\nImportant OrangeFS is currently not compatible with SELinux, integrated into many Linux distributions, so be sure to disable it on all your Linux installations. If it is not disabled, you will get a \u0026ldquo;permission denied\u0026rdquo; error when you try to run OrangeFS. To disable SELinux, use the following command:\necho 0 \u0026gt; /seLinux/enforce\nTo prevent SELinux from loading at boot time, edit /etc/seLinux/config and set the SELINUX value to “disabled”, for example,\nSELINUX=disabled\nThe command for disabling SELinux can vary, depending on your Linux version.\n     "
},
{
	"uri": "/build-configure/configuring_ldap_for_identity_mapping/",
	"title": "Configure LDAP",
	"tags": [],
	"description": "",
	"content": " When an OrangeFS server receives a certificate from a client, it performs identity mapping with the certificate. The certificate contains a subject distinguished name (DN) to identify it, while the server needs a numerical user ID (UID) and primary group ID (GID). In order to do the mapping, an LDAP directory is used. The subject DN is transformed in a configurable way to locate a user object in the LDAP directory; the object contains the UID and GID.\nOrangeFS is designed to use OpenLDAP client libraries, which are available for most distributions. The OrangeFS server can communicate with an OpenLDAP server or a standard LDAP server from another organization.\nFor more information on LDAP seehttp://openldap.org.\nPlanning for LDAP Identity Mapping First, identify which users will be allowed to use OrangeFS. These users will require user certificates and must have a user object in the LDAP directory. Information on creating users in LDAP is provided below.\nYou might be able to leverage an existing LDAP directory. Use the information below to evaluate how existing LDAP user objects can be utilized.\nThe next step is to identify a string to be uniquely associated with each user. The most obvious is the login name, the first field of /etc/passwd, with which users log in. However, if you have existing LDAP users, use their naming attribute values (often the “CN” or “UID” attribute). The description field of /etc/passwd could also be used. Any string will work as long as it is unique to each user. This value is the “user name”.\nDetermine the naming attribute for user objects in your LDAP directory. When creating a new LDAP directory, Common Name (CN) is a good choice.\nNext, determine where in LDAP the users will be, or are, stored. LDAP directories are hierarchical trees, where objects are identified by distinguished names (DNs). A DN consists of segments in the form “attribute=value”, separated by commas. The DN “ou=Users,dc=acme,dc=com” indicates an organizational unit (OU) named Users under the acme domain context (DC), which in turn is in the com DC. Objects containing other objects are called containers; some typical container classes are domain contexts (DC), organizations (O) and organizational units (OU). Often the DNS name of an organization is used to form the domain contexts at the root of the directory, for example acme.com becomes “dc=acme,dc=com”.\nDetermine the DN of the container that contains all the users to enable for OrangeFS. In some cases the users are in multiple containers; if so, select the container at the “highest” point that contains all subcontainers with users. For example if users are in both “ou=Engineering,ou=Users\u0026hellip;” and “ou=Sales,ou=Users\u0026hellip;”, make a note of “ou=Users” as the container. Also note whether the users are in one container or multiple containers.\nFinally, you must know where the UID and GID values are stored in LDAP. Objects in LDAP have named attributes, which can have one or more values. The default attributes that store the UID and GID are uidNumber and gidNumber. If you are using the OpenLDAP server, use the schema file nis.schema to enable these attributes. (See the OpenLDAP documentation for more information.)\nThe list below summarizes information needed to configure OrangeFS for LDAP identity mapping.\n Which users to enable for OrangeFS A user name to uniquely identify each user. For existing LDAP installations, this should correspond to the naming attribute of the existing user objects (often “CN” or “UID”). The naming attribute used for user objects in LDAP, often Common Name (CN) or UID. The DN of the LDAP container where user objects are stored. Users can be stored in one container or multiple containers. The names of the UID- and GID-storing attributes, usually uidNumber and gidNumber.  Planning for LDAP Binding \u0026ldquo;Binding\u0026rdquo; means connecting and authenticating to an LDAP server. You must have the following information to bind to your LDAP server:\n URI(s) for the LDAP server(s). These URIs are in form “ldap[s]://hostname[:port]”. Using “ldap” specifies a plaintext connection, and “ldaps” specifies a secure (usually SSL) connection. The default port is 389 for plaintext, and 636 for secure. You can have multiple LDAP servers for the same directory—specify any of these. DN of a binding user. The user must have sufficient rights to search for users in their specified container, and to read their uidNumber and gidNumber attributes. This value is optional, as anonymous binds are possible. The administrator must ensure that anonymous binds do not have excess rights. Password of the binding user. This value can be stored in a protected file for additional security. This value is optional, as users are not required to have passwords.  Because the password is not encrypted, a user should be created for OrangeFS usage with only the rights described above.\nServer Configuration File Settings The LDAP settings are specified in the OrangeFS configuration file, which is identical for each server. The \u0026lt;LDAP\u0026gt; tag within the \u0026lt;Security\u0026gt; tag contains the settings:\n\u0026lt;Defaults\u0026gt;\n\u0026hellip;\n\u0026lt;Security\u0026gt;\n\u0026hellip;\n\u0026lt;LDAP\u0026gt;\n[Hosts {list of LDAP URIs}]\n[BindDN {DN}]\n[BindPassword {password} or {file:path}]\n[SearchMode “CN” or “DN”]\n[SearchRoot {DN}]\n[SearchClass {Class name}]\n[SearchAttr {Attrname}]\n[SearchScope “onelevel” or “subtree”]\n[UIDAttr {Attrname}]\n[GIDAttr {Attrname}]\n[SearchTimeout {timeout (secs)}]\n\u0026lt;/LDAP\u0026gt;\n\u0026lt;/Security\u0026gt;\n\u0026hellip;\n\u0026lt;/Defaults\u0026gt;\nThe settings are defined below.\n###### Setting {style=\u0026ldquo;font-size: 10pt; font-family: Verdana, Arial, Helvetica, sans-serif; ###### Default {style=\u0026ldquo;font-size: 10pt; font-family: Verdana, Arial, Helvetica, sans-serif; font-weight: bold; color: rgb(20, 50, 125); font-weight: bold; color: rgb(20, 50, 125); margin-top: 0pt; margin-bottom: 0pt;\u0026ldquo;} margin-top: 0pt; margin-bottom: 0pt;\u0026ldquo;}\nHosts: a list of LDAP URIs separated by spaces, for example “ldaps://myhost.org”. “ldaps://localhost”.\nBindDN: an LDAP DN specifying the user that will connect to LDAP will bind anonymously\nBindPassword: the password for the binding user, or the string “file:” followed by a path to a file from which to read the password. no password\nSearchMode: “CN” or “DN”. See below for more information. “CN”\nSearchRoot: the DN of the container with the user objects. the root of the directory\nNote You must specify this value if you are using an OpenLDAP server.\nSearchClass: the object class of the user objects. “inetOrgPerson”\nSearchAttr: the naming attribute to match against the certificate CN. “CN”\nSearchScope: “onelevel” or “subtree”. Whether to search only the SearchRoot container (“onelevel”) or that container and all child containers (“subtree”). “subtree”\nUIDAttr: the name of the UID-storing attribute. “uidNumber”\nGIDAttr: the name of the GID-storing attribute. “gidNumber”\nSearchTimeout: timeout in seconds for LDAP searches. “15”\nYou should have noted these values during “Planning for LDAP Binding” described above.\nSearching LDAP for Identities The OrangeFS server searches LDAP for the user object based on the user certificate’s subject DN.\nIf the SearchMode is “CN”, the CN (common name) of the certificate subject is used. It must match an object meeting these criteria:\n It is in or under the SearchRoot container (depending on SearchMode).\n It has an object class equal to the SearchClass\n It has its SearchAttr attribute matching the certificate CN. The search filter used is:\n  (\u0026amp;(objectClass={SearchClass})({SearchAttr}={Certificate CN}))\nThe UID and GID will be retrieved from the UIDAttr and GIDAttr attributes of the object. This UID and GID will be used for subsequent file system operations. If this search fails, an error will be printed to the server log and “operation not permitted” returned to the client.\nIf the SearchMode is “DN”, the certificate subject DN must match the LDAP user object DN exactly (case-insensitive). In this mode, SearchRoot, SearchClass, SearchAttr and SearchScopeare not used.\nOrangeFS will retry the connection if it can’t contact the LDAP server. It will try different servers on the URI list.\nLDAP and System Identities You can specify that an LDAP user object have a different UID/GID from its corresponding system user. For example, the system user “jsmith” can have UID/GID 500/100, but the LDAP user corresponding to “jsmith” might have UID/GID 550/500. However, OrangeFS utilities will still show the system login name associated with the OrangeFS UID/GID. In our example, OrangeFS utilities display files as owned by system UID 550 rather than “jsmith”. If you are using nsswitch (Name Service Switch) with LDAP you will not have this conflict. Otherwise, it is not recommended that the identities have mismatching UID/GIDs.\nCreating a New LDAP Directory The examples/certs directory included in the distribution contains scripts and files that can be used to create a new OpenLDAP directory.\nThe script pvfs2-ldap-create-dir.sh will create a new OpenLDAP directory and add some basic objects. Usage of the script is:\n./pvfs2-ldap-create-dir.sh [-p {prefix}] [-a {admin dn}] [-s {suffix dn}] [-w {admin password}]\n prefix: base directory for OpenLDAP installation, default /usr/local admin dn: DN of LDAP administrator; should end with suffix DN, default cn=admin,{suffix dn} suffix dn: base (topmost) DN of directory; default based on hostname, for example hostname acme.com would give dc=acme,dc=com admin password: LDAP administrator password, default “ldappwd”.  The script will create the new LDAP directory and add two organizational units, named \u0026ldquo;Users\u0026rdquo; and \u0026ldquo;Groups.\u0026rdquo; A user object for the system root account will be created with a random password. See “Adding Users to LDAP” below for information on changing the password.\nImportant The directory created is not secure. User passwords are stored in plaintext, and SSL/TLS security is not enabled.\nThe directory should only be used for testing, or as a starting point for a secure directory. Consult the OpenLDAP documentation for information on securing the directory.\nThese statements in the OrangeFS configuration file will configure this directory.\n\u0026lt;Defaults\u0026gt;\n\u0026hellip;\n\u0026lt;Security\u0026gt;\n\u0026hellip;\n\u0026lt;LDAP\u0026gt;\nHosts ldap://{hostname}\nBindDN {admin dn}\nBindPassword {admin password}\nSearchRoot ou=Users,{suffix dn}\nSearchScope onelevel\n\u0026lt;/LDAP\u0026gt;\n\u0026lt;/Security\u0026gt;\n\u0026hellip;\n\u0026lt;/Defaults\u0026gt;\nSubstitute the values in braces for the values used when creating the LDAP directory. All unspecified values are equal to the defaults.\nAdding Users to LDAP The ldapadd utility is used to add objects, including users, to an LDAP directory. LDAP utilities use LDIF files to describe objects. Consult the LDIF RFC (http://www.ietf.org/rfc/rfc2849.txt) for more information on the LDIF file format.\nIn examples/certs, the script pvfs2-ldap-add-user.sh will create a user based on the information for that user in /etc/passwd:\n./pvfs2-ldap-add-user.sh [-D {admin dn}] [-w {admin pw}] {logon name} {container dn}\nThe script will create a user with the CN equal to the logon name, located in the specified container. The uidNumber, gidNumber, displayName, homeDirectory and login shell attributes will be set to correspond to the system account fields (displayName corresponds to description). A random password will be created.\nTo change a user password, the ldapmodify utility is used. A wrapper script is provided in examples/certs:\n./pvfs2-ldap-set-pass.sh [-D {admin dn}] [-w {admin pw}] {user dn} {password}\nFor example:\n./pvfs2-ldap-set-pass.sh -D cn=admin,dc=acme,dc=com -w ldappwd cn=jsmith,ou=users,dc=acme,dc=com ‘sEcr3t!’\nThe script will store the password in LDAP in an encrypted format, using the slappasswd utility.\n   "
},
{
	"uri": "/build-configure/create_orangefs_configuration_file/",
	"title": "OrangeFS Config File",
	"tags": [],
	"description": "",
	"content": " Procedure The OrangeFS installation directory on the Build system will need an OrangeFS configuration file. You will enter basic information for this file in a program called pvfs2-genconfig. Once the configuration file has been created, you might need to make additional modifications (regarding security, for example) for the initial deployment.\n **Note **After standard installation, consult the [Administration Guide](Administration_Guide.htm) for details on the options and values available for fine tuning the configuration file.  To create the OrangeFS configuration file, follow these steps:\n Using pvfs2-genconfig, the configuration file will be automatically generated as follows:  /opt/orangefs/bin/pvfs2-genconfig /opt/orangefs/etc/orangefs-server.conf\nThe program presents a series of prompts to enter the required settings for your OrangeFS configuration file.\n Answer all the prompts to generate the configuration file in the etc directory. Following is a list of possible entries for these prompts:  Option/Setting\nDefault/Example Value\nDescription\nProtocol\ntcp\nProtocol choices are tcp, gm, mx, ib and portals. See Preview System Requirements for more details. Default is tcp. For multi-homed configurations, separate multiple protocols with commas, for example ib, tcp\n (tcp)\nPort number\n3334\nTCP/IP port number that each OrangeFS server will listen on. Default is 3334.\n (gm)\nPort number\n6\nGM port number (in the range of 0 to 7) that each OrangeFS server will listen on. Default is 6.\n (mx)\nBoard number\n0\nMX board number (in the range of 0 to 4) that each server will listen on. Default is 0.\npvfs2-genconfig assumes that all servers will use the same board number.\nEndpoint number\n3\nMX endpoint (in the range of 0 to 7) that each server will listen on. Default is 3.\npvfs2-genconfig assumes that all servers will use the same endpoint number.\n (ib)\nPort number\n3335\nTCP/IP port that each server will listen on for IB communications. Default is 3335.\npvfs2-genconfig assumes that all servers will use the same port number.\n (portals)\nPortal index\n5\nPortal index that each server will listen on for portals communications. Default is 5.\npvfs2-genconfig assumes that all servers will use the same portal index.\nData Directory\n/opt/orangefs/storage/data\nFull path + directory name where each OrangeFS server will store its data. Metadata Directory\n/opt/orangefs/storage/meta\nFull path + directory name where each OrangeFS server will store its metadata.\nLog Directory\n/var/log/orangefs-server.log\nFull path + file name where each server will write its log messages.\nServer Host Names\nDefault: localhost\nExample: ofs{1-4}\nHostname of each OrangeFS data server (server on which data directory is located). This should be the value returned by the hostname command. Syntax is node1, node2, \u0026hellip; or node{#-#,#,#}.\nData/Metadata Allowed\nyes\nEnter yes to keep metadata directory on same server as data directory. If you enter no, you are prompted to enter additional hostnames.\nSecurity Options Options that display for security are based on the security mode you chose when you built OrangeFS. The three security modes are default, key-based or certificate-based. Default\nNA\nNA If you select this security mode, you will not be prompted with any more security options. Key\nServer key file location\n/opt/orangefs/etc/orangefs-serverkey.pem\nFull path + file name where each server will store its public server key.\nKeystore location\n/opt/orangefs/etc/orangefs-keystore\nFull path + file name where each server will store its keystore.\nCertificate\nCA certificate file\n/opt/orangefs/etc/orangefs-ca-cert.pem Full path + file name where each server will store a copy of the CA certificate.\nCA private key file\n/opt/orangefs/etc/orangefs-ca-cert-\nkey.pem\nFull path + file name where each server will store its private key.\nUser certificate root DN\nC=US, O=OrangeFS\nThe distinguished name (DN) for any existing user certificates in your LDAP setup. User certificate expiration\n365 Enter the number of days a user certificate is in effect (before expiration)\nLDAP host list\nldap://localhost\nEnter the LDAP host or list of hosts. Syntax is ldap[s]://host[:port],\u0026hellip;\nLDAP bind user DN\ncn=admin,dc=acme,dc=com Enter the LDAP bind user\u0026rsquo;s DN. By default, will bind anonymously.\nLDAP bind password\npassword or passwd:/opt/orangefs/etc/ldappwd.txt\nLDAP bind password or passwd:file_path to specify text file with password.\nLDAP search mode\nCN Enter either CN or DN for the LDAP search mode.\nLDAP search root\nou=users,dc=acme,dc=com Enter the LDAP search root object\u0026rsquo;s DN. LDAP search class\ninetOrgPerson Enter the name of the LDAP search class. LDAP search attribute\ncn\nEnter the LDAP search attribute.\nLDAP search scope\nsubtree\nEnter either onelevel or subtree for the LDAP search scope.\nLDAP UID attribute\nuidNumber\nEnter the LDAP UID attribute.\nLDAP GID attribute\n*gidNumber* Enter the LDAP GID attribute.\nVerify Server List\nn\nAsks (y/n) if you want to redisplay the server hostnames you entered.\nNote Standard installation, as configured above, places file system storage directories inside the OrangeFS installation directory under opt for portability. These directories can be located elsewhere for system optimization and larger space allocations. For detailed information on all options in the OrangeFS configuration file, see the Administration Guide.\nWhen you are finished running pvfs2-genconfig, the OrangeFS configuration file is added to /opt/orangefs/etc.\nThe configuration file is a simple text file that can be opened and modified manually. While pvfs2-genconfig will query you about the most important options, default values are assigned to many additional options. You can consider changes for most of these defaults later after installation, when you can reference the Administration Guide for performance-tuning and optimization.\n     "
},
{
	"uri": "/build-configure/results_of_build_and_configure/",
	"title": "Results",
	"tags": [],
	"description": "",
	"content": " At the end of the Build and Configure step, the build system will include:\n An installation directory (/opt/orangefs) A configuration file (/opt/orangefs/etc/orangefs-server.conf) to be used by all servers associated with this installation.  If you chose key-based security mode, the build system will also include:\n A temporary directory where all keys and the keystore file were generated. A copy of the keystore file in the installation directory (opt/orangefs/etc/keystore).  If you chose certificate-based security mode, the build system will also include a CA certificate and key (orangefs-ca-cert.pem and orangefs-ca-cert-key.pem in /opt/orangefs/etc).\nInstallation Directory Following is a top-level list of the orangefs installation directory:\n/opt/orangefs \\$ ls\nbin include lib sbin share etc log\nFor file listings of all directories and subdirectories, see Directory/File Listing.\nConfiguration File Following is a sample OrangeFS configuration file:\n/opt/orangefs/etc \\$ cat orangefs-server.conf\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 50\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 1000\nServerJobBMITimeoutSecs 30\nServerJobFlowTimeoutSecs 30\nClientJobBMITimeoutSecs 300\nClientJobFlowTimeoutSecs 300\nClientRetryLimit 5\nClientRetryDelayMilliSecs 2000\nPrecreateBatchSize 0,32,512,32,32,32,0\nPrecreateLowThreshold 0,16,256,16,16,16,0\nDataStorageSpace /opt/orangefs/storage/data\nMetadataStorageSpace /opt/orangefs/storage/meta\nLogFile /var/log/orangefs-server.log\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias tweeks tcp://tweeks:3334\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs\nID 1600781381\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange tweeks 3-4611686018427387904\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange tweeks 4611686018427387905-9223372036854775806\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\nIf you enabled key- or certificate-based security, a \u0026lt;Security\u0026gt; context will also be in the configuration file.\nHere is an example \u0026lt;Security\u0026gt; context for key-based security:\n\u0026lt;Defaults\u0026gt;\n\u0026hellip;\n\u0026lt;Security\u0026gt;\nServerKey /opt/orangefs/etc/orangefs-serverkey.pem\nKeystore /opt/orangefs/etc/keystore\n\u0026lt;/Security\u0026gt;\n\u0026hellip;\n\u0026lt;/Defaults\u0026gt;\n\u0026hellip;\nHere is an example \u0026lt;Security\u0026gt; context for certificate-based security:\n\u0026lt;Defaults\u0026gt;\n\u0026hellip;\n\u0026lt;Security\u0026gt;\nCAFile /opt/orangefs/etc/orangefs-ca-cert.pem\nServerKey /opt/orangefs/etc/orangefs-ca-cert-key.pem\n\u0026lt;LDAP\u0026gt;\nHosts ldap://ldap01.acme.com\nBindDN cn=ofsadmin,dc=acme,dc=com\nBindPassword file:/opt/orangefs/etc/ldappw.txt\nSearchRoot ou=OrangeFS-Users,dc=acme,dc=com\nSearchMode CN\nSearchClass inetOrgPerson\nSearchAttr CN\nSearchScope subtree\nUIDAttr uidNumber\nGIDAttr gidNumber\nSearchTimeout 10\n\u0026lt;/LDAP\u0026gt;\n\u0026lt;/Security\u0026gt;\n\u0026hellip;\n\u0026lt;/Defaults\u0026gt;\n\u0026hellip;\nThe \u0026lt;Security\u0026gt; context can also be specified in a \u0026lt;ServerOptions\u0026gt; context for different settings on each server.\nFor more information, see OrangeFS Configuration File in the Administration Guide.\n     "
},
{
	"uri": "/add-servers/",
	"title": "Add Server(s)",
	"tags": [],
	"description": "",
	"content": "You add servers by copying the OrangeFS installation directory from the Build system to each Server system designated in your OrangeFS solution. You must also consider additional setup and configuration tasks for security. Then you can start up each server you have added.\nThe OrangeFS servers make up your actual file system. The servers provide the space across which all data and metadata are distributed and managed for optimal storage and retrieval.\nAdding servers includes the following topics:\n Copy OrangeFS Installation Directory Set up Security Run Review Results       "
},
{
	"uri": "/add-servers/copy_ofs_install_directory_servers/",
	"title": "Copy OrangeFS Server Installation Directory",
	"tags": [],
	"description": "",
	"content": "              Begin your deployment by copying the OrangeFS installation directory from the Build system to each Server system designated in your OrangeFS solution. These are the servers already identified in the OrangeFS configuration file.    System Requirements Any system that functions as an OrangeFS server requires a supported distribution of Linux.\nNote For more information on supported distributions, see Preview System Requirements.\nProcedure To add the required software to an OrangeFS server, copy the /opt/orangefs directory from the Build system:\nscp –r /opt/orangefs hostname:/opt\nwhere\u0026hellip;\nhostname = host name of the Server system\nImportant the default OrangeFS configuration is not compatible with the default SELinux configuration, for streamlined installation you can disable SELinux. This SELinux configuration will cause a \u0026ldquo;permission denied\u0026rdquo; error when you try to run OrangeFS.\nTo disable SELinux, use the following command:\necho 0 \u0026gt; /seLinux/enforce\nTo prevent SELinux from loading at boot time, edit /etc/seLinux/config and set the SELINUX value to “disabled”, for example,\nSELINUX=disabled\nThe command for disabling SELinux can vary, depending on your Linux version.\n      "
},
{
	"uri": "/add-servers/set_up_security_servers/",
	"title": "Set up Server Security",
	"tags": [],
	"description": "",
	"content": "              To use key-based security mode, you must copy the private keys you generated on the Build system to each of your Server systems. In future versions of OrangeFS, security will be simplified.    *Note* Neither the default nor certificate-based modes of security require any additional setup on Server systems. For these modes, see the next topic, Server Startup\nProcedure Copying Keys Manually To add a private key to an individual Server, copy the private key file from /opt/ofs_keys on the Build system to the Server system:\nscp –r /opt/ofs_keys/orangefs-serverkey-hostname.pem hostname:/opt/orangefs/etc/orangefs-serverkey.pem\nwhere\u0026hellip;\nhostname = host name of the Server system\nNote The above command line format assumes you generated your keys according to instructions in Set Up Security under the Build and Configure step.\nCopying Keys to Many Systems You can use a script file (provided with OrangeFS) to copy all of your private keys with one command if both the following statements are true:\n You have already copied the OrangeFS installation directory to all of your designated servers and any additional Linux systems on which you plan to use an OrangeFS client interface.\n You generated your security keys during the Build and Configure step, using the script provided with OrangeFS (pvfs2-gen-keys.sh).\n  Note For more information about client interfaces, see Add Clients.\n If both the above statements are true, you can add private keys to all your Linux-based OrangeFS systems as follows:\n Change Directory (cd) to the /opt/ofs_keys directory on the Build system:  cd /opt/ofs_keys\n  If you followed the security setup instructions under the earlier Build and Configure step, the script file should be in the current directory and you can skip this step. Otherwise, copy the script from the OrangeFS source directory as follows:  cp /tmp/src/orangefs-version/examples/keys/pvfs2-dist-keys.sh\n  With the script named pvfs2-dist-keys.sh, use the following command format to copy private keys to all OrangeFS Linux systems:  ./pvfs2-dist-keys.sh orangefs_install\nwhere\u0026hellip;\norangefs_install = the location of the OrangeFS installation directory\nExample: /opt/orangefs\n Example of full command:\n./pvfs2-dist-keys.sh /opt/orangefs\nIf the above example is used, the script examines the key filenames to determine the hostname for each target server or client, then secure-copies (scp) each key accordingly to the /opt/orangefs/etc directory of the relevant system. Note The script assumes that the specified OrangeFS installation directory already exists on all of the targeted systems. The above example uses the default location for the instructions in this Installation Guide.\n     "
},
{
	"uri": "/add-servers/server-startup/",
	"title": "Server Startup",
	"tags": [],
	"description": "",
	"content": "              You will use the OrangeFS server daemon (pvfs2-server) on each server to initialize the storage directories and start the OrangeFS server process.    Procedure Running the server involves two tasks:\n Initializing the working directories on each server for storage space Starting the server process  The first task must be performed once on each server. Thereafter, you can start and stop the server process with a single command. Both tasks are accomplished with a command line statement that includes the OrangeFS server daemon (pvfs2-server), located in the OrangeFS installation directory under sbin.\nInitialize the Storage Directories To initialize the storage directories, run the following command on each server:\n/opt/orangefs/sbin/pvfs2-server -f -a [hostname] /opt/orangefs/etc/orangefs-server.conf\nThe -f option indicates that the file system storage directories should be initialized. This command creates the storage directories using the locations provided in the orangefs-server.conf file. The storage directories created will be /opt/orangefs/storage/{data,meta} with additional subdirectories under both storage locations.\nNotes Because each server has different data based on the handle ranges provided with the orangefs-server.conf file, do not copy one set of databases to each server. You must create them separately on each server.\nThe storage space on each OrangeFS server must be initialized only once. You can change the locations for storage directories by manually adding the \u0026lt;ServerOptions\u0026gt; section in OrangeFS configuration file. With this method, you can specify unique directory locations for each server. For detailed information on all options in the OrangeFS configuration file, see the Administration Guide.\nStart the Server Process To start the server process, enter the following command:\n/opt/orangefs/sbin/pvfs2-server -a hostname /opt/orangefs/etc/orangefs-server.conf\n Starting the Server Process Automatically To avoid repeating this command each time you reboot an OrangeFS server, you can place the statement in the appropriate system file(s) for automatic execution. For more information, see Automating System Startup.\n Stopping the Server Process To stop the server process, enter the following command:\nkillall pvfs2-server\n      "
},
{
	"uri": "/add-servers/results_of_add_servers/",
	"title": "Add Server(s) Results",
	"tags": [],
	"description": "",
	"content": "At the end of the Add Servers step, each Server system will include an OrangeFS installation directory (/opt/orangefs).\nIf you are using key-based security mode, each Server system will also include its own private key in /opt/orangefs/etc.\n     "
},
{
	"uri": "/nix-clients/",
	"title": "OrangeFS Clients",
	"tags": [],
	"description": "",
	"content": " Client access to OrangeFS is flexible, with support for a variety of operating environments and interfaces.\nDepending on the Client you wish to select, your Client system might run Linux, Windows, MacOS X or even Apache (web-based), as shown here:\n   Client Interface Client System (Operating Environment)     Kernel Module Linux   Direct Interface Linux (Kernel bypass)   FUSE MacOS X and Linux   ROMIO (MPI-IO) Linux   Windows Client Windows   Apache WebDAV / S3 Multiplatform Web Access    Generally, the requirements for these client solutions can be addressed separately, as their instructions assume the file system servers are already installed and running.\nThis topic further summarizes client options in two parts:\n Client Matrix Client Architecture Diagram  Client Matrix    Client Description Typical Uses Advantages     Linux Kernel Module Enables access to OrangeFS through the native Linux operating environment. For Linux users who wish to access OrangeFS as a mounted file system, using standard tools like ls, cp and rm. Supports standard out-of-the-box Linux kernels.   Linux Direct Interface Provides program libraries that allow developers to call standard functions (open, close, read, write, etc.) that communicate with OrangeFS servers directly, bypassing the Linux kernel. For advanced users who can benefit from higher access speeds or targeted programming access to OrangeFS. Bypasses the Linux Kernel for improved performance. Interoperability between application programs. Provides three levels of access in varying performance versus ease-of-use combinations.   ROMIO (MPI-IO) ROMIO is an implementation of the MPI-IO protocol that includes support for OrangeFS. Access to OrangeFS in programs and operations optimized for parallel computing. Any MPI Library implementation that works with ROMIO (such as MPICH and OpenMPI) can also work with OrangeFS.   FUSE targeted for MacFuse Allows access to OrangeFS file systems through FUSE (Filesystem in Userspace), which provides its own kernel module/driver to mount a file system. For FUSE interface users who want to use OrangeFS for their file system storage. Adds performance advantages of OrangeFS to a MacFUSE front end.   Windows Client Enables access to OrangeFS through Microsoft Windows environment. Native, transparent access to OrangeFS from Windows. Parallel protocol perforance directly from Windows.   Hadoop Client Enables MapReduce, the processing engine for Hadoop, to replace its standard file system (HDFS) with OrangeFS. For Hadoop-based, data-intensive, distributed applications. Can improve MapReduce performance and provides more ways to leverage data with the OrangeFS feature set.   WebDAV Apache Module Allows any WebDAV client access to OrangeFS via an Apache server. Access OrangeFS data via HTTP. Native WebDAV access to OrangeFS.   S3 Apache Module Allows any S3 client access to OrangeFS via an Apache server. For using the S3 file access protocol. Numerous client tools already exist.    Client Architecture Diagram The following diagram depicts the primary OrangeFS components that enable each client interface to connect to the file system.\n          "
},
{
	"uri": "/nix-clients/pvfs2tab-file/",
	"title": "pvfs2tab",
	"tags": [],
	"description": "",
	"content": "   Each client must know where to access OrangeFS resources. The pvfs2tab file, similar to the /etc/fstab file in Linux, provides clients with this access information. It involves creating a file at a designated path, which will function as the gateway to your OrangeFS installation.\n Determine the URL of the OrangeFS server you will access.  You can retrieve this information from the orangefs-server.conf file. For example, the first URL listed in that file can be extracted with the following command:\ngrep \u0026ldquo;Alias \u0026rdquo; /opt/orangefs/etc/orangefs-server.conf | awk \u0026lsquo;{ print \\$3 }\u0026rsquo; | head -n 1\nThe format to use for server URL is protocol://hostname:port.\nExample: tcp://server1:3334\n Create a file named pvfs2tab in the system\u0026rsquo;s /etc directory that tells the system how to access OrangeFS:  echo \u0026ldquo;tcp://server1:3334/orangefs /mnt/orangefs pvfs2 defaults,noauto 0 0\u0026rdquo; \u0026gt;\u0026gt;\n/etc/pvfs2tab\nNote In the above example, tcp: is the network protocol, //server1 is the server providing access to the configuration file, and 3334 is the number of the TCP/IP port on which the OrangeFS servers communicate, which was determined in step 1; /mnt/orangefs is the path you use to access these files. You can think of /mnt/orangefs as the root directory of the OrangeFS file system.\n You must also assign read-access to the new file:  chmod a+r /etc/pvfs2tab\n If you want to use an alternative file path instead of the standard location of /etc/pvfs2tab, you can set the PVFS2TAB_FILE environment variable to the desired path.        "
},
{
	"uri": "/nix-clients/linux-kernel-module/",
	"title": "Linux Kernel Module",
	"tags": [],
	"description": "",
	"content": "The Kernel Module enables access to OrangeFS through the native Linux IO interfaces. Starting with the Linux Kernel verwsion 4.6, OrangeFS is available natively in the kernel source. The code that is upstream is recommended for kernel IO, the OrangeFS team has focused on improving the up stream module for several years thus it is recommended to use this version vs. the one that is in the orangefs repo.\n   Linux Kernel Version Features     4.6 First release of the Linux Kernel with OrangeFS kmod included   4.9 Read Cache Integrated   5.2 Full Read and Write Linux page cache integration, significantly improved small IO performance    If you are using the Upstream Linux Kernel Module, which is highly recommended, you can enable it using the following command:\n modprobe orangefs\n Insert the Kernel Module The kernel module (pvfs2.ko) can be found under the OrangeFS installation directory. To insert the module you can use this find/install statement, generally this should be for systems using older than the 4.6 Linux Kernel:\n insmod find /opt/orangefs -name pvfs2.ko\n     "
},
{
	"uri": "/nix-clients/direct-interface/",
	"title": "Linux Direct Interface",
	"tags": [],
	"description": "",
	"content": " The Direct Interface allows you to access OrangeFS in a cluster similar to Linux (POSIX-based); however, the Direct Interface (also known by usrint, the system folder in which it is stored) bypasses the Linux Kernel for a more direct and better performing path to OrangeFS. It provides high performance access for programs that are not written for MPI.\nImportant The OrangeFS Direct Interface using Global Configuration will work only on systems configured with shared C libraries.\nThe Direct Interface is included with the OrangeFS standard installation, accessed by copying appropriate files to a client location and activating it with configuration statements.\nThis topic is organized into two sections:\n Understanding_the_Interface_Levels Configuring_the_Direct_Interface  Note To learn about System Calls for the Direct Interface, see System Calls in the Administration Guide.\nUnderstanding the Interface Levels The Direct Interface offers three levels of access, so you must configure your access based on the level that works best for your needs. The following illustration shows the three interface levels.\nDescriptions of the three levels:\nLevel Library Description\n1 System Call Library The first and lowest level is an API with OrangeFS-specific functions that can be substituted for each of the basic POSIX defined I/O related system calls. Essentially, each POSIX system call is replicated in the API. What makes this API different is that each function ONLY works with files in the OrangeFS file systems.\n2 POSIX Library The next layer is a POSIX system call interposition library. Each of the same POSIX system calls represented in the lower layer are provided in this API, this time with the same interface syntax as Linux POSIX. Rather than calling the Linux kernel directly, each call is checked to see if it refers to an OrangeFS file, and if so the call is made to the corresponding function in the lower level API. Thus a call to open() will call pvfs_open() if the path refers to an OrangeFS file; otherwise it will call the Linux open system call. This API is more convenient, though slightly less efficient, than the lower level one.\n3 C Library Finally, many programmers prefer to use the C library interface rather than the system call interface to file I/O, in part because it provides I/O buffering and a richer set of interface options. Any C calls are implemented using the POSIX calls, and so their implementation can, in theory, be linked from the C library, and use the OrangeFS POSIX interposition API.\n Virtually all modern Linux systems use shared libraries for the C library. Shared libraries tend to link all of the various functions at various levels into a single shared object that is loaded dynamically. Thus, if you call fopen() using the standard shared C library, there is no means to get that function to call the OrangeFS pvfs\\_open() function. For this reason, OrangeFS provides its own implementation of these functions in an OrangeFS C Library interposition API. These functions are identical to those in the standard C library implementation, except that they call the OrangeFS functions, and, in some cases, can be optimized for specific OrangeFS features.   Configuring the Direct Interface This section explains two methods for configuring the Direct Interface.\nProgram_Configuration Use this method to specify an individual program to run through the OrangeFS Direct Interface. Global_Configuration Use this method to specify that all programs will run through the OrangeFS Direct Interface.\n Program Configuration Programs, and higher level libraries, written to any of the three library levels included in the Direct Interface should link to the appropriate OrangeFS replacement library (liborangefsposix or liborangefs) to directly access the OrangeFS file system. The command for this configuration also determines whether to use a shared or static version of the library.\nTo link a program with the replacement library, include the following command when compiling the program:\ngcc -o program program_source -Lorangefs_lib_path -rep_lib\nwhere\u0026hellip;\nprogram = the name of your program, including the path\nprogram_source = the name of your program source code, including the path\norangefs_lib_path = path to lib directory in the OrangeFS installation directory\nrep_lib = one of the following options:\nIf your program is written to: Enter this option: To use this replacement library: C Library or POSIX Library -lorangefsposix liborangefsposix OrangeFS System Call Library -lorangefs liborangefs\nExample command line:\ngcc -o /programs/foo /programs/foo.c -L/opt/orangefs/lib -lorangefsposix\n Global Configuration Programs not specifically recompiled to use OrangeFS can still be redirected to do so by preloading the shared version of the appropriate OrangeFS replacement library (libofs and/or libpvfs2). You must configure the source to build the shared library before compiling OrangeFS.\nAssuming the shared libraries are installed, set the following environment variables:\nexport OFS_LIB_PATH=orangefs_lib_path\nexport LD_LIBRARY_PATH=\\$OFS_LIB_PATH:\\$LD_LIBRARY_PATH\nexport LD_PRELOAD=\\$OFS_LIB_PATH/rep_shared_library\nwhere\u0026hellip;\norangefs_lib_path = path to lib directory (in the OrangeFS installation directory)\nExample: /opt/orangefs/lib\nrep_shared_lib = one of the following replacement library files:\nTo redirect programs written to: Use these replacement library files: C Library or POSIX Library libofs.so and libpvfs2.so OrangeFS System Call Library libpvfs2.so\nExample: LD_PRELOAD=\\$OFS_LIB_PATH/libpvfs2.so\n Notes The global configuration method does not work if you use the static version of libc.\nEnsure that your system\u0026rsquo;s /etc/ld.so.preload includes libdl, libssl, libcrypto and libpthreads preloaded through /etc/ld.so.preload. Most Linux systems will already include this.\nIf this configuration method is used in the shell, every program (including such commands as ls, vi and cp) will redirect through the OrangeFS libraries. You can set these variables in a script to affect only the desired commands.\nIf all users on a system want the shared libraries preloaded, the system administrator can edit the file /etc/ld.so.preload and list the libraries there.\n      "
},
{
	"uri": "/nix-clients/romio-interface/",
	"title": "Linux ROMIO MPI Interface",
	"tags": [],
	"description": "",
	"content": " ROMIO is a particular implementation of the MPI-IO protocol, the open standard for data transfer to and from MPI.\nMPI, also an open standard, was created for researchers who needed a message-passing interface optimized for high performance parallel computing.\nDifferent working implementations for MPI, also called MPI libraries, exist. Two popular MPI libraries are MPICH from Argonne National Laboratory and Open MPI from a consortium of users including Oak Ridge National Laboratory.\nDifferent implementations of MPI-IO also exist. The ROMIO implementation includes support for OrangeFS. Therefore, any MPI library implementation that works with ROMIO, such as MPICH and Open MPI, can also work with OrangeFS.\nSetting up a ROMIO client involves one step, with options for configuring Open MPI or MPICH:\n Configuring for Linux\n Install OrangeFS 2.9 with MPICH 3.0.4\n Install OrangeFS 2.9 with Open MPI 1.6.5\n  Configuring for Linux Both MPICH and Open MPI are packaged with ROMIO. Configuring either of these MPI implementations to access OrangeFS involves two areas:\n Adding OrangeFS installation files\n Linking programs to OrangeFS\n  Adding OrangeFS Installation Files To add the OrangeFS installation files to the MPI client system, Change Directory (cd) to /opt on the client and copy the /opt/orangefs directory from the build system:\nscp -r hostname:/opt/orangefs /opt\nwhere\u0026hellip;\nhostname = host name of the build system\nLinking Programs to OrangeFS When you run your Open MPI or MPICH applications, link to OrangeFS by including the -lpvfs2 option.\nFor example, to run a program called mytest, you would follow these steps:\n Compile and link the program to the pvfs2 library in your OrangeFS installation:  cc mytest.c -o mytest -L /opt/orangefs/lib -L /mpich2_install_dir/lib -I /opt/orangefs/include -I /mpich2_install_dir/include -lpvfs2 -lmpich\nwhere\u0026hellip;\nmpich2_install_dir = the name and path of your MPICH installation directory\nOther Operating Environments ROMIO can also run on Windows and Mac. Those platforms are less efficient for the high performance parallel computing that most ROMIO users seek in OrangeFS, so the above instructions focus on Linux client implementations only.\n To connect to OrangeFS from a Windows environment, consider using the Windows Client developed specifically for OrangeFS. To connect to OrangeFS from a Mac environment, consider using FUSE.  Install OrangeFS 2.9 with MPICH 3.0.4 Notes You must install OrangeFS on your storage nodes and the OrangeFS system must be online prior to performing these steps. If you have not completed this step, see the Installation Guide for instructions to complete this step before proceeding.\nFor instructions on how to use MPICH, see MPICH User\u0026rsquo;s Guide.\nSecure Shell (SSH)—without Passphrase You must configure all clients to support secure shell connections via SSH without passing a passphrase. For more information, see Generating SSH Keys for Passwordless Login, an article from the Hortonworks Knowledgebase.\nPrior to configuring MPICH, ensure that you have built shared libraries for OrangeFS:\n Run the same ./configure command you used when you installed OrangeFS, but add the following additional option:  \u0026ndash;enable-shared\nTo configure OrangeFS to work with MPICH 3.0.4, complete the following steps:\n Run the following commands to remove references to methods included in MPICH that will cause errors during the ./configure stage.  Note You will not be able to use the MPI/IO functions IReadContig and IWriteContig.\nsed -i s/ADIOI_PVFS2_IReadContig/NULL/ src/mpi/romio/adio/ad_pvfs2/ad_pvfs2.c\nsed -i s/ADIOI_PVFS2_IWriteContig/NULL/\nsrc/mpi/romio/adio/ad_pvfs2/ad_pvfs2.c\n Compile MPICH with \u0026ndash;enable-shared option:  ./configure \u0026ndash;prefix=/opt/mpich-3.0.4 \u0026ndash;enable-romio \u0026ndash;enable-shared \u0026ndash;with-pvfs2=/opt/orangefs \u0026ndash;with-file-system=pvfs2\nwhere\u0026hellip;\n/opt/orangefs = the location of your OrangeFS installation\n/opt/mpich-3.0.4 = the location of your MPICH installation\nNote You can remove the \u0026ndash;prefix command to install to/usr/local\n Make and install freshly compiled MPICH 3.0.4 with OrangeFS Support  ·sudo make all install\n Set LD_LIBRARY_PATH to point to the MPICH libs  export LD_LIBRARY_PATH=/opt/mpich-3.0.4/lib:\\$LD_LIBRARY_PATH\nwhere\u0026hellip;\nopt/mpich-3.0.4 = the location of your MPICH installation\nInstall OrangeFS 2.9 with Open MPI 1.6.5 Notes You must install OrangeFS on your storage nodes and the OrangeFS system must be online prior to performing these steps. If you have not completed this step, see the Installation Guide for instructions to complete this step before proceeding.\nOrangeFS 2.9.0 has been successfully tested with OpenMPI 1.8.3 on CentOS 7. No patches are necessary to run OrangeFS with OpenMPI 1.8.3. If you are using this version, skip steps 1 and 2 below, and change the OpenMPI version number in step 3.\nFor instructions on how to use Open MPI, see Open MPI: Open Source High Performance Computing.\nSecure Shell (SSH)—without Passphrase You must configure all clients to support secure shell connections via SSH without passing a passphrase. For more information, see Generating SSH Keys for Passwordless Login, an article from the Hortonworks Knowledgebase.\nPrior to configuring MPICH, ensure that you have built shared libraries for OrangeFS:\n Run the same ./configure command you used when you installed OrangeFS, but add the following additional option:  \u0026ndash;enable-shared\nTo configure OrangeFS to work with Open MPI 1.6.5, complete the following steps.\n Patch the Open MPI 1.6.5 source to support OrangeFS: Patch the Open MPI installation using the openmpi-1.6.5-romio.patch file. This patch is available on the OrangeFS  patch -p0 \u0026lt; openmpi-1.6.5-romio.patch\n Run the following commands to remove references to methods included in Open MPI that will cause errors during the ./configure stage.  Note You will not be able to use the MPI-IO functions IReadContig and IWriteContig.\nsed -e \u0026rsquo;s/ADIOI_PVFS2_IReadContig/NULL/\u0026rsquo; \\\n-i ompi/mca/io/romio/romio/adio/ad_pvfs2/ad_pvfs2.c\nsed -e \u0026rsquo;s/ADIOI_PVFS2_IWriteContig/NULL/\u0026rsquo; \\\n-i ompi/mca/io/romio/romio/adio/ad_pvfs2/ad_pvfs2.c\n Compile Open MPI with the \u0026ndash;enable-shared and \u0026ndash;with-pic options:  ./configure \u0026ndash;prefix=/opt/openmpi-1.6.5 \u0026ndash;enable-shared \u0026ndash;with-pic \u0026ndash;with-io-romio-flags=\u0026ldquo;\u0026ndash;with-pvfs2=/opt/orangefs \u0026ndash;with-file-system=pvfs2\u0026rdquo;\nwhere\u0026hellip;\n/opt/orangefs = the location of your OrangeFS installation\n/opt/openmpi-1.6.5 = the location of your Open MPI installation\nNote You can remove the \u0026ndash;prefix command to install to/usr/local\n Make and install freshly compiled Open MPI 1.6.5 with OrangeFS Support  ·sudo make all install\n Set LD_LIBRARY_PATH to point to the Open MPI libs  export LD_LIBRARY_PATH=/opt/openmpi-1.6.5/lib:\\$LD_LIBRARY_PATH\nwhere\u0026hellip;\n/opt/orangefs = the location of your OrangeFS installation\n/opt/openmpi-1.6.5 = the location of your Open MPI installation\n    "
},
{
	"uri": "/nix-clients/advanced-linux-client-security/",
	"title": "Linux Client Advanced Security Modes",
	"tags": [],
	"description": "",
	"content": "              After you copy the OrangeFS installation directory, you must perform additional setup and configuration for the advanced key-based and certificate-based security modes.    For key-based security, most of this work can be done once on the build system, then copied later to your servers and clients.\nThis topic includes sections for setting up two types of security:\n Key-Based Security Certificate-Based Security   Key-Based Security Each client has its own key pair, consisting of a private key and a public key that are cryptographically related. The private key is kept secret while the public key can be distributed. A file used by the servers known as the keystore contains public keys for all servers and clients in the OrangeFS system. When a client sends a request to the server, it submits a credential object which is signed by its private key. The server verifies the signature using the known public key of the client.\nNote All OrangeFS clients and servers must be built for the same security mode (key-based in this case) to interoperate.\nGenerating Client Private Keys Like servers, all client systems must have a key pair. Because you need to build the keystore file for the servers, you should create the client private keys on a single server—typically the one you used to create the server private keys. You can then distribute them to the clients.\nThe openssl command used is the same as for the server, although for performance reasons the size of the key (in bits) is less:\nopenssl genrsa -out pvfs2-clientkey.pem 1024\nThe size of the client private key, 1024 bits, is usually half the size of the server keys (default 2048).\nThis file is typically stored in the etc directory under the OrangeFS installation directory, /opt/orangefs/etc by default.\nKeys for multiple clients can be generated in a temporary directory and distributed to the client systems in a similar fashion as the server keys.\nConfigure Client for Key-Based Security On OrangeFS client systems, the private key should be readable only by root:\nchmod 600 /opt/orangefs/etc/pvfs2-clientkey.pem\nThe default private key location is pvfs2-clientkey.pem in the etc directory under the OrangeFS installation directory, for example /opt/orangefs/etc/pvfs2-clientkey.pem. You can override this location by using the \u0026ndash;keypath parameter when running pvfs2-client. Example:\n/opt/orangefs/sbin/pvfs2-client \u0026ndash;keypath \\\n/usr/local/orangefs/etc/pvfs2-clientkey.pem\nCopy Files to Client The script pvfs2-dist-keys.sh distributes private keys and the keystore to multiple systems using scp. The keys should have been generated with the pvfs2-gen-keys.sh script as described in the Administration Guide.\nNote The script requires one argument: the installation directory of OrangeFS which must be the same on all systems. This directory must exist prior to executing the script.\nAn example using the default location:\n./pvfs2-dist-keys.sh /opt/orangefs\nThe script examines the key filenames to determine the hostname of the target server or client. For example, the server file orangefs-serverkey-orangefs-server01.pem will cause the script to execute this command, given /opt/orangefs as the installation directory:\nscp orangefs-serverkey-orangefs-server01.pem orangefs-server01:/opt/orangefs/etc/orangefs-serverkey.pem\nGenerate a client private key as instructed in the Administration Guide and append its public key to the keystore. Distribute the private key to the client system and the keystore to all servers.\nTo remove a client, edit the keystore file and remove the hostname identifier (for example “C:client01”) and the public key that follows. Distribute this updated keystore file to all servers.\nCurrently in key-based security when a client is added to (or removed from) your OrangeFS installation, all servers must be stopped and restarted. The keystore is read only at server startup, so you would generally add clients during a maintenance period. Certificate-Based Security can be used if a more dynamic system is needed.\nCertificate-Based Security Note All OrangeFS clients and servers must be built for the same security mode (certificates, in this case) to interoperate.\nPrior to configuring your client(s) for certificate-based security, you must configure your servers and create a CA certificate. See Building OrangeFS for Certificate-Based Security for steps to take before configuring clients.\nThen, install OpenSSL client libraries to the client system if necessary. (Consult your OS distribution documentation for more information.)\nUser Certificate Application A client application, pvfs2-get-user-cert, is installed to allow users to request and receive a user certificate with no intervention from the administrator.\nYou must configure the client system to connect to a running OrangeFS server; the file pvfs2tab, located in /opt/orangefs/etc by default, contains the necessary configuration information. (See pvfs2tab File for more information on pvfs2tab.)\nThe requesting user must have an identity (user account) in the LDAP directory before requesting a certificate. See Configuring LDAP for Identity Mapping for more information.\nThe usage of pvfs2-get-user-cert is:\npvfs2-get-user-cert [user name]\nIf the optional user name is not supplied, the user name of the currently-active user account will be used. The user will be prompted for their LDAP directory password. Once this is entered correctly, the user certificate and private key are stored as ~/.pvfs2-cert.pem and ~/.pvfs2-cert-key.pem, respectively.\nObtaining a User Certificate Manually If you do not want users to use the pvfs2-get-user-cert application, they can create a certificate request, which an administrator can use to generate a certificate.\nCreating a User Certificate Request A certificate request is a file indicating what values should be in the requested certificate. A user can generate the request and submit the file to the administrator for signing by the CA certificate. In a production environment, it is not secure for users to sign their own certificates.\nTo generate a certificate request, execute this command:\nopenssl req -newkey rsa:1024 -config pvfs2-user.cnf -keyout pvfs2-cert-key.pem -nodes -out pvfs2-cert-req.pem\nNote pvfs2-user.cnf is in the examples/certs directory.\nYou can use different file names. The user will be prompted to enter subject values, which should follow some organization-defined naming scheme.\nNote The common name of the certificate subject will be used for UID/GID-mapping later, so take note of it.\nThe user can then submit (for example via email) the certificate request (but not the private key) to the administrator for signing.\nA script named pvfs2-cert-req.sh is in examples/certs for this step. It takes a name as an optional parameter (default “pvfs2”):\n./pvfs2-cert-req.sh pvfs2\nSigning a User Certificate Request The administrator will sign the certificate request with the CA private key. Execute this command:\nopenssl x509 -req -in pvfs2-cert-req.pem -CA orangefs-ca-cert.pem -CAkey orangefs-ca-cert-key.pem -days 365 -out pvfs2-cert.pem\nThe file names should correspond with file names used in prior steps. Return the resulting certificate file (pvfs2-cert.pem above) to the user.\nA script named pvfs2-sign-cert.sh is in examples/certs. It takes the cert name and the CA name as optional parameters (defaults “pvfs2” and “orangefs” respectively):\n./pvfs2-cert-sign.sh pvfs2 orangefs\nThe files pvfs2-cert.pem and pvfs2-cert-key.pem can then be sent to the user (for example via email).\nStoring the User Certificate The user can now store the certificate and private key files. The default file names used by OrangeFS are ~/.pvfs2-cert.pem for the certificate file and ~/.pvfs2-cert-key.pem for the key file. Note the “.” preceding both names, which marks them hidden. The private key and certificate should have permissions revoked for other users:\nmv pvfs2-cert.pem~/.pvfs2-cert.pem\nmv pvfs2-cert-key.pem~/.pvfs2-cert-key.pem\nchmod 600~/.pvfs2-cert*.pem\nThese locations can be overridden with the PVFS2CERT_FILE and PVFS2KEY_FILE environment variables. These variables are used when accessing OrangeFS through a client application (sysint\u0026ndash;for example pvfs2-ls) or library (usrint); they are not used if OrangeFS is mounted through the kernel module.\n     "
},
{
	"uri": "/nix-clients/fuse-client/",
	"title": "FUSE Client",
	"tags": [],
	"description": "",
	"content": " Filesystem in Userspace (FUSE) is a loadable kernel module for UNIX-like computer operating systems that lets non-privileged users create their own file systems without editing kernel code. File system code is run in user space while the FUSE module provides only a bridge to the actual kernel interfaces.\nThe OrangeFS client interface for FUSE enables access to an OrangeFS file system from a Mac.\n*Note* While FUSE can run on both Linux and Mac. Linux users will achieve better results with the up-stream Linux Kernel module and Direct Interface.\nSetting up a FUSE client involves four main steps on your Mac system:\n Install FUSE\n Install OrangeFS\n Mount an OrangeFS Server\n Set up Security\n  Install FUSE The recommended FUSE distribution for the Mac is Fuse4x.\nFuse4x can be downloaded using Apple\u0026rsquo;s port mechanism or from the Web at http://fuse4x.github.io/.\nTo get fuse4x using the port command:\nport install fuse4x\nNote  At the time of this Installation Guide’s initial release, Fuse4x had been recently tested on OrangeFS using the Darwin Kernel Version 11.4.2.\nFuse4x documentation on its website will guide you through the installation process.\nInstall OrangeFS OrangeFS must be downloaded and built in the OS X environment on your Mac system.\nImportant Copying the OrangeFS installation directory from your Linux Build system to a Mac system will not work. You must build it separately.\nPrerequisites Prior to installing OrangeFS, you must install gcc, flex, bison, make, and openssl-devel as described in Additional Linux Software for the Build System.\nProcedure To build OrangeFS on your Mac system, follow these steps:\n Go to www.orangefs.org. If your OrangeFS filesystem is using the latest released version, select  orangefs-\u0026lt;version\u0026gt;\nwhere\u0026hellip;\n\u0026lt;version\u0026gt; = version number of the OrangeFS distribution release\nExample: orangefs-2.9. If your OrangeFS filesystem is using an older version, select the New releases in the Previous Releases section on the OrangeFS downloads page. select your release then select the source link to find the tar ball.\nNotes The OrangeFS client and servers MUST be using the same version.\nFor systems using releases older than 2.8.2-1, the tar balls can be found by selecting the Previous releases link; however, these releases have not been recently tested. Use at your own discretion.\nIf using Safari to download, the tar ball will be automatically unzipped, producing an orangefs-\u0026lt;version\u0026gt;.tar file. In Firefox, you will download a zipped tar ball, orangefs-\u0026lt;version\u0026gt;.tar.gz.\n Change directory (cd) to  /Users/username/Downloads,\nwhere\u0026hellip;\nusername is the Mac username of the person creating this interface.\nLocate one of the following tar balls:\norangefs-\u0026lt;version\u0026gt;.tar or orangefs-\u0026lt;version\u0026gt;.tar.gz\nand extract the OrangeFS source files using one of the following commands:\nUnzipped:\ntar -xf orangefs-\u0026lt;version\u0026gt;.tar\nZipped:\ntar -xzf orangefs-\u0026lt;version\u0026gt;.tar.gz\nThen, change your working directory (cd) to orangefs-\u0026lt;version\u0026gt;.\n-xzf orangefs-\u0026lt;version\u0026gt;.tar.gz\ncd orangefs-\u0026lt;version\u0026gt;\n Build a Makefile for OrangeFS that includes the installation location and four other options as follows:  ./configure \u0026ndash;prefix=/opt/orangefs \u0026ndash;disable-server \u0026ndash;disable-usrint \u0026ndash;disable-opt \u0026ndash;enable-fuse\n Continue with the standard Linux commands to build and run an executable program:  make\nmake install\nThis will create the OrangeFS installation directory in /opt/orangefs. Within that directory, the binary you need to run FUSE, pvfs2fuse, will be located in the bin directory.\nMount an OrangeFS Filesystem Assuming you have network access to the OrangeFS filesystem, you must first create a mount point on your Mac.\nNote Confirm access to any of the servers using the ping command.\nTo mount an OrangeFS Server:\n Create a directory as the mount point. This directory can be anywhere on your Mac where you have create permissions:  mkdir /mnt/orangefs\n The FUSE client requires an OrangeFS filesystem specification defined as  URL/\u0026lt;filesystem name\u0026gt;\nwhere\u0026hellip;\nURL= any ONE of the OrangeFS servers that manages your filesystem, found with the filesystem name in the OrangeFS server conf file\nExample: orangefs-server.conf.\nThe URL value for each server in the filesystem is listed in the \u0026lt;Aliases\u0026gt; section, while the filesystem name is listed in the \u0026lt;Filesystem\u0026gt; section.\n\u0026lt;Aliases\u0026gt;\nclemson1 tcp://server1:3334\ntiger1 tcp://server2:3334\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName \u0026lt;filesystem name\u0026gt;\n\u0026hellip;\n\u0026lt;/Filesystem\u0026gt;\nThe filesystem spec in this case is one of two choices:\ntcp://server1:3334/\u0026lt;filesystem name\u0026gt;\ntcp://server2:3334/\u0026lt;filesystem name\u0026gt;\n Now you are ready to mount an OrangeFS filesystem, as follows:  /opt/orangefs/bin/pvfs2fuse /mnt/orangefs -o fs_spec=tcp://server1:3334/\u0026lt;filesystem name\u0026gt;\nNotes In the above example, tcp://server1:3334 is the URL of only one of the OrangeFS servers managing the given filesystem, determined in Step 2; /mnt/orangefs is the mount point created in Step 1.\nIf \u0026lsquo;root\u0026rsquo; issues the pvfs2fuse command, then all users of your Mac can access the filesystem. However, if \u0026lt;username\u0026gt; issues the command, only \u0026lt;username\u0026gt; has access.\nOnce the mount is successful, you can access your OrangeFS installation using common commands like ls and cp. For example:\nls /mnt/orangefs\nSet up Security Using Default Security By default, OrangeFS uses User and Group IDs to enforce file permissions. Files created using your Mac will be stored with your Mac UID and primary GID, so only you have access to your files. However, if you created files using one of the other OrangeFS clients, you might not have access to your files from the Mac, unless your Mac UID (or GID) happens to match the UID (or GID) in these other environments.\nTo alleviate this problem, you or your Mac administrator can create User IDs having the same UIDs and GIDs that match across platforms. We suggest that you do NOT change an existing user\u0026rsquo;s UID or primary GID. Instead, we recommend you create a new ID having the appropriate UID/GID values. Below is an example (Darwin Kernel Version 11.4.2) that creates a Mac user called \u0026ldquo;orangefs\u0026rdquo;, with a specific UID and GID from the command line:\n\\$ sudo dscl . create /Users/orangefs uid 500\n\\$ sudo dscl . create /Users/orangefs gid 5005\n\\$ sudo dscl . create /Users/orangefs shell /bin/bash\n\\$ sudo dscl . create /Users/orangefs home /Users/orangefs\n\\$ sudo dscl . create /Users/orangefs realname \u0026ldquo;orangefs\u0026rdquo;\n\\$ sudo dscl . create /Groups/orangefs gid 5005\n\\$ sudo dscl . create /Groups/orangefs passwd \\*\nTo create an \u0026ldquo;orangefs\u0026rdquo; group and set its GID to 5005:\n\\$ sudo dscl . create /Groups/orangefs gid 5005\n\\$ sudo dscl . create /Groups/orangefs passwd \u0026lsquo;*\u0026lsquo;\nTo add a user to this group:\n\\$ sudo dscl . merge /Groups/orangefs users \u0026lt;username\u0026gt;\nUsing Key Security If your OrangeFS file system is using key security, then the OrangeFS FUSE client must be built with key security enabled. Add \u0026ndash;enable-security-key to the \u0026ldquo;configure\u0026rdquo; command:\n./configure \u0026ndash;prefix=/opt/orangefs \u0026ndash;disable-server \u0026ndash;disable-usrint \u0026ndash;disable-opt \u0026ndash;enable-fuse \u0026ndash;enable-security-key\nYour OrangeFS system administrator will typically create a public/private key pair for your Mac and will give you the private key to store on your machine. By storing the private key as\n\u0026lt;prefix\u0026gt;/etc/pvfs2-clientkey.pem\nor, as in the above configure command,\n/opt/orangefs/etc/pvfs2-clientkey.pem\npvfs2fuse will automatically find and use this key. If you store the key with a different name or in a different location, you must first define the PVFS2KEY_FILE environment variable before issuing the pvfs2fuse command:\n\\$ export PVFS2KEY_FILE=\u0026lt;path-to-key\u0026gt;/\u0026lt;key filename\u0026gt;\nYour OrangeFS system administrator must create the public/private key pair using the hostname of your Mac. To determine the hostname, first ensure that you can ping at least one of the OrangeFS server machines. Then, issue the hostname command to get the value needed by the system administrator to create the correct public/private key pair.\nNotes The system administrator must add the public key to the OrangeFS keystore, copy the keystore to each server machine, then restart the servers before you will have access to the file system. See Setting up Key-Based Security Mode for more information.\nIf your Mac has a non-static IP address in your environment, you will have to regenerate a new public/private key pair each time the address changes.\nThe default security using UID and GID for file permissions is used in addition to the public/private key pair. See Using Default Security above.\n     "
},
{
	"uri": "/nix-clients/hadoop_installation/",
	"title": "Hadoop Client",
	"tags": [],
	"description": "",
	"content": " Apache Hadoop is an open source framework that supports data-intensive distributed applications. Hadoop has many parts, but two are fundamental:\n MapReduce is the framework that understands and assigns work to the nodes in a cluster. MapReduce divides the application into many fragments of work, each of which can be executed or re-executed on any node in the cluster.\n HDFS (Hadoop File System) spans all the nodes in a Hadoop cluster for data storage.\n  The OrangeFS Hadoop Client is an HCFS plug-in which allows you to run Apache Hadoop version 1.2.1 and 2.6.0 with the OrangeFS distributed file system replacing Hadoop\u0026rsquo;s HDFS filesystem. Together, these two open source products can perform massive computations on the petabyte scale. OrangeFS also permits modification of data within the file system.\nNotes You may also configure an existing Hadoop cluster using HDFS as the default distributed file system to use OrangeFS as an alternative storage solution.\nOther versions of Apache Hadoop 1.x.x and 2.x.x will likely work with the OrangeFS Hadoop Client but have not been fully tested. Brief instructions for building the OrangeFS Hadoop client for a particular Hadoop release are provided in the setup guides.\nPlanning For Installation Before you begin installing the OrangeFS Hadoop Client, you must select either an HPC or a traditional Hadoop storage option to use with the OrangeFS Hadoop Client. You can then preview the system and software requirements before moving on to the appropriate installation topic.\nUnderstanding the Architecture The basic design that enables MapReduce to work with OrangeFS integrates the OrangeFS Hadoop Client, the OrangeFS Java Native Interface (JNI) Shim, and the OrangeFS Direct Interface (DI).\nApache Hadoop is designed to support file systems other than HDFS through an abstract file system API. An implementation of this API, the OrangeFS Hadoop Client enables MapReduce to interface with the OrangeFS JNI Shim.\nThe OrangeFS JNI Shim utilizes the JNI, a programming framework that enables Java code running in a Java Virtual Machine to interface with native programs. In this case, the Java code is the OrangeFS Hadoop Client and the native code is the DI, with their interaction facilitated by the OrangeFS JNI Shim.\nThe OrangeFS DI is a Linux client interface written in C, which enables POSIX-like and direct system calls to the OrangeFS API, directing operations to OrangeFS data/metadata servers.\nUnderstanding Storage Options HPC vs. Traditional You can set up the OrangeFS storage for your OrangeFS Hadoop Client in two ways.\nSetup Options HPC In this setup, Hadoop MapReduce accesses an OrangeFS file system through a single mount point to any of the OrangeFS servers.   Traditional Hadoop This setup simulates a traditional Hadoop installation, running a client and server program on each server in an OrangeFS cluster. This model represents the colocated compute and storage resources typical of most Hadoop clusters.   Linux Operating System All server and client systems should use the same distribution of Linux. Guidelines for selecting a Linux distribution in Preview System Requirements also apply to any systems used with the OrangeFS Hadoop Client.\nNote For consistency, all topics about the OrangeFS Hadoop client use RHEL command line syntax wherever distribution-specific commands are required.\nCommon System Requirements The HPC and the Traditional Hadoop installation configurations share a number of common requirements.\nPreparing the Build System Many of the instructions will prepare the OrangeFS Hadoop Client build system, including downloading, installing and configuring both Hadoop and OrangeFS. For both configurations, the administrator should select a single node out of the desired pool of nodes which will run MapReduce to act as the build system. Some tasks affect all clients, while others are focused on the single build system. This will produce a directory of software that must be copied from the build system node to the desired installation directory on each client node.\nJDK The build system requires the Java Development Kit (JDK) to build the OrangeFS Hadoop Client and OrangeFS JNI Shim.\nNote For additional guidance on the appropriate JDK version, consult the Apache Hadoop recommendations.\nMaven To build the OrangeFS Hadoop Client, Maven must be installed on the build system.\nPreparing Individual Client Nodes JRE or JDK While some Apache Hadoop related projects require the JDK for proper functionality (Sqoop, for example), only the Java Runtime Environment (JRE) is required to run MapReduce on client nodes. Your requirements will determine which one you should install.\nNote It might be easiest to install the JDK on all client nodes, which produces no adverse results.\nHadoop Binaries The Hadoop binaries are required to “run” Hadoop and use the OrangeFS Hadoop Client. You must download, extract, and copy the Hadoop binaries archive to each node.\nSystem Variables On each client node, you must eventually set the environment variables LD_LIBRARY_PATH, JNI_LIBRARY_PATH, and PVFS2TAB_FILE to run MapReduce with OrangeFS.\nInstallation Requirement Differences Installation instructions are separated into two topics, according to your selected storage option. Following are some of the differences in their content.\nHPC Setup  Assumes that OrangeFS servers have already been configured and installed on the storage cluster. For more information on completing that setup process prior to setting up the OrangeFS Hadoop Client, see the beginning of the Installation Guide. Hadoop was not originally designed to work in a scheduled HPC environment, but you can use a customized version of myHadoop, myHadoop-orangefs, with PBS to support on-demand clusters. Additional steps are required to incorporate myHadoop-orangefs here. This approach has been tested with PBS Professional version 12.0.0.x and myHadoop-orangefs version 0.1.  Traditional Hadoop Setup  Assumes that you will configure and install OrangeFS client and server libraries/binaries on all desired nodes in your cluster.   "
},
{
	"uri": "/windows-client/",
	"title": "Windows Client",
	"tags": [],
	"description": "",
	"content": "The Windows Client provides native access to OrangeFS for desktops and servers using the Microsoft Windows operating system.\nThe Windows Client harnesses the power and speed of OrangeFS from the Windows platform, including scale-out storage access and high performance parallel computing with full programmatic access via standard parallel programming APIs.\nOptions for authentication and user mapping include LDAP and X.509 certificates. The Client, which runs as a standard Windows service, supports Windows Vista, Windows 7, Windows 8, and Windows Server 2008 R2 (all editions) and Windows Server 2012 (all editions; Server Core installation not currently supported); x86 and x64.\nThis Client enables you to view files though Windows Explorer and the Command Prompt, or you can access files programmatically through standard function calls, for example, fopen() in C.\nThe following topics guide you through the installation, operation and configuration of the Windows Client:\n [Preparing for Installation]((/windows-client/preparing_for_installation_windows/) [What to Expect]((/windows-client/what_to_expect_windows/) [Running the Installer]((/windows-client/running_the_installation_program_windows/) [Manual Installation]((/windows-client/manual_installation_windows/) [Uninstalling the Windows Client]((/windows-client/uninstalling_the_client_windows/) [Using the Client]((/windows-client/winclient_use/) [Client Administration]((/windows-client/winclient_admin/)         "
},
{
	"uri": "/windows-client/preparing_for_installation_windows/",
	"title": "Preparing for Windows Installation",
	"tags": [],
	"description": "",
	"content": " *Important* Please read this section before beginning installation of the Windows Client.\nClient Requirements Operating systems:\n Windows Vista Windows 7 Windows 8 Windows Server 2008 or Windows Server 2008 R2 (all editions; Server Core installation not currently supported) Windows Server 2012 (all editions; Server Core installation not currently supported)   Hardware:\n 30MB disk space Other requirements dependent on usage; minimum requirements very low   Other:\n You must assign a drive letter during installation. It is best to run the installer as an administrative user (Administrator, for example).   OrangeFS Requirements To connect to the OrangeFS server during installation, you must specify its URI. You must know the host name and port number (default is 3334). The format for this entry is provided later in the instructions.\n*Important* The OrangeFS installation accessed by the Windows Client must be configured for TCP network protocol.\nFile System Security Mode An OrangeFS file system operates in one of three security modes: default, key-based or certificate-based. All servers and clients must operate in the chosen mode. The “security-mode” option of the Windows Client configuration file (see “Windows Client Interface \u0026gt; Client Administration”) should be set to select the correct mode. See Preview Security for more information.\nAuthentication Configuration During installation you have four mode options for user mapping:\n list certificate ldap   The following table summarizes these options:\n   User Mode Option Description Best For\u0026hellip; Installation Input More to do after installation?     list Directly matches one Windows ID with one OrangeFS UID and primary GID. Simple, smaller installations, trial runs, etc. Enter one Windows user ID and the OrangeFS (Linux/UNIX-based) UID and primary GID for mapping. All but first user must be entered manually in the orangefs.cfg file after installation.   certificate Maps user digital certificate to OrangeFS UID/GID. Our recommended setup is for grid computing, which requires CA, proxy and user certificates. Important You must install and configure your certificates before installation. A recommended method for doing this is included in these instructions. Scientific, large cluster, research, etc. Specify the Windows prefix directory of your user and proxy certificates. This might be either the user\u0026rsquo;s profile directory or a custom directory, which you must enter: c:\\users\\ or cert-dir-prefix If your certificates were properly installed and configured before installation, nothing else should be required.   ldap Maps user(s) on an LDAP tree to OrangeFS UIDs/GIDs. Windows with Active Directory or eDirectory. LDAP inputs, acount to sign in, etc. If all inputs are entered, nothing else should be required.   server This mode is only used with certificate security mode (see above). Identity information is stored for each user in a client-side certificate. Then the server, rather than the client, maps this information to an OrangeFS identity using LDAP. Installations that require per-user security, particularly those that use LDAP for user information. Non (configured post-installation) Run orangefs-get-user-cert for each user (see Using the orangefs-get-user-cert App)    For more information on user mapping, see ClientAdministration.\n         "
},
{
	"uri": "/windows-client/what_to_expect_windows/",
	"title": "What to Expect",
	"tags": [],
	"description": "",
	"content": "When you complete the Enterprise installation process, if you have provided all the necessary inputs, the last panel in the installer offers the option to start the client. If you select this option, your system mounts the OrangeFS server you specified, and the Windows Client starts. If you are not ready to start the client, you can do it manually later.\nThe installation program creates two new directories on your Windows system:\n   New Directory Description     C:\\OrangeFS\\Client OrangeFS client software, including the client executable (orangefs-client.exe), the orangefs-get-user-cert.exe app, and two configuration files (orangefs.cfg, orangefstab).   C:\\Program Files\\Dokan (enterprise installation)\\ or C:\\Dokan (manual installation) The Dokan Library, an open source set of files used by the OrangeFS client to mount an OrangeFS file system as a virtual drive.    The installation program adds a few settings to your Windows Registry. These settings are automatically removed if you uninstall the client.\n       "
},
{
	"uri": "/windows-client/running_the_installation_program_windows/",
	"title": "Installing the Software",
	"tags": [],
	"description": "",
	"content": "To install the OrangeFS Windows Client, you need the self-extracting installation program. Two versions are available, depending on your system’s processor type (32-bit or 64-bit).\nDownload and run orangefs-client-version-win32.exe or orangefs-client-version-win64.exe\nwhere\u0026hellip;\nversion = version number of the executable\nExample: orangefs-client-2.8.5.3-win64.exe\nNotes OS. It is best to run the installer as an administrative user (Administrator, for example).\nAfter running the executable, follow these steps:\n When the installation program\u0026rsquo;s Welcome dialog displays, click Next. The next dialog prompts you for an installation location.  Use the default or select a different location and click Next. Click Install to install the client. The next dialog prompts you for a file system URI, a mount point and user mapping mode.  Complete the dialog as follows:           File System URI Enter the DNS name/IP address and port number of an OrangeFS file system server in a URI format: tcp://[hostname]:[port]/[FS_name] Example: tcp://server1.com:3334/orangefs The default port number is 3334.   Mount Point Click the drop-down button to select a drive letter (E: to Z:) for the file system. Select Auto to use the first available drive letter (starting with E:).   User Mapping select List, Certificate, or LDAP. This corresponds with the mode of user mapping (described in the next step). If you are not sure, select List, as the settings can be changed later. Important The certificates must first be generated and placed in appropriate locations to support the Windows client before you can select the certificate mode. If you still need to complete this process, close the installation program and restart it when you have completed the certificate generation.    Click Next to continue.\n Depending on the mode of user mapping you chose in step 5, a dialog with one of the following titles prompts you for more information:           List Map Add User If you selected list mode, enter one Windows user ID and the OrangeFS (Linux/UNIX-based) UID and primary GID for mapping. You will manually add additional users to the configuration file after the installation.   Certificate User Mapping If you selected certificate mode, enter the Windows prefix directory of your user and proxy certificates. The default is the user profile directory (C:\\Users). You can also enter another location, for the prefix directory.   Setup Type If you selected ldap mode, a dialog provides three choices for your LDAP implementation (Microsoft Active Directory, Novell eDirectory or Custom). Select one and click Next. In the next dialog, enter the LDAP values required by OrangeFS. Note Depending on your LDAP selection, some of the text fields that display in the dialog might already have entries.    For complete details on user mapping see ClientAdministration.\n Click Next to continue.  The final dialog displays with an option to start the OrangeFS service when you exit the installation program.\n Do one of the following:\n Select the check box for Start the OrangeFS services if you want the Windows Client to mount the OrangeFS file system.\n Leave the check box deselected if your configuration is not complete. You can manually start the service later.\n  Click Finish to complete the installation.\n             "
},
{
	"uri": "/windows-client/manual_installation_windows/",
	"title": "Manual Installation",
	"tags": [],
	"description": "",
	"content": " Important The Client connects to a running OrangeFS server. If you have not yet installed the OrangeFS server components, consult the documentation and install the server before installing the Windows Client.\nFollow the instructions below to install the OrangeFS Windows Client:\nDownload the ZIP file associated with your system type (64- or 32-bit):\n For 64-bit systems, download orangefs-windows-client-version#-win64.zip. For 32-bit systems, download orangefs-windows-client-version#-win32.zip.\nwhere\u0026hellip;\nversion# is the OrangeFS version, for example, 2.8.*.  Extract the ZIP file to any directory, where the OrangeFS and Dokan directories will be created.\nOpen a Command Prompt from Start | All Programs | Accessories to complete the following steps.\nInstall the Dokan driver:  Change directory (cd) to the Dokan\\DokanLibrary directory.\n Copy dokan.dll to the System32 directory: copy dokan.dll c:\\windows\\system32\n Copy dokan.sys to the system Drivers directory: copy dokan.sys c:\\windows\\system32\\drivers\n Install the driver using dokanctl.exe: dokanctl /i d\n Restart your system.\n  Install the Dokan Mounter service:  Change directory (cd) to the Dokan\\DokanLibrary directory. Install the service using dokanctl.exe: dokanctl /i s  Install the OrangeFS Client service:  Change directory (cd) to the OrangeFS\\Client directory. Install the service using orangefs-client.exe: orangefs-client -installService\n Configure the OrangeFS Client by creating the orangefstab and orangefs.cfg files in OrangeFS\\Client, following the instructions in the Configuration section of the Windows Client documentation.\n Start the Dokan Mounter and OrangeFS Client services using the Services Administrative Tool (Start | Control Panel Administrative Tools | Services).\n  Your OrangeFS file system should appear as a Removable Drive.\nFor troubleshooting, open the Event Log Administrative Tool and consult the Application Log. For additional help, consult the documentation.\n         "
},
{
	"uri": "/windows-client/uninstalling_the_client_windows/",
	"title": "Uninstalling the Windows client",
	"tags": [],
	"description": "",
	"content": " Uninstalling the Enterprise Installation To uninstall the Windows client, follow these steps:\n From the Windows Start Menu, select Control Panel, then Programs and Features. Locate and select the OrangeFS Client item, and click the Uninstall button above. Follow the uninstaller steps to remove the Client. Remove configuration files under C:\\OrangeFS\\Client (by default) and the C:\\OrangeFS\\Client directories.  Uninstalling a Manual Installation Follow the instructions below to uninstall the OrangeFS Windows Client:\nStop the Dokan Mounter and OrangeFS Client services.\nRemove the OrangeFS Client service:\n Change directory (cd) to the OrangeFS\\Client directory. Remove the service using orangefs-client.exe:\norangefs-client -removeService  Remove the Dokan Mounter service:  Change directory (cd) to the Dokan\\DokanLibrary directory. Remove the service using dokanctl.exe:\ndokanctl /r s  Remove the Dokan driver:\n Change directory (cd) to the Dokan\\DokanLibrary directory. Remove the driver using dokanctl.exe:\ndokanctl /r d Restart your system  Remove Dokan system files:\n Remove dokan.dll:\ndel c:\\windows\\system32\\dokan.dll Remove dokan.sys:\ndel c:\\windows\\system32\\drivers\\dokan.sys  Remove application files:\n Remove the Dokan directory:\nrd Dokan /s Remove the OrangeFS directory:\nrd OrangeFS /s            "
},
{
	"uri": "/windows-client/winclient_use/",
	"title": "Using the Client",
	"tags": [],
	"description": "",
	"content": " Information in this topic includes:\n Interfacing with OrangeFS Running the Client Understanding Security Getting/Generating New User-Mapping Certificates  Interfacing with OrangeFS When the Windows Client is running on your computer, the OrangeFS file system appears as a removable drive at the drive letter (E:-Z:). This drive letter, specified during installation, is a setting in the configuration file that can be changed. For more information, see Client Administration.\nYou can interact with files and directories in the file system like local files. For example, they can be viewed in Windows Explorer, listed in the Command Prompt or accessed using program API functions, such as fopen.\nNote Currently the Client can mount only one OrangeFS file system at a time.\nRunning the Client You must start two Windows Services to run the OrangeFS Windows Client:\n DokanMounter OrangeFS Client  You can access these services in the Windows Services utility. To open the Services utility, navigate to the Control Panel and click Administrative Tools | Services. You should see the DokanMounter and OrangeFS Client services included in the console listing.\nTo start (or stop) a service, right-click the service and select the desired action.\nYou should start the DokanMounter service first. This service is tied to the Dokan Library, which is the third-party software included with your installation. DokanMounter enables the Windows Client to mount the file system transparently.\nThe two services are configured to start automatically any time the system is restarted. To change this setting, right-click the service and select Properties.\nNote If you need to stop the Windows Client service, you do not normally have to stop the DokanMounter service.\nUnderstanding Security First you must set the Client to operate using the File System security mode used by the servers. Do this by setting the “security-mode” option in the configuration file to “default”, “key” or “certificate”, with “default” being used if no option is specified. (For more information, see Client Administration.)\nYou can configure the file as read-only on Windows to remove owner write permissions.\nNote The default permissions mask can be changed with the new-file-perms and new-dir-perms configuration file keywords. Form more information, see Client Administration.\nLevel of security will also depend on the user mapping configuration of your Windows Client. The three types of user mapping are\nList Directly matches one Windows ID with one OrangeFS UID and primary GID. Certificate Maps user digital certificate to OrangeFS UID/GID. Our recommended configuration is for grid computing which requires CA, proxy and user certificates. LDAP Maps user(s) on an LDAP tree, such as Active Directory or eDirectory, to OrangeFS UIDs/GIDs. Server Used only when the security mode is “certificate,” this mode features client-side certificates for each user and server-side identity mapping with LDAP.\nFor more information, see Client Administration.\nGetting (or Generating) New User-Mapping Certificates Note This task only applies if your Windows Client is using certificates mode for user mapping.\nIf your Windows Client is configured for certificate mapping, this will likely involve three types of certificates (CA, proxy, user). Usually, your administrator creates and installs these certificates. However, since all certificates have expiration dates, you might need new ones regenerated from time to time while using the Windows Client.\nDepending on your setup, you might need to request new certificates from your administrator, or the administrator might provide you with instructions for doing it yourself.\nOf the three types of certificates mentioned earlier, the proxy certificate must generally be renewed more often than the other two. Depending on your administrative policies, the time before a proxy certificate expires can average anywhere from 6 hours to two weeks.\n     "
},
{
	"uri": "/windows-client/winclient_admin/",
	"title": "Client Administration",
	"tags": [],
	"description": "",
	"content": " Information in this topic includes:\n Configuration Configuring the Client Security Mode User Mapping Installing and Using Globus Toolkit (certificates only) Troubleshooting Source Code  Configuration Two configuration files exist for the OrangeFS Client:\n orangefstab orangefs.cfg   Both text files are located in the installation directory (C:\\OrangeFS\\Client) by default and can be edited.\nThe orangefstab file contains only one line entry, which is the URI address of the OrangeFS server to be mounted for Windows Client access.\nThe orangefs.cfg file can contain a wide range of settings, including:\n The drive letter on your Windows system that is associated with OrangeFS The user mapping option your client is configured for (list, certificate, ldap) Various additional settings for each of the user mapping options Debug settings for logging and troubleshooting    Note Because the configuration files can be altered to change security information, only administrative users should have access to change them. For security information, see your Windows documentation.\n Working with the orangefstab File The orangefstab file uses the same format as Linux/UNIX mtab (mounted file system table) files. Here is a sample line entry in orangefstab:\ntcp://orangefs.acme.com:3334/orangefs /mnt/orangefs pvfs2 defaults,noauto 0 0\n Since only one file system can be mounted, only one line can be used. The first field is a URI that specifies an OrangeFS file system server. The format is:  tcp://hostname:port/fs_name\nwhere\u0026hellip;\nhostname = OrangeFS server host name\nport = port number\nfs_name = OrangeFS installation name\nTCP is the only protocol supported on Windows. The default port is 3334. The file system name can be determined from the server configuration file (default is orangefs).\n The second field is the internal UNIX-style mount point. This value should be the same for all clients (Windows or Linux/UNIX). The other fields should be left as-is above.   Working with the orangefs.cfg File Most of the Windows Client configuration information is contained in orangefs.cfg, a text file that contains lines in the form:\nkeyword option_value\nYou can specify comments using the # character:\n# This is a comment.\n Keyword: mount {.normal_indent_1} The first essential keyword is mount. It specifies the drive letter associated with the mounted OrangeFS server.\nExample:\nmount O:\nThis example will mount the file system on O: drive. (You must include the colon.) If you do not use the mount keyword, the first alphabetically available drive, starting with E:, is used by default.\n Keyword: user-mode {.emphasis} The user-mode keyword sets the user mapping mode. The Client will not start if it is not included in the file. The option value must be list, certificate or LDAP.\nExample:\nuser-mode list\nNote The user-mode keyword is at the top level of a hierarchy of keywords for configuring user mapping, discussed in more detail in the next section.\n Keywords: new-file-perms, new-dir-perms The new-file-perms and new-dir-perms keywords change the initial permissions mask of newly created files and directories. If these keywords are not present, the default permissions mask is 755 (rwxr-xr-x).\nNote For more information about the permissions mask, see the Linux/UNIX chmod man page.\nThe keywords are used with an octal integer value representing the permissions mask.\nExamples:\nnew-file-perms 644\nnew-dir-perms 700\nThe first example will cause new files to be created with “rw-r\u0026ndash;r\u0026ndash;“ permissions.\nThe second will create directories with “rwx\u0026mdash;\u0026mdash;“ permissions.\nNote While you can set the “sticky bit” in OrangeFS, it has no effect.\nImportant Ensure that the file owners always have read permissions to their own files (mask 400), and read and execute permissions to their own directories (mask 500). Otherwise, they cannot read these files and directories after creation.\n Keywords: debug, debug-file, debug-stderr The debug, debug-file and debug-stderr keywords log detailed debugging information. If you specify the debug keyword by itself, client-related messages are recorded in orangefs.log in the installation directory (C:\\OrangeFS\\Client by default). You can change the name and location of the log file by using the debug-file keyword.\nExample:\ndebug-file C:\\Temp\\myfile.log\nYou can also use any of the debugging flags available with OrangeFS. For a list of these flags, see the OrangeFS system documentation. The client flag is win_client.\nExample:\ndebug win_client io msgpair\nIn this example, you would log debugging information about the client, I/O and message pair operations.\nThe debug-stderr keyword is used with no option value and prints debugging messages to the console. This keyword is useful only if orangefs-client.exe is running as a normal executable (not as a service).\nKeywords Table Following is a list of all keywords available for use in the orangefs.cfg file.\n   Keyword Description     mount Sets the Windows drive letter to represent the OrangeFS file system.   user-mode Sets the authentication/security mode used to map Windows user accounts with OrangeFS user accounts. Three possible option values: - list: This mode directly matches one Windows ID with one OrangeFS UID and primary GID. - certificate: This mode maps digital certificates to OrangeFS UID/GID - ldap: This mode enables Windows user ID to be looked up in an identity directory that supports LDAP. Examples: Active Directory, eDirectory, Open LDAP.   user Used only when value for user-mode keyword is list. Specifies a user. A separate line entry with this keyword is required for each user. Each time it is used, you must enter it in a line that occurs below the user-mode keyword line.   ca-path Used only when value for user-mode keyword is certificate. Sets path to file for CA (Certificate Authority) certificate. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   cert-dir-prefix Used only when value for user-mode keyword is certificate. Sets the location of your user and proxy certificates if the user\u0026rsquo;s default profile directory is not being used. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line. The option value is the alternative path.   ldap-host Used only when value for user-mode keyword is ldap. Sets the host computer that is running ldap. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-bind-dn Used only when value for user-mode keyword is ldap. Sets a user DN to bind to. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-bind-password Used only when value for user-mode keyword is ldap. Sets a user password. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-search-root Used only when value for user-mode keyword is ldap. Specifies the DN of the directory container object where searches should begin. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-search-class Used only when value for user-mode keyword is ldap. Specifies object class that the user object must be. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-search-scope Used only when value for user-mode keyword is ldap. Sets the scope of user searches. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-naming-attr Used only when value for user-mode keyword is ldap. Sets the attribute on the user object that must exactly match the Windows user ID. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-uid-attr Used only when value for user-mode keyword is ldap.\nSpecifies the attributes with store the OrangeFS UID. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   ldap-gid-attr Used only when value for user-mode keyword is ldap. Specifies the attributes with store the OrangeFS GID. If you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.   new-file-perms Specifies the permissions mask that new OrangeFS files will have.   new-dir-perms Specifies the permissions mask that new OrangeFS directories will have.   debug Specifies for all client-related messages to be logged in orangefs.log.   debug-file Sets a custom name and location of the log file to be used for debugging (in place of orangefs.log).   debug-stderr Sets all debugging messages to print to console. Works only when the executable, orangefs-client, is running (rather than the service).    Configuring the Client Security Mode An OrangeFS installation operates in one of three security modes: default, key- and certificate-based (see Preview Security). You must configure the Client’s security mode to match that of the servers or it cannot access the file system.\nNote The “certificate” security mode is distinct from the “certificate” user-mapping mode.\nThe security mode is specified by the security-mode keyword in orangefs.cfg (see above). Its value is one of default, key and certificate. (The default value is default.)\nConfiguring the Client for Default Security This mode offers checking file object permissions (i.e. read, write and execute) against the owner\u0026rsquo;s identity but does not prevent user impersonation. You may use any user-mapping mode with this security mode, which requires no further configuration.\nConfiguring the Client for Key-Based Security In this mode, each client and server has a key pair consisting of a public key and a private key. Public keys are stored in a server-side file known as the keystore, while each client or server stores its private key in a protected file. See Set Up Security for instructions for generating key pairs. The generated private key for the client should be transferred to the client’s local file system.\nIn key mode, the key-file keyword in orangefs.cfg must be present and must specify the absolute path to the private key file.\nExample:\nkey-file C:\\OrangeFS\\Client\\orangefs-key.pem\nNote You should protect this file using Windows security so that it cannot be accessed by non-administrative accounts.\nThe client’s public key must be stored in the keystore on each server as normal.\nConfiguring the Client for Certificate-Based Security In this mode, each user has a certificate which stores identifying information and their public key. A private key corresponds to the public key, with the certificate and private key being stored in separate files on the local (or user-shared) file system.\nThe key-file and cert-file keywords in orangefs.cfg specify absolute paths to these files. However, because each pair of files is user-specific, use the %USERNAME% token to specify how the path is formed.\nExample:\nkey-file C:\\Users\\%USERNAME%\\orangefs-cert-key.pem\ncert-file C:\\Users\\%USERNAME%\\orangefs-cert.pem\nAdditionally, a certificate and private key must be obtained for the SYSTEM user which performs basic OrangeFS operations such as retrieving the disk space. You must place these files in the same directory as orangefs-client.exe, C:\\OrangeFS\\Client by default. (SeeUsing the orangefs-get-user-cert App below.)\nUsers can generate their own certificates and private keys using the orangefs-get-user-cert app.\nUsers must not be able to read other users’ private keys, so you should protect them using Windows security. Users who do not have a certificate receive an “access denied” message when attempting to access OrangeFS.\nUser-mapping is done on the server for this mode, so the user-mapping mode must be “server”.\nUsing the orangefs-get-user-cert App An OrangeFS installation may have a dynamic pool of users who need access to files. Having an administrator generate credentials for every user request would be a needless waste of time. Instead, users can use the orangefs-get-user-cert app to create a private key and retrieve a certificate from the server.\nFirst, users must have and know their OrangeFS user name and password; these correspond to their identity stored in the server-side LDAP directory. It is convenient to make them match their Windows credentials, but not necessary.\nThen they may run the orangefs-get-user-cert app from the client. The executable is in C:\\OrangeFS\\Client. You may create a shortcut to it.\nUsers will first be prompted for their OrangeFS user name, with their Windows user name given as a default. Then they’re prompted for their password. If these are entered correctly, their credential files are stored in the directory specified by orangefs.cfg (typically their profile directory).\nAdditionally, an administrator can create a certificate for the SYSTEM user by specifying the -s option when running the app. The OrangeFS user name is typically root (UID 0), but can be any OrangeFS user.\nBelow is the full usage of the app:\norangefs-get-user-cert [-h|\u0026ndash;help] [options\u0026hellip;] [username]\n   Option Description     -s \u0026ndash;system generates files for the SYSTEM user   -c path \u0026ndash;certfile=path full path for certificate file storage (overrides orangefs.cfg)   -k path \u0026ndash;keyfile=path full path for private key file storage (overrides orangefs.cfg)   -x days \u0026ndash;expiration=days expiration time days (default set in server configuration file)    User Mapping The Windows Client maps Windows user IDs to OrangeFS Linux/UNIX-based UIDs for authentication. The user-mode keyword in orangefs.cfg specifies the type of user mapping. There are three modes of user mapping, detailed below.\nList Mode This simple form of mapping allows you to list Windows user IDs and their corresponding OrangeFS UIDs and primary GIDs. The list is created in orangefs.cfg. Here is the format of each line:\nuser windows_userid uid:gid\nExample:\nuser ofsuser 500:100\nA separate line entry with the user keyword is required for each user. Each time you use this keyword, you must enter it in a line that occurs below the user-mode keyword line.\nFile operations originating from the specified Windows user ID will be carried out on OrangeFS as the specified UID.\nCertificate Mode This section includes:\n A summary of the currently supported approach to certificate mapping for the Windows Client, including the supported software package for implementing this approach The three types of certificates that must be in place before configuring the Windows Client for certificate mapping The configuration settings for certificate mapping that can be set in orangefs.cfg, either during installation or manually  Important This topic does not discuss how to create certificates. For details on the mechanics of generating certificates, see Notes on Installing and Using Globus Toolkit later in this topic.\nCertificates for Grid-Computing With OrangeFS, certificates for user mapping and security are often associated with grid computing. Therefore, the OrangeFS team chose to support the certificate generation capabilities of Globus Toolkit (an open source utilities package for grid computing) in its early implementation of the Windows Client.\nSpecifically, the Globus Toolkit components used to generate certificates for the Windows Client are MyProxy and SimpleCA.\nIf you select the certificate mode for user mapping, the certificates must already have been generated and placed in their appropriate locations. For more information on meeting these certificate requirements for Windows Client, see Notes on Installing and Using Globus Toolkit below.\nFuture releases of the Windows Client will address alternatives to Globus Toolkit. Until then, if you wish to implement a certificate solution other than the one used here, please contact Technical Support.\nCertificate Requirements The Client uses X.509 certificates to identify users. The certificates contain the UID and GID to be used on the OrangeFS server. Because OrangeFS currently expects trusted clients, the certificates do not provide true security. However, they will limit the actions of typical users, such as preventing deleting files they do not own. Note that support for untrusted clients will be added to OrangeFS in an upcoming release.\nThree types of certificates must be in place for the Windows Client:\n CA (certificate authority) Proxy User   The following table describes each type.\nType Example Name Default Location on Windows Client Default Location on Globus Toolkit System\nCA cacert.pem C:\\OrangeFS\\Client\\CA home/.globus/cacert.pem \u0026hellip;where home is the home directory of the user who installed SimpleCA (typically root).\nProxy cert.0 C:\\Users\\userid /tmp/x509up_u250 \u0026hellip;for UID 250\nUser cert.1, cert.2, \u0026hellip; C:\\Users\\userid home/.globus/cacert.pem \u0026hellip;where home is the home directory of the user who installed SimpleCA (typically root).\nConfiguration File Two configuration file keywords are associated with the certificate mode for user mapping: ca-path and cert-dir-prefix.\nTo store the CA certificate in a non-default location on the Windows Client, you can add a line entry to orangefs.cfg that begins with the ca-path keyword, followed by the custom path.\nExample:\nca-path C:\\Certificates\\OrangeFS\\CA\nTo store the user and proxy certificates in a non-default location on the Windows Client, you can add a line entry to orangefs.cfg that begins with the cert-dir-prefix keyword, followed by a prefix directory path to be placed in front of the certificate user directory.\nExample:\ncert-dir-prefix C:\\Certificates\\OrangeFS\nWhen the Client attempts to locate the proxy and user certificates for a user, it will append the userid as a directory name to the cert-dir-prefix. Using the above example, the certificates for user bsmith would be placed in C:\\Certificates\\OrangeFS\\bsmith\\ using the cert-dir-prefix above.\nLDAP Mode LDAP (Lightweight Directory Access Protocol) mapping allows the Windows user ID to be looked up in an identity directory that supports LDAP. LDAP directory examples include Microsoft Windows Active Directory and Novell* eDirectory. Consult your directory documentation for information on LDAP.\nLDAP options for the Windows Client are specified in orangefs.cfg. All keywords described in this section must occur below user-mode ldap line entry.\nConnecting over LDAP First you must specify the host computer running LDAP. This is done with the ldap-host keyword in the following format:\nldap-host ldap[s]://hostname:port\nIf ldaps is specified, a secure connection is used; otherwise, the connection is plain text. The default secure port is 636, and the default plain text port is 389, but you can alter the port as shown above.\nExample:\nldap-host ldaps://myldaphost.acme.com:1636\nYou can bind to the directory anonymously if it allows, or you can specify a user and password with the ldap-bind-dn and ldap-bind-password keywords:\nldap-bind-dn bind_user_dn (login)\nldap-bind-password password\nExample:\nldap-bind-dn cn=orangefs-user,ou=special,o=acme\nldap-bind-password S3crt!\nBecause the password is stored in plain text in the configuration file, give the binding user minimal rights to the directory. For more information, see LDAP Security below.\nSearch Options The Windows Client will search LDAP for the Windows user ID making the file system request. The search options specify how the directory is searched.\nFirst, the ldap-search-root keyword specifies the DN of the directory container object where the search should begin.\nExample:\nldap-search-root ou=cluster-users,o=acme\nThe ldap-search-scope keyword can be either onelevel or subtree. If onelevel is specified, only the object specified with ldap-search-root is searched—no descendant objects (sub-containers) are searched. If subtree is specified, the object specified with ldap-search-root is searched along with all descendant objects. The default is onelevel.\nExample:\nldap-search-root subtree\nThe Client will form an LDAP search string in the following form:\n(\u0026amp;(objectClass=ldap-search-class)(ldap-naming-attr=windows_userid))\nThe ldap-search-class keyword specifies the required object class of the user object. Typical values are User or inetOrgPerson.\nExample:\nldap-search-class User\nThe ldap-naming-attr keyword indicates the attribute on the user object that must exactly match the Windows user ID. Consult your documentation to determine if the comparison is case-sensitive (typically it is not). Typical values might be cn or name.\nExample:\nldap-naming-attr cn\n Attribute Options The ldap-uid-attr and ldap-gid-attr keywords specify the attributes which store the OrangeFS UID and primary GID, respectively. The Windows Client retrieves these values for use on the file system.\nExample:\nldap-uid-attr uidNumber\nldap-gid-attr gidNumber\nLDAP Security Because the LDAP binding password is stored as plain text, give the binding user minimal rights to the LDAP directory. Alternatively, minimal rights can be given to users who bind anonymously—no password is stored in this case. Here are rights to consider:\n Rights to search objects in the search root and below Rights to read the object class, naming attribute, UID attribute and GID attribute from searchable objects No write/delete/administrator rights  For performance, UID/GID credentials are cached for a time after lookup. If you need to revoke rights, you must restart the OrangeFS Client service.\nYou should also use an encrypted connection to LDAP if possible, by specifying ldaps in the host URI.\nNotes on Installing Globus Toolkit This section provides supplementary information about Globus Toolkit. The information applies only to Windows Clients that use the certificate mode for user mapping.\nWith OrangeFS, certificates for user mapping and security are often associated with grid computing. Therefore, the OrangeFS team chose to support the certificate generation capabilities of Globus Toolkit (an open source utilities package for grid computing) in its early implementation of the Windows Client.\nNote Future releases will accommodate alternatives to the Globus Toolkit approach. Until then, if you wish to implement a certificate solution other than the one described here, please contact Technical Support. Whether you are new to Globus Toolkit or you have already installed it for certificate generation, the guidelines and suggestions in this section ensure optimal certificate configuration for the Windows Client.\nIntroduction The Client can use X.509 certificates to identify users. The certificates contain the UID and GID to be used on the OrangeFS server. Because OrangeFS currently expects trusted clients, the certificates do not provide true security. However, they will restrict the actions of typical users, such as deleting files they do not own. Note that support for untrusted clients will be added to OrangeFS in an upcoming release.\nIdentifying Certificate Format The certificate that identifies the OrangeFS user is called the identifying certificate. It is a proxy certificate, which allows authorization on behalf of an “end entity,” in this case, a user. This user is represented by a user certificate.\nProxy certificates contain authorization information in a data field known as a policy. For the Client, the policy is a UTF-8 string in the form uid/gid. For example, with OpenSSL, the proxy specification for UID 250 and primary GID 100 would be as follows:\nlanguage=id-ppl-anyLanguage\npathlen=0\npolicy=text:250\u0026frasl;100\nMore information on generating this certificate is provided below.\nCertificates and Validation The identifying certificate is useful only if it can be validated against its signing certificate. The signing certificate might also require validation against the certificate that signed it, and so on, forming a certificate chain. Ultimately, the chain must end at the trusted, self-signed certificate of a certificate authority (CA).\nInstalling Globus Toolkit Install Globus Toolkit on one of the OrangeFS servers or another Linux system that shares the same user information (UIDs/GIDs).\nInstallation instructions for Globus Toolkit can be obtained at http://www.globus.org/toolkit/docs/latest-stable/. The Quickstart instructions will provide a default configuration for MyProxy, including a CA called SimpleCA.\nMany different security options can be configured. For example, a third-party certificate authority can be used. As long as the identifying certificate follows the format above, the client will accept the certificate.\nLocating the CA Certificate If SimpleCA is being used, the default CA certificate is home/.globus/cacert.pem, where home is the home directory of the user who installed SimpleCA, typically root. If a third-party CA is being used, the certificate will be located in an implementation-dependent location. The security administrator of the grid should be able to locate the file.\nThe CA certificate must be copied to the Windows Client system after the Client is installed. For the file location, see Client Certificate Locations below.\nUsing Grid-Based Certification To use grid-based certification, the user must first have a user certificate. To obtain this certificate, the user runs grid-cert-request to generate a certificate request file. At that time, the user specifies the certificate pass phrase. This file is then delivered to the CA organization, where a human agent will review the request and return a user certificate signed by the CA certificate. The certificate will be stored in home/.globus/usercert.pem, where home is the home directory of the user who installed SimpleCA, typically root. If the grid installation is using SimpleCA, the certificate request can be processed by a local administrator using the grid-ca-sign command.\nThe grid-proxy-init command can then be used to obtain a proxy certificate. Create a file (cert-policy, for example) to contain the policy text, which is formatted uid/gid. For example, the file would contain 250\u0026frasl;100 for a user with UID 250 and GID 100. The grid-proxy-init command can be used to generate the proxy certificate with the example cert-policy file, as follows:\ngrid-proxy-init -policy cert-policy -pl id-ppl-anyLanguage\nWhen the user enters the certificate pass phrase, the proxy certificate is generated.\nTo simplify this command, the OrangeFS installation package includes the script Tools\\pvfs2-grid-proxy-init.sh. This will generate the policy file and run grid-proxy-init.\nThe resulting proxy certificate is stored by default at /tmp/x509up_uuid. Example for UID 250: /tmp/x509up_u250\nTransfer this certificate to the Windows Client system, along with the user certificate. For the file location, see Client Certificate Locations below. The proxy certificate must be renamed cert.0, and the user certificate cert.1.\nDelegating Identities for Clusters The use of identifying proxy certificates allows the identity of the user to be separated from the actual Windows user ID making a file system request. This ability is useful for clusters.\nFor example, when a user with a Windows user ID of JSmith executes a job on a cluster node, the job scheduler uses Windows user ID ClusterUser.\nThe system administrator would set the certificate directory prefix to C:\\ClusterWork. A directory called ClusterUser would be created under ClusterWork. The job scheduler would transfer certificates to the C:\\ClusterWork\\ClusterUser directory. When ClusterUser makes file system requests, it will use the certificates of JSmith, so requests on the file system will use the UID of JSmith. When a different user uses the node, that user’s certificates will be used.\nCertificate Expiration and Renewal For performance, the Client caches the OrangeFS user identity (UID/GID) until the proxy certificate expires.\nBy default, Globus Toolkit proxy certificates expire after 12 hours. If jobs requiring more time are expected, a means for the user to renew the certificate should be provided.\nOne way to do this is to have the user to run grid-proxy-init again. This will overwrite the current proxy. Then the new proxy certificate can be transferred to the Client system (overwriting the current certificate) without interrupting the current job.\nClient Certificate Locations The certificates are stored as PEM-format files on the Windows Client system. The identifying certificate’s name is cert.0. Because the identifying certificate is associated with a Windows user, it is stored in its user’s profile directory by default. On most systems this is C:\\Users\\.\nExample: C:\\Users\\jsmith\nAlternatively, you can specify a certificate prefix directory in the client configuration file, C:\\OrangeFS\\Client\\orangefs.cfg by default. Use the cert-dir-prefix keyword to specify this directory. The user’s userid will be appended as a directory name to the prefix directory.\nExample configuration file line entry:\ncert-dir-prefix M:\\OrangeFS Users\nFor user jsmith, the identifying certificate will be M:\\OrangeFS Users\\jsmith\\cert.0.\nThe identifying certificate must be verified by its end-entity (sometimes called a user) certificate. Place this certificate in the same directory as the identifying certificate, with the name cert.1. Additional intermediate certificates can be placed in the same directory with names cert.2, cert.3, and so on.\nThe CA certificate is placed in the OrangeFS CA directory with the name cacert.pem. By default this is C:\\OrangeFS\\Client\\CA\\cacert.pem. This path can be changed in the configuration file using the ca-path directive in the configuration file.\nExample:\nca-path M:\\OrangeFS Certificates\\orangefs-cacert.pem\nTroubleshooting To troubleshoot problems, check the Application Event Log in the Event Viewer utility. You can also turn on detailed debugging (see Working_With_The_orangefs.cfg_File).\nStartup errors are logged to the Windows Event Log.\nThe configuration file has some strict requirements, so the Windows Client will log an error to Event Log and exit if there is a problem. The event message should give an exact explanation of the problem with the configuration file. Correct the problem and restart the OrangeFS Client service.\nensure network connectivity is available between the Client system and the server(s) hosting OrangeFS. Check firewall settings and network access lists.\nFor information about the debug and related keywords, see Configuration. You can use the generated file orangefs.log to diagnose problems. A file named service.log is also created in the installation directory when debugging is enabled and can provide more detail on startup errors.\nNote that many debug messages are low-level and require extensive knowledge of OrangeFS/PVFS2 to interpret. For more information, consult the OrangeFS and PVFS2 system documentation.\nFree and commercial support is available at http://www.orangefs.org.\nSource Code The OrangeFS team intends to provide all source code needed for building the Client.\nCurrently, a source code package is available at http://www.orangefs.org. (The Windows package is separate from the Linux/UNIX package.) Build instructions will be released at a later date.\n   "
},
{
	"uri": "/configuration/",
	"title": "OrangeFS Configuration",
	"tags": [],
	"description": "",
	"content": " OrangeFS Configuration and Advanced Configuration "
},
{
	"uri": "/configuration/admin_ofs_configuration_file/",
	"title": "OrangeFS Configuration File",
	"tags": [],
	"description": "",
	"content": " The OrangeFS configuration file is copied to all servers as a single reference point for operation and performance. This is the file in which you specify settings and preferences for the file system. During installation, you use a program called pvfs2-genconfig to automatically generate the OrangeFS configuration file. The program presents a series of prompts, enabling you to enter basic required settings.\nWhile pvfs2-genconfig is designed to query you about the most important options, there are many additional options with default values that are bypassed during installation. After installation, you can revisit the configuration file to make changes and additions from a broad selection of options for:\n Server reconfiguration\n Performance-tuning\n Storage optimization\n Troubleshooting\n   Note After installation, any time you change the configuration file, you will need to recopy it to all servers in your OrangeFS installation and also restart each server.\n Note This list of options is generated automatically from program comments that have not been edited for spelling and grammar.\nWhat\u0026rsquo;s Inside The configuration file is a simple text file that can be opened and manually modified.\nIt is organized into a number of option categories called contexts. Each context is bracketed by tags and includes a list of one or more option-value pairs, as shown in this example:\n\u0026lt;ContextName\u0026gt; Option1Name Option1Value\nOption2Name Option2Value \u0026lt;/ContextName\u0026gt;\n When a server is started, the options associated with its server-alias in the configuration file are executed.\nAn option cannot span more than one line, and only one option can be specified on each line. The OptionValue should be formatted based on the option\u0026rsquo;s type:\n Integer - must be an integer value\n String - must be a string without breaks (newlines)\n List - a set of strings separated by commas\n   Options must be defined within a specified context or set of contexts. Sub-contexts must be defined within their specified parent contexts.\nFor example, the Range option is specified in either the DataHandleRanges or MetaHandleRanges contexts. Both of those contexts are specified to be defined in the FileSystem context.\nOptions and contexts that appear in the top-level (not defined within another context) are considered to be defined in a special Global context. Many options are only specified to appear within the Default context, which is a context that allows a default value to be specified for certain options. The options detailed below specify their type, the context where they appear, a default value, and description. The default value is used if the option is not specified. Options without default values must be defined.\nOption and Context Descriptions The remainder of this topic is a reference for all options in the configuration file, grouped by the contexts in which they are allowed to be used.\nOrangeFS Configuration File The OrangeFS configuration file is copied to all servers as a single reference point for operation and performance. This is the file in which you specify settings and preferences for the file system. During installation, you use a program called pvfs2-genconfig to automatically generate the OrangeFS configuration file. The program presents a series of prompts, enabling you to enter basic required settings.\nWhile pvfs2-genconfig is designed to query you about the most important options, there are many additional options with default values that are bypassed during installation. After installation, you can revisit the configuration file to make changes and additions from a broad selection of options for:\n Server reconfiguration\n Performance-tuning\n Storage optimization\n Troubleshooting\n   Note After installation, any time you change the configuration file, you will need to recopy it to all servers in your OrangeFS installation and also restart each server.\n Note This list of options is generated automatically from program comments that have not been edited for spelling and grammar.\nWhat\u0026rsquo;s Inside The configuration file is a simple text file that can be opened and manually modified.\nIt is organized into a number of option categories called contexts. Each context is bracketed by tags and includes a list of one or more option-value pairs, as shown in this example:\n\u0026lt;ContextName\u0026gt; Option1Name Option1Value\nOption2Name Option2Value \u0026lt;/ContextName\u0026gt;\n When a server is started, the options associated with its server-alias in the configuration file are executed.\nAn option cannot span more than one line, and only one option can be specified on each line. The OptionValue should be formatted based on the option\u0026rsquo;s type:\n Integer - must be an integer value\n String - must be a string without breaks (newlines)\n List - a set of strings separated by commas\n   Options must be defined within a specified context or set of contexts. Sub-contexts must be defined within their specified parent contexts.\nFor example, the Range option is specified in either the DataHandleRanges or MetaHandleRanges contexts. Both of those contexts are specified to be defined in the FileSystem context.\nOptions and contexts that appear in the top-level (not defined within another context) are considered to be defined in a special Global context. Many options are only specified to appear within the Default context, which is a context that allows a default value to be specified for certain options. The options detailed below specify their type, the context where they appear, a default value, and description. The default value is used if the option is not specified. Options without default values must be defined.\nOption and Context Descriptions The remainder of this topic is a reference for all options in the configuration file, grouped by the contexts in which they are allowed to be used.\nOption Descriptions This is the list of possible Options that can be used in the config files in this version of OrangeFS.\n   Option: TrustedPorts     Type: String   Contexts: Security   Default Value: None   Description: Specifies the range of ports in the form of a range of 2 integers from which the connections are going to be accepted and serviced. The format of the TrustedPorts option is: TrustedPorts{StartPort}-{EndPort} As an example: TrustedPorts 0-65535       Option: TrustedNetwork     Type: List   Contexts: Security   Default Value: None   Description: Specifies the IP network and netmask in the form of 2 BMI addresses from which the connections are going to be accepted and serviced. The format of the TrustedNetwork option is: TrustedNetwork {bmi-network-address@bmi-network-mask}-{EndPort} As an example: TrustedNetwork tcp://192.168.4.0@24       Option: KeyStore     Type: String   Contexts: Defaults ServerOptions Security   Default Value: None   Description: A path to a keystore file, which stores server and client public keys for key-based security. Note: May be in the Defaults section for compatibility. For newly-generated configuration files it should appear in the Security section.       Option: ServerKey     Type: String   Contexts: Defaults ServerOptions Security   Default Value: None    | Description: | Path to the server private key file, in PEM format. Must correspond to CA certificate in certificate mode. Note: May be in the Defaults section for backwards-compatibility. For newly-generated configuration files it should appear in the Security section. |\n   Option: CredentialTimeoutSecs     Type: Integer   Contexts: Security   Default Value: 3600   Description: Credential timeout in seconds       Option: CapabilityTimeoutSecs     Type: Integer   Contexts: Security   Default Value: 600   Description: Capability timeout in seconds       Option: TurnOffTimeouts     Type: String   Contexts: Security   Default Value: yes   Description: Prevent the server from issuing an error whenever a capability or credential expires. In this case, the client provides the only mechanism determining when a capability or credential needs to be egenerated. This option is only valid within the Defaults context; either the entire system is using timeouts or it is not.       Option: CredentialCacheTimeoutSecs     Type: Integer   Contexts: Security   Default Value: 3600   Description: Server-side Credential cache timeout in seconds       Option: CapabilityCacheTimeoutSecs     Type: Integer   Contexts: Security   Default Value: 600   Description: Server-side Capability cache timeout    in seconds       Option: CertificateCacheTimeoutSecs     Type: Integer   Contexts: Security   Default Value: 3600   Description: Server-side Certificate cache timeout in seconds       Option: CAFile     Type: String   Contexts: Defaults ServerOptions     Security   Default Value: None   Description: Path to CA certificate file in PEM format. Note: May be in the Defaults section for backwards-compatibility. For newly-generated configuration files it should appear in the Security section.       Option: UserCertDN     Type: String   Contexts: Defaults ServerOptions Security   Default Value: \\C=US, O=OrangeFS\\   Description: DN used for root of generated user certificate subject DN Note: May be in the Defaults section for backwards-compatibility. For newly-generated configuration files it should appear in the Security section.       Option: UserCertExp     Type: Integer   Contexts: Defaults ServerOptions Security   Default Value: 365   Description: Expiration of generated user certificate in days Note: May be in the Defaults section for backwards-compatibility. For newly-generated configuration files it should appear in the Security section.       Option: Hosts     Type: String   Contexts: LDAP   Default Value: ldaps://localhost   Description: List of LDAP hosts in URI format, e.g. ldaps://ldap.acme.com:999       Option: BindDN     Type: String   Contexts: LDAP   Default Value: None   Description: DN of LDAP user to use when binding to LDAP directory.       Option: BindPassword     Type: String   Contexts: LDAP   Default Value: None   Description: Password of LDAP user to use when binding to LDAP directory. May also be in form file:{path} which will load password from restricted file.       Option: SearchMode     Type: String   Contexts: LDAP   Default Value: CN   Description: May be CN or DN. Controls how the certificate subject DN is used to search LDAP for a user.       Option: SearchRoot     Type: String   Contexts: LDAP   Default Value: None   Description: DN of top-level LDAP search container. Only used in CN mode.       Option: SearchClass     Type: String   Contexts: LDAP   Default Value: inetOrgPerson   Description: Object class of user objects to search in LDAP.       Option: SearchAttr     Type: String   Contexts: LDAP   Default Value: CN   Description: Attribute name to match certificate CN. Only used in CN mode.       Option: SearchScope     Type: String   Contexts: LDAP   Default Value: subtree   Description: May be onelevel to search only SearchRoot container, or subtree to search SearchRoot container and all child containers.       Option: UIDAttr     Type: String   Contexts: LDAP   Default Value: uidNumber   Description: Attribute name in which UID value is stored.       Option: GIDAttr     Type: String   Contexts: LDAP   Default Value: gidNumber   Description: Attribute name in which GID value is stored.       Option: SearchTimeoutSecs     Type: Integer   Contexts: LDAP   Default Value: 15   Description: LDAP server timeout for searches (in seconds)       Option: Alias     Type: List   Contexts: Aliases   Default Value: None   Description: Specifies an alias in the form of a non-whitespace string that can be used to reference a BMI server address (a HostID). This allows us to reference individual servers by an alias instead of their full HostID. The format of the Alias option is:\nAlias {alias string} {bmi address} As an example: Alias mynode1 tcp://hostname1.clustername1.domainname:12345       Option: Server     Type: String   Contexts: ServerOptions   Default Value: None   Description: Defines the server alias for the server specific options that are to be set within the ServerOptions context.       Option: Range     Type: List   Contexts: MetaHandleRanges DataHandleRanges   Default Value: None   Description: As logical files are created in OrangeFS, the data files and meta files that represent them are given file system unique handle values. The user can specify a range of values (or set of ranges) to be allocated to data files and meta files for a particular server, using the Range option in the DataHandleRanges and MetaHandleRanges contexts. Note that in most cases, its easier to let the pvfs2-genconfig script determine the best ranges to specify. This option specifies a range of handle values that can be used for a particular OrangeFS server in a particular context (meta handles or data handles). The DataHandleRanges and MetaHandleRanges contexts should contain one or more Range options. The format is: [Range {alias} {min value1}-{max value1}[, {min value2}-{max value2},\u0026hellip;] Where {alias} is one of the alias strings already specified in the Aliases context. {min value} and {max value} are positive integer values that specify the range of possible handles that can be given out for that particular host. {max value} must be less than 18446744073709551615 (UINT64_MAX). As shown in the specified format, multiple ranges can be specified for the same alias. The format requires that max value of a given range is less than the min value of the next one, i.e. {max value1}\u0026lt;{min value2} Example of a Range option for data handles: Range mynode1 2147483651-4294967297       Option: RootHandle     Type: String   Contexts: FileSystem   Default Value: None   Description: Specifies the handle value for the root of the file system. This is a required option in the FileSystem context. The format is: RootHandle {handle value} Where {handle value} is a positive integer no greater than 18446744073709551615 (UIN64_MAX). In general its best to let the pvfs-genconfig script specify a RootHandle value for the file system.       Option: Name     Type: String   Contexts: FileSystem Distribution   Default Value: None   Description: This option specifies the name of the particular file system or distribution that its defined in. It is a required option in FileSystem and Distribution contexts.       Option: ID     Type: Integer   Contexts: FileSystem   Default Value: None   Description: An OrangeFS server may manage more than one file system, and so a unique identifier is used to represent each one. This option specifies such an ID (sometimes called a \u0026lsquo;collection id\u0026rsquo;) for the file system it is defined in. The ID value can be any positive integer, no greater than 2147483647 (INT32_MAX). It is a required option in the FileSystem context.       Option: TroveMaxConcurrentIO     Type: Integer   Contexts: Defaults ServerOptions   Default Value: 16   Description: Maximum number of AIO operations that Trove will allow to run concurrently       Option: LogFile     Type: String   Contexts: Defaults ServerOptions   Default Value: /tmp/pvfs2-server.log   Description: The gossip interface in OrangeFS allows users to specify different levels of logging for the OrangeFS server. The output of these different log levels is written to a file, which is specified in this option. The value of the option must be the path pointing to a file with valid write permissions. The LogFile option can be specified for all the OrangeFS servers in the Defaults context or for a particular server in the Global context.       Option: LogType     Type: String   Contexts: Defaults ServerOptions   Default Value: file   Description: The LogType option can be used to control the destination of log messages from OrangeFS server. The default value is file, which causes all log messages to be written to the file specified by the LogFile parameter. Another option is syslog, which causes all log messages to be written to syslog.       Option: EventLogging     Type: List   Contexts: Defaults ServerOptions   Default Value: none   Description: The gossip interface in OrangeFS allows users to specify different levels of logging for the OrangeFS server. This option sets that level for either all servers (by being defined in the Defaults context) or for a particular server by defining it in the Global context. Possible values for event logging are:    Logging Options listed in the Table Below:\n         Name Log output for:   acache Debug the attribute cache. Only useful on the client.   access Show server file (metadata) accesses (both modify and read-only).   access_detail Show more detailed server file accesses   access_hostnames Display the hostnames instead of IP addrs in debug output   all Everything   bstream Debug the bstream code   cancel Debug the cancel operation   client Log client sysint info. This is only useful for the client.   clientcore Debug the client core app   clientcore_timing Debug the client timing state machines (job timeout, etc.)   coalesce Debug the metadata sync coalescing code   dbpfattrcache Debug the server-side dbpf attribute cache   directio Debug trove in direct io mode   distribution Log/Debug distribution calls   endecode network encoding   flow Log flow calls   flowproto Log the flow protocol events including flowproto_multiqueue   fsck Debug the fsck tool   getattr Debug the server getattr state machine.   geteattr Debug the client and server get ext attributes SM.   io Debug the io operation (reads and writes) for both the client and server   keyval Debug the metadata dbpf keyval functions   listattr vectored getattr server state machine   listeattr Debug the listeattr operation   lookup Debug the client lookup state machine.   mgmt Debug direct io thread management   mirror Debug mirroring process   mkdir Debug the mkdir operation (server only)   msgpair Debug the msgpair state machine   ncache Debug the client name cache. Only useful on the client.   network Log network debug info.   none No debug output   open_cache Debug the server\u0026rsquo;s open file descriptor cache   permissions Debug permissions checking on the server   racache Debug read-ahead cache events. Only useful on the client.   readdir Debug the readdir operation (client and server)   remove Debug the client remove state macine.   reqsched Log request scheduler events   request Debug PINT_process_request calls. (EXTREMELY verbose!)   seccache Capability Cache   security Debug robust security code   server Log server info, including new operations.   setattr Debug the server setattr state machine.   seteattr Debug the client and server set ext attributes SM.   sm Debug the state machine management code   storage Log trove debugging info. Same as \u0026lsquo;trove\u0026rsquo;.   trove Log trove debugging info. Same as \u0026lsquo;storage\u0026rsquo;.   trove_op Log trove operations.   user_dev Show the client device events   usrint Client User Interface   varstrip Debug the varstrip distribution   verbose Everything except the periodic events. Useful for debugging   win_client Windows client    The value of the EventLogging option can be a comma-separated list of the above values. Individual values can also be negated with a \u0026lsquo;-\u0026rsquo;. Examples of possible values are:\n EventLogging flow,msgpair,io EventLogging -storage EventLogging -flow,-flowproto  \n   Option: EnableTracing     Type: String   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: no   Description: Enable code related to the use of TAU (Tuning and Analysis Utilities)       Option: UnexpectedRequests     Type: Integer   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: 50   Description: At startup each OrangeFS server allocates space for a set number of incoming requests to prevent the allocation delay at the beginning of each unexpected request. This parameter specifies the number of requests for which to allocate space. A default value is set in the Defaults context which will be be used for all servers. However, the default value can also be overwritten by setting a separate value in the ServerOptions context.       Option: StorageSpace     Type: String   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: None   Description: DEPRECATED. Use DataStorageSpace and MetadataStorageSpace instead.       Option: DataStorageSpace     Type: String   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: None   Description: Specifies the local path for the OrangeFS server to use as storage space for data files. This option specifies the default path for all servers and will appear in the Defaults context. NOTE: This can be overridden in the ServerOptions context on a per-server basis. Example: DataStorageSpace /opt/orangefs/storage/data       Option: MetadataStorageSpace     Type: String   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: None   Description: Specifies the local path for the OrangeFS server to use as storage space for metadata files. This option specifies the default path for all servers and will appear in the Defaults context. NOTE: This can be overridden in the ServerOptions context on a per-server basis. Example: MetadataStorageSpace /opt/orangefs/storage/meta       Option: TCPBufferSend     Type: Integer   Contexts: Defaults   Default Value: 0   Description: Current implementations of TCP on most systems use a window size that is too small for almost all uses of OrangeFS. We recommend administators consider tuning the Linux kernel maximum send and receive buffer sizes via the /proc settings. The PSC tcp tuning section for linux has good information on how to do this. The TCPBufferSend and TCPBufferReceive options allow setting the tcp window sizes for the OrangeFS clients and servers, if using the system wide settings is unacceptable. The values should be large enough to hold the full bandwidth delay product (BDP) of the network. Note that setting these values disables tcp autotuning. See the PSC networking options for details.       Option: TCPBufferReceive     Type: Integer   Contexts: Defaults   Default Value: 0   Description: See the TCPBufferSend option.       Option: TCPBindSpecific     Type: String   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: no   Description: If enabled, specifies that the server should bind its port only on the specified address (rather than INADDR_ANY).       Option: ServerJobBMITimeoutSecs     Type: Integer   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: 300   Description: Specifies the timeout value in seconds for BMI jobs on the server.       Option: ServerJobFlowTimeoutSecs     Type: Integer   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: 300   Description: Specifies the timeout value in seconds for TROVE jobs on the server.       Option: ClientJobBMITimeoutSecs     Type: Integer   Contexts: Defaults   Default Value: 300   Description: Specifies the timeout value in seconds for BMI jobs on the client.       Option: ClientJobFlowTimeoutSecs     Type: Integer   Contexts: Defaults   Default Value: 300   Description: Specifies the timeout value in seconds for FLOW jobs on the client.       Option: ClientRetryLimit     Type: Integer   Contexts: Defaults   Default Value: 5   Description: Specifies the number of retry attempts for operations (when possible).       Option: ClientRetryDelayMilliSecs     Type: Integer   Contexts: Defaults   Default Value: 2000   Description: Specifies the delay in milliseconds to wait between retries.       Option: PrecreateBatchSize     Type: List   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: 0, 1024, 1024, 1024, 32, 1024, 0   Description: Specifies the number of handles to be preceated at a time from each server using the batch create request. One value is specified for each type of DS handle. Order is important. It matches the order in which the types are defined in the PVFS_ds_type enum, which lives in include/pvfs2-types.h. If that enum changes, it must be changed here to match. Currently, this parameter follows the order: PVFS_TYPE_NONE PVFS_TYPE_METAFILE PVFS_TYPE_DATAFILE PVFS_TYPE_DIRECTORY PVFS_TYPE_SYMLINK PVFS_TYPE_DIRDATA PVFS_TYPE_INTERNAL       Option: PrecreateLowThreshold     Type: List   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: 0, 256, 256, 256, 16, 256, 0   Description: Precreate pools will be \u0026ldquo;topped off\u0026rdquo; if they fall below this value. One value is specified for each DS handle type. This parameter operates the same as the PrecreateBatchSize in that each count corresponds to one DS handle type. The order of types is identical to the PrecreateBatchSize defined above.       Option: FileStuffing     Type: String   Contexts: FileSystem   Default Value: yes   Description: Specifies if file stuffing should be enabled or not. File stuffing allows the data for a small file to be stored on the same server as the metadata.       Option: PerfUpdateHistory     Type: Integer   Contexts: Defaults   Default Value: 10   Description: This specifies the number of samples that performance monitor should keep Can be set in either Default or ServerOptions contexts.       Option: PerfUpdateInterval     Type: Integer   Contexts: Defaults   Default Value: 1000   Description: This specifies the frequency (in milliseconds) that performance monitor should be updated Can be set in either Default or ServerOptions contexts.       Option: BMIModules     Type: List   Contexts: Defaults   Default Value: None   Description: List the BMI modules to load when the server is started. At present, only tcp, infiniband, and myrinet are valid BMI modules. The format of the list is a comma separated list of one of: bmi_tcp bmi_ib bmi_gm For example: BMIModules bmi_tcp,bmi_ib Note that only the bmi modules compiled into OrangeFS should be specified in this list. The BMIModules option can be specified in either the Defaults or ServerOptions contexts.       Option: FlowModules     Type: List   Contexts: Defaults   Default Value: flowproto_multiqueue,   Description: List the flow modules to load when the server is started. The modules available for loading currently are: flowproto_multiqueue - A flow module that handles all the possible flows, bmi-\u0026gt;trove, trove-\u0026gt;bmi, mem-\u0026gt;bmi, bmi-\u0026gt;mem. At present, this is the default and only available flow for production use. flowproto_bmi_cache - A flow module that enables the use of the NCAC (network-centric adaptive cache) in the OrangeFS server. Since the NCAC is currently disable and unsupported, this module exists as a proof of concept only. flowproto_dump_offsets - Used for debugging, this module allows the developer to see what/when flows are being posted, without making any actual BMI or TROVE requests. This should only be used if you know what you\u0026rsquo;re doing.       Option: LogStamp     Type: String   Contexts: [Defaults   ServerOptions](#Defaults\nServerOptions)    Default Value: usec   Description: Specifies the format of the date/timestamp that events will have in the event log. Possible values are: usec: [%H:%M:%S.%U] datetime: [%m/%d/%Y %H:%M:%S] thread: [%H:%M:%S.%U (%lu)] none The format of the option is one of the above values. For example, LogStamp datetime       Option: FlowBufferSizeBytes     Type: Integer   Contexts: FileSystem   Default Value: 262144   Description: buffer size to use for bulk data transfers       Option: FlowBuffersPerFlow     Type: Integer   Contexts: FileSystem   Default Value: 8   Description: number of buffers to use for bulk data transfers       Option: RootSquash     Type: List   Contexts: ExportOptions   Default Value:    Description: RootSquash option specifies whether the exported file system needs to squash accesses by root. This is an optional parameter that needs to be specified as part of the ExportOptions context and is a list of BMI URL specification of client addresses for which RootSquash has to be enforced. RootSquash tcp://192.168.2.0@24 tcp://10.0.0.* tcp://192.168.* \u0026hellip;       Option: RootSquashExceptions     Type: List   Contexts: ExportOptions   Default Value:    Description: RootSquashExceptions option specifies exceoptions to the RootSquash list. This is an optional parameter that needs to be specified as part of the ExportOptions context and is a list of BMI URL specification of client addresses for which RootSquash has to be enforced. RootSquash tcp://192.168.2.0@24 tcp://10.0.0.* tcp://192.168.* \u0026hellip;       Option: ReadOnly     Type: List   Contexts: ExportOptions   Default Value:    Description: ReadOnly option specifies whether the exported file system needs to disallow write accesses from clients or anything that modifies the state of the file system. This is an optional parameter that needs to be specified as part of the ExportOptions context and is a list of BMI URL specification of client addresses for which ReadOnly has to be enforced. An example: ReadOnly tcp://192.168.2.0@24 tcp://10.0.0.* tcp://192.168.* \u0026hellip;       Option: AllSquash     Type: List   Contexts: ExportOptions   Default Value:    Description: AllSquash option specifies whether the exported file system needs to squash all accesses to the file system to a specified uid/gid. This is an optional parameter that needs to be specified as part of the ExportOptions context and is a list of BMI URL specification of client addresses for which AllSquash has to be enforced. An example: AllSquash tcp://192.168.2.0@24 tcp://10.0.0.* tcp://192.168.* \u0026hellip;       Option: AnonUID     Type: String   Contexts: ExportOptions   Default Value: 65534   Description: AnonUID tells the servers to translate the requesting client\u0026rsquo;s uid to the specified one whenever AllSquash is specified. If this is not specified and AllSquash is specified then the uid used will be that of nobody. An example: AnonUID 3454       Option: AnonGID     Type: String   Contexts: ExportOptions   Default Value: 65534   Description: AnonGID tells the servers to translate the requesting client\u0026rsquo;s gid to the specified one whenever AllSquash is specified. If this is not specified and AllSquash is specified then the gid used will be that of nobody. An example: AnonGID 3454       Option: HandleRecycleTimeoutSecs     Type: Integer   Contexts: StorageHints   Default Value: 360   Description: The TROVE storage layer has a management component that deals with allocating handle values for new metafiles and datafiles. The underlying trove module can be given a hint to tell it how long to wait before reusing handle values that have become freed up (only deleting files will free up a handle). The HandleRecycleTimeoutSecs option specifies the number of seconds to wait for each file system. This is an optional parameter that can be specified in the StorageHints context.       Option: AttrCacheKeywords     Type: List   Contexts: StorageHints   Default Value: DATAFILE_HANDLES_KEYSTR, METAFILE_DIST_KEYSTR, DIRECTORY_ENTRY_KEYSTR, SYMLINK_TARGET_KEYSTR   Description: The TROVE layer (server side storage layer) has an attribute caching component that caches stored attributes. This is used to improve the performance of metadata accesses. The AttrCacheKeywords option is a list of the object types that should get cached in the attribute cache. The possible values for this option are: dh - (datafile handles) This will cache the array of datafile handles for each logical file in this file system md - (metafile distribution) This will cache (for each logical file) the file distribution information used to create/manage the datafiles. de - (directory entries) This will cache the handles of the directory entries in this file system st - (symlink target) This will cache the target path for the symbolic links in this file system The format of this option is a comma-separated list of one or more of the above values. For example: AttrCacheKeywords dh,md,de,st       Option: AttrCacheSize     Type: Integer   Contexts: StorageHints   Default Value: 511   Description: The attribute cache in the TROVE layer mentioned in the documentation for the AttrCacheKeywords option is managed as a hashtable. The AttrCacheSize adjusts the number of buckets that this hashtable contains. This value can be adjusted for better performance. A good hashtable size should always be a prime number.       Option: AttrCacheMaxNumElems     Type: Integer   Contexts: StorageHints   Default Value: 1024   Description: This option specifies the max cache size of the attribute cache in the TROVE layer mentioned in the documentation for the AttrCacheKeywords option. This value can be adjusted for better performance.       Option: TroveSyncMeta     Type: String   Contexts: StorageHints   Default Value: yes   Description: The TroveSyncMeta option allows users to turn off metadata synchronization with every metadata write. This can greatly improve performance. In general, this value should probably be set to yes; otherwise, metadata transaction could be lost in the event of server failover.       Option: TroveSyncData     Type: String   Contexts: StorageHints   Default Value: yes   Description: The TroveSyncData option allows users to turn off datafile synchronization with every write operation. This can greatly improve performance, but may cause lost data in the event of server failover.       Option: DBCacheSizeBytes     Type: Integer   Contexts: StorageHints   Default Value: 0   Description: Berkeley DB: The DBCacheSizeBytes option allows users to set the size of the shared memory buffer pool (i.e., cache) for Berkeley DB. The size is specified in bytes. See BDB documentation for set_cachesize() for more info.    || |Option:|DBCacheType| |Type:|String| |Contexts:|StorageHints| |Default Value:|sys| |Description:|Berkeley DB: cache type for berkeley db environment. sys and mmap are valid values for this option|\n|| |Option:|DBMaxSize| |Type:|String| |Contexts:|Defaults StorageHints ServerOptions| |Default Value:|536870912| |Description:|LMDB: when specified in the Defaults context, DBMaxSize specifies the size of the storage_attributes and collections databases. When specified in the StorageHints context, DBMaxsize specifies the size of the collection_attributes, dataspace_attributes, and keyval databases. DBMaxSize can also be specified in the ServerOptions context to override the Defaults value on a per server basis. Default is 512MB if not specified.|\n|| |Option:|Param| |Type:|String| |Contexts:|Distribution| |Default Value:|None| |Description:|This option specifies a parameter name to be passed to the distribution to be used. This option should be immediately followed by a Value option.|\n|| |Option:|Value| |Type:|Integer| |Contexts:|Distribution| |Default Value:|None| |Description:|This option specifies the value of the parameter whose name was specified in the Param option.|\n|| |Option:|DefaultNumDFiles| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|0| |Description:|This option specifies the default number of datafiles to use when a new file is created. The value is passed to the distribution and it determines whether to use that value or not.|\n|| |Option:|ImmediateCompletion| |Type:|String| |Contexts:|StorageHints| |Default Value:|no| |Description:| |\n|| |Option:|CoalescingHighWatermark| |Type:|String| |Contexts:|StorageHints| |Default Value:|8| |Description:| |\n|| |Option:|CoalescingLowWatermark| |Type:|Integer| |Contexts:|StorageHints| |Default Value:|1| |Description:| |\n|| |Option:|TroveMethod| |Type:|String| |Contexts:|Defaults StorageHints| |Default Value:|alt-aio| |Description:|This option specifies the method used for trove. The method specifies how both metadata and data are stored and managed by the OrangeFS servers. Currently the alt-aio method is the default. Possible methods are: alt-aio This uses a thread-based implementation of Asynchronous IO. directio This uses a direct I/O implementation to perform I/O operations to datafiles. This method may give significant performance improvement if OrangeFS servers are running over shared storage, especially for large I/O accesses. For local storage, including RAID setups, the alt-aio method is recommended. null-aio This method is an implementation that does no disk I/O at all and is only useful for development or debugging purposes. It can be used to test the performance of the network without doing I/O to disk. dbpf Uses the system\u0026rsquo;s Linux AIO implementation. No longer recommended in production environments. Note that this option can be specified in either the Defaults context of fs.conf, or in a file system specific StorageHints context, but the semantics of TroveMethod in the Defaults context is different from other options. The TroveMethod in the Defaults context only specifies which method is used at server initialization. It does not specify the default TroveMethod for all the file systems the server supports. To set the TroveMethod for a file system, the TroveMethod must be placed in the StorageHints context for that file system.|\n|| |Option:|SecretKey| |Type:|String| |Contexts:|FileSystem| |Default Value:|None| |Description:|Specifies the file system\u0026rsquo;s key for use in HMAC-based digests of client operations.|\n|| |Option:|SmallFileSize| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|None| |Description:|Specifies the size of the small file transition point|\n|| |Option:|DirectIOThreadNum| |Type:|Integer| |Contexts:|StorageHints| |Default Value:|30| |Description:|Specifies the number of threads that should be started to service Direct I/O operations.|\n|| |Option:|DirectIOOpsPerQueue| |Type:|Integer| |Contexts:|StorageHints| |Default Value:|10| |Description:|Specifies the number of operations to service at once in Direct I/O mode.|\n|| |Option:|DirectIOTimeout| |Type:|Integer| |Contexts:|StorageHints| |Default Value:|1000| |Description:|Specifies the timeout in Direct I/O to wait before checking the next queue.|\n|| |Option:|TreeWidth| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|2| |Description:|Specifies the number of partitions to use for tree communication.|\n|| |Option:|TreeThreshold| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|2| |Description:|Specifies the minimum number of servers to contact before tree communication kicks in.|\n|| |Option:|DistrDirServersInitial| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|1| |Description:|Specifies the default for initial number of servers to hold directory entries. Note that this number cannot exceed 65535 (max value of a 16-bit unsigned integer).|\n|| |Option:|DistrDirServersMax| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|4| |Description:|Specifies the default for maximum number of servers to hold directory entries. Note that this number cannot exceed 65535 (max value of a 16-bit unsigned integer).|\n|| |Option:|DistrDirSplitSize| |Type:|Integer| |Contexts:|FileSystem| |Default Value:|10000| |Description:|Specifies the default for number of directory entries on a server before splitting.|\n\\#\\#\\# Context Descriptions This is the list of possible Contexts that can be used in the configuration file in this version of OrangeFS.  || |Context:|Defaults| |Parent Context:|Global| |Description:|Options specified within the Defaults context are used as default values over all the OrangeFS server specific config files.|\n|| |Context:|StorageHints| |Parent Context:|FileSystem| |Description:|This groups options specific to a file system and related to the behavior of the storage system. Mostly these options are passed directly to the TROVE storage module which may or may not support them. The DBPF module (currently the only TROVE module available) supports all of them.|\n|| |Context:|Global| |Parent Context:|None| |Description:|Global Context|\n|| |Context:|Security| |Parent Context:|None| |Description:|settings related to key- or certificate-based security options. These options are ignored if security mode is not compiled in.|\n|| |Context:|DataHandleRanges| |Parent Context:|FileSystem| |Description:|This context groups together the Range options that define valid values for the data handles on a per-host basis for this file system. A DataHandleRanges context is required to be present in a FileSystem context.|\n|| |Context:|ServerOptions| |Parent Context:|Global| |Description:|This groups the Server specific options. The ServerOptions context should be defined after the Alias mappings have been defined. The reason is that the ServerOptions context is defined in terms of the aliases defined in that context. Default options applicable to all servers can be overridden on a per-server basis in the ServerOptions context. To illustrate: Suppose the Option name is X, its default value is Y, and one wishes to override the option for a server to Y\u0026rsquo;. \u0026lt;Defaults\u0026gt; .. X Y .. \u0026lt;/Defaults\u0026gt; \u0026lt;ServerOptions\u0026gt; Server {server alias} .. X Y\u0026rsquo; .. \u0026lt;/ServerOptions\u0026gt; The ServerOptions context REQUIRES the Server option specify the server alias, which sets the remaining options specified in the context for that server.|\n|| |Context:|LDAP| |Parent Context:|Security| |Description:|Open tag for LDAP options, used in certificate mode.|\n|| |Context:|MetaHandleRanges| |Parent Context:|FileSystem| |Description:|This context groups together the Range options that define valid values for meta handles on a per-host basis for this file system. The MetaHandleRanges context is required to be present in a FileSystem context.|\n|| |Context:|ExportOptions| |Parent Context:|FileSystem| |Description:|Specifies the beginning of an ExportOptions context. This groups options specific to a file system and related to the behavior of how it gets exported to various clients. Most of these options will affect things like uid translation.|\n|| |Context:|Distribution| |Parent Context:|FileSystem| |Description:|Provides a context for defining the file system\u0026rsquo;s default distribution to use and the parameters to be set for that distribution. Valid options within the Distribution context are Name, Param, and Value. This context is an optional context within the FileSystem context. If not specified, the file system defaults to the simple-stripe distribution.|\n|| |Context:|Aliases| |Parent Context:|Global| |Description:|This groups the Alias mapping options. The Aliases context should be defined before any FileSystem contexts are defined, as options in the FileSystem context usually need to reference the aliases defined in this context.|\n|| |Context:|FileSystem| |Parent Context:|Global| |Description:|This groups options specific to a file system. An OrangeFS server may manage more than one file system, so a config file may have more than one FileSystem context, each defining the parameters of a different file system.|\n"
},
{
	"uri": "/configuration/orangefs_advanced_configuration/",
	"title": "Multiple File Systems",
	"tags": [],
	"description": "",
	"content": " In some circumstances, you may need to configure OrangeFS to support multiple concurrent file systems on the same set of storage servers. This topic provides examples of two different configuration options.\nTo configure OrangeFS to support multiple concurrent file systems on the same set of storage servers, you have two options. One is to run multiple server processes, each with its own config file. The second option is to have a single server process surface multiple file systems. There are no hard coded limits on the number of file systems via either method, so you are limited only by system resources. This topic is organized into the following two sections:\n Multiple Server Processes, Multiple File Systems\n Single Server Process, Multiple File Systems\n  Multiple Server Processes, Multiple File Systems Below are two sample configuration files that will run on the same systems and provide two different file systems. Each file system will have its own storage area.\nMultiple Server Processes Config File 1 Below is the first sample configuration file.\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 50\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 1000\nServerJobBMITimeoutSecs 30\nServerJobFlowTimeoutSecs 30\nClientJobBMITimeoutSecs 300\nClientJobFlowTimeoutSecs 300\nClientRetryLimit 5\nClientRetryDelayMilliSecs 2000\nPrecreateBatchSize 0,1024,1024,1024,32,1024,0\nPrecreateLowThreshold 0,256,256,256,16,256,0\nDataStorageSpace /ofs001/storage/3334/data\nMetadataStorageSpace /ofs001/storage/3334/meta\nLogFile /var/log/orangefs-server-3334.log\n\u0026lt;Security\u0026gt;\nTurnOffTimeouts yes\n\u0026lt;/Security\u0026gt;\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias ofs001 tcp://ofs001:3334\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs\nID 466735872\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange ol7dot3 3-4611686018427387904\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange ol7dot3 4611686018427387905-9223372036854775806\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\n** Multiple Server Processes Config File 2\nBelow is the second sample configuration file.\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 50\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 1000\nServerJobBMITimeoutSecs 30\nServerJobFlowTimeoutSecs 30\nClientJobBMITimeoutSecs 300\nClientJobFlowTimeoutSecs 300\nClientRetryLimit 5\nClientRetryDelayMilliSecs 2000\nPrecreateBatchSize 0,1024,1024,1024,32,1024,0\nPrecreateLowThreshold 0,256,256,256,16,256,0\nDataStorageSpace /ofs001/storage/3335/data\nMetadataStorageSpace /ofs001/storage/3335/meta\nLogFile /var/log/orangefs-server-3335.log\n\u0026lt;Security\u0026gt;\nTurnOffTimeouts yes\n\u0026lt;/Security\u0026gt;\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias ofs001 tcp://ofs001:3335\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs\nID 466735872\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange ol7dot3 3-4611686018427387904\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange ol7dot3 4611686018427387905-9223372036854775806\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\nSingle Server Process, Multiple File Systems {dir=\u0026ldquo;ltr\u0026rdquo;} Below is an example configuration file for a situation in which one server manages multiple file systems. The storage area for these two file systems is shared.\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 50\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 1000\nServerJobBMITimeoutSecs 30\nServerJobFlowTimeoutSecs 30\nClientJobBMITimeoutSecs 300\nClientJobFlowTimeoutSecs 300\nClientRetryLimit 5\nClientRetryDelayMilliSecs 2000\nPrecreateBatchSize 0,1024,1024,1024,32,1024,0\nPrecreateLowThreshold 0,256,256,256,16,256,0\nDataStorageSpace /ofs001/storage/data\nMetadataStorageSpace /ofs001/storage/meta\nLogFile /var/log/orangefs-server.log\n\u0026lt;Security\u0026gt;\nTurnOffTimeouts yes\n\u0026lt;/Security\u0026gt;\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias ofs001 tcp://ofs001:3334\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs-1\nID 466735872\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange ol7dot3 3-4611686018427387904\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange ol7dot3 4611686018427387905-9223372036854775806\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs-2\nID 1234567\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange ol7dot3 3-4611686018427387904\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange ol7dot3 4611686018427387905-9223372036854775806\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\n         "
},
{
	"uri": "/configuration/multiple_server_processes/",
	"title": "Multiple Server Processes",
	"tags": [],
	"description": "",
	"content": " To increase backend throughput when you have separate local volumes, you may elect to run multiple server processes on each server.\nThe topic is organized into the following three sections:\n Multiple Server Processes, Single File System Multiple Servers, Single File System, Some Data-only Servers Multiple Server Processes, Single File System, Multiple Machines  Multiple Server Processes, Single File System You can increase parallel throughput with multiple server processes. This option is efficient only when you run one server process per disc, because running multiple server processes per disc will cause access delays which counteract any throughput advantage.\nBelow is a sample configuration for multiple server processes with a single file system.\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 128\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 10000\nServerJobBMITimeoutSecs 120\nServerJobFlowTimeoutSecs 120\nClientJobBMITimeoutSecs 120\nClientJobFlowTimeoutSecs 120\nClientRetryLimit 5\nClientRetryDelayMilliSecs 5000\nPrecreateBatchSize 0,1024,1024,1024,32,1024,0\nPrecreateLowThreshold 0,256,256,256,16,256,0\nTroveMaxConcurrentIO 16\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias ofs001 tcp://ofs001:3334\nAlias ofs002 tcp://ofs001:3335\nAlias ofs003 tcp://ofs001:3336\nAlias ofs004 tcp://ofs001:3337\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer ofs001\nDataStorageSpace /ofs001/3334/data\nMetadataStorageSpace /ofs001/3334/meta\nLogFile /var/log/orangefs-server-3334.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer ofs002\nDataStorageSpace /ofs001/3335/data\nMetadataStorageSpace /ofs001/3335/meta\nLogFile /var/log/orangefs-server-3335.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer ofs003\nDataStorageSpace /ofs001/3336/data\nMetadataStorageSpace /ofs001/3336/meta\nLogFile /var/log/orangefs-server-3336.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer ofs004\nDataStorageSpace /ofs001/3337/data\nMetadataStorageSpace /ofs001/3337/meta\nLogFile /var/log/orangefs-server-3337.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs\nID 696608094\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\nTreeThreshold 16\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\nDBCacheSizeBytes 2147483648\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;Distribution\u0026gt;\nName simple_stripe\nParam strip_size\nValue 262144\n\u0026lt;/Distribution\u0026gt;\n\u0026lt;MetaHandleRanges\u0026gt;\nRange ofs001 3-144115188075855875\nRange ofs002 144115188075855876-288230376151711748\nRange ofs003 288230376151711749-432345564227567621\nRange ofs004 432345564227567622-576460752303423494\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange ofs001 2305843009213693971-2449958197289549843\nRange ofs002 2449958197289549844-2594073385365405716\nRange ofs003 2594073385365405717-2738188573441261589\nRange ofs004 2738188573441261590-2882303761517117462\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\nMultiple Servers, Single File System, Some Data-only Servers Below is an example configuration file for a situation in which seven servers are combined meta and data servers, and the remaining nine servers are data servers only. The \u0026lt;MetaHandleRanges\u0026gt; and \u0026lt;DataHandleRanges\u0026gt; sections in the code below determine which servers serve in which capacity.\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 50\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 1000\nServerJobBMITimeoutSecs 30\nServerJobFlowTimeoutSecs 30\nClientJobBMITimeoutSecs 300\nClientJobFlowTimeoutSecs 300\nClientRetryLimit 5\nClientRetryDelayMilliSecs 2000\nPrecreateBatchSize 0,1024,1024,1024,32,1024,0\nPrecreateLowThreshold 0,256,256,256,16,256,0\nDataStorageSpace /opt/orangefs/storage/data\nMetadataStorageSpace /opt/orangefs/storage/meta\nLogFile /opt/orangefs/orangefs-server.log\n\u0026lt;Security\u0026gt;\nTurnOffTimeouts yes\n\u0026lt;/Security\u0026gt;\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias server01 tcp://ofs001:3334\nAlias server02 tcp://ofs002:3334\nAlias server03 tcp://ofs003:3334\nAlias server04 tcp://ofs004:3334\nAlias server05 tcp://ofs005:3334\nAlias server06 tcp://ofs006:3334\nAlias server07 tcp://ofs007:3334\nAlias server08 tcp://ofs008:3334\nAlias server09 tcp://ofs009:3334\nAlias server10 tcp://ofs010:3334\nAlias server11 tcp://ofs011:3334\nAlias server12 tcp://ofs012:3334\nAlias server13 tcp://ofs013:3334\nAlias server14 tcp://ofs014:3334\nAlias server15 tcp://ofs015:3334\nAlias server16 tcp://ofs016:3334\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs\nID 991638827\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange server01 3-288230376151711745\nRange server02 288230376151711746-576460752303423488\nRange server03 576460752303423489-864691128455135231\nRange server04 864691128455135232-1152921504606846974\nRange server05 1152921504606846975-1441151880758558717\nRange server06 1441151880758558718-1729382256910270460\nRange server07 1729382256910270461-2017612633061982203\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange server01 4611686018427387891-4899916394579099633\nRange server02 4899916394579099634-5188146770730811376\nRange server03 5188146770730811377-5476377146882523119\nRange server04 5476377146882523120-5764607523034234862\nRange server05 5764607523034234863-6052837899185946605\nRange server06 6052837899185946606-6341068275337658348\nRange server07 6341068275337658349-6629298651489370091\nRange server08 6629298651489370092-6917529027641081834\nRange server09 6917529027641081835-7205759403792793577\nRange server10 7205759403792793578-7493989779944505320\nRange server11 7493989779944505321-7782220156096217063\nRange server12 7782220156096217064-8070450532247928806\nRange server13 8070450532247928807-8358680908399640549\nRange server14 8358680908399640550-8646911284551352292\nRange server15 8646911284551352293-8935141660703064035\nRange server16 8935141660703064036-9223372036854775778\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;\nMultiple Server Processes, Single File System, Multiple Machines Below is an example configuration file for a situation with four server processes per machine with four machines serving a single file system.\n\u0026lt;Defaults\u0026gt;\nUnexpectedRequests 50\nEventLogging none\nEnableTracing no\nLogStamp datetime\nBMIModules bmi_tcp\nFlowModules flowproto_multiqueue\nPerfUpdateInterval 1000\nServerJobBMITimeoutSecs 30\nServerJobFlowTimeoutSecs 30\nClientJobBMITimeoutSecs 300\nClientJobFlowTimeoutSecs 300\nClientRetryLimit 5\nClientRetryDelayMilliSecs 2000\nPrecreateBatchSize 0,1024,1024,1024,32,1024,0\nPrecreateLowThreshold 0,256,256,256,16,256,0\n\u0026lt;Security\u0026gt;\nTurnOffTimeouts yes\n\u0026lt;/Security\u0026gt;\n\u0026lt;/Defaults\u0026gt;\n\u0026lt;Aliases\u0026gt;\nAlias server01 tcp://ofs001:3334\nAlias server02 tcp://ofs001:3335\nAlias server03 tcp://ofs001:3336\nAlias server04 tcp://ofs001:3337\nAlias server05 tcp://ofs002:3334\nAlias server06 tcp://ofs002:3335\nAlias server07 tcp://ofs002:3336\nAlias server08 tcp://ofs002:3337\nAlias server09 tcp://ofs003:3334\nAlias server10 tcp://ofs003:3335\nAlias server11 tcp://ofs003:3336\nAlias server12 tcp://ofs003:3337\nAlias server13 tcp://ofs004:3334\nAlias server14 tcp://ofs004:3335\nAlias server15 tcp://ofs004:3336\nAlias server16 tcp://ofs004:3337\n\u0026lt;/Aliases\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server01 DataStorageSpace /opt/orangefs/storage/server01/data\nMetadataStorageSpace /opt/orangefs/storage/server01/meta\nLogFile /opt/orangefs/orangefs-server01.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server02 DataStorageSpace /opt/orangefs/storage/server02/data\nMetadataStorageSpace /opt/orangefs/storage/server02/meta\nLogFile /opt/orangefs/orangefs-server02.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server03 DataStorageSpace /opt/orangefs/storage/server03/data\nMetadataStorageSpace /opt/orangefs/storage/server03/meta\nLogFile /opt/orangefs/orangefs-server03.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server04 DataStorageSpace /opt/orangefs/storage/server04/data\nMetadataStorageSpace /opt/orangefs/storage/server04/meta\nLogFile /opt/orangefs/orangefs-server04.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server05 DataStorageSpace /opt/orangefs/storage/server05/data\nMetadataStorageSpace /opt/orangefs/storage/server05/meta\nLogFile /opt/orangefs/orangefs-server05.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server06 DataStorageSpace /opt/orangefs/storage/server06/data\nMetadataStorageSpace /opt/orangefs/storage/server06/meta\nLogFile /opt/orangefs/orangefs-server06.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server07 DataStorageSpace /opt/orangefs/storage/server07/data\nMetadataStorageSpace /opt/orangefs/storage/server07/meta\nLogFile /opt/orangefs/orangefs-server07.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server08 DataStorageSpace /opt/orangefs/storage/server08/data\nMetadataStorageSpace /opt/orangefs/storage/server08/meta\nLogFile /opt/orangefs/orangefs-server08.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server09 DataStorageSpace /opt/orangefs/storage/server09/data\nMetadataStorageSpace /opt/orangefs/storage/server09/meta\nLogFile /opt/orangefs/orangefs-server09.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server10 DataStorageSpace /opt/orangefs/storage/server10/data\nMetadataStorageSpace /opt/orangefs/storage/server10/meta\nLogFile /opt/orangefs/orangefs-server10.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server11 DataStorageSpace /opt/orangefs/storage/server11/data\nMetadataStorageSpace /opt/orangefs/storage/server11/meta\nLogFile /opt/orangefs/orangefs-server11.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server12 DataStorageSpace /opt/orangefs/storage/server12/data\nMetadataStorageSpace /opt/orangefs/storage/server12/meta\nLogFile /opt/orangefs/orangefs-server12.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server13 DataStorageSpace /opt/orangefs/storage/server13/data\nMetadataStorageSpace /opt/orangefs/storage/server13/meta\nLogFile /opt/orangefs/orangefs-server13.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server14 DataStorageSpace /opt/orangefs/storage/server14/data\nMetadataStorageSpace /opt/orangefs/storage/server14/meta\nLogFile /opt/orangefs/orangefs-server14.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server15 DataStorageSpace /opt/orangefs/storage/server15/data\nMetadataStorageSpace /opt/orangefs/storage/server15/meta\nLogFile /opt/orangefs/orangefs-server15.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;ServerOptions\u0026gt;\nServer server16 DataStorageSpace /opt/orangefs/storage/server16/data\nMetadataStorageSpace /opt/orangefs/storage/server16/meta\nLogFile /opt/orangefs/orangefs-server16.log\n\u0026lt;/ServerOptions\u0026gt;\n\u0026lt;Filesystem\u0026gt;\nName orangefs\nID 991638827\nRootHandle 1048576\nFileStuffing yes\nDistrDirServersInitial 1\nDistrDirServersMax 1\nDistrDirSplitSize 100\n\u0026lt;MetaHandleRanges\u0026gt;\nRange server01 3-288230376151711745\nRange server02 288230376151711746-576460752303423488\nRange server03 576460752303423489-864691128455135231\nRange server04 864691128455135232-1152921504606846974\nRange server05 1152921504606846975-1441151880758558717\nRange server06 1441151880758558718-1729382256910270460\nRange server07 1729382256910270461-2017612633061982203\nRange server08 2017612633061982204-2305843009213693946\nRange server09 2305843009213693947-2594073385365405689\nRange server10 2594073385365405690-2882303761517117432\nRange server11 2882303761517117433-3170534137668829175\nRange server12 3170534137668829176-3458764513820540918\nRange server13 3458764513820540919-3746994889972252661\nRange server14 3746994889972252662-4035225266123964404\nRange server15 4035225266123964405-4323455642275676147\nRange server16 4323455642275676148-4611686018427387890\n\u0026lt;/MetaHandleRanges\u0026gt;\n\u0026lt;DataHandleRanges\u0026gt;\nRange server01 4611686018427387891-4899916394579099633\nRange server02 4899916394579099634-5188146770730811376\nRange server03 5188146770730811377-5476377146882523119\nRange server04 5476377146882523120-5764607523034234862\nRange server05 5764607523034234863-6052837899185946605\nRange server06 6052837899185946606-6341068275337658348\nRange server07 6341068275337658349-6629298651489370091\nRange server08 6629298651489370092-6917529027641081834\nRange server09 6917529027641081835-7205759403792793577\nRange server10 7205759403792793578-7493989779944505320\nRange server11 7493989779944505321-7782220156096217063\nRange server12 7782220156096217064-8070450532247928806\nRange server13 8070450532247928807-8358680908399640549\nRange server14 8358680908399640550-8646911284551352292\nRange server15 8646911284551352293-8935141660703064035\nRange server16 8935141660703064036-9223372036854775778\n\u0026lt;/DataHandleRanges\u0026gt;\n\u0026lt;StorageHints\u0026gt;\nTroveSyncMeta yes\nTroveSyncData no\nTroveMethod alt-aio\n\u0026lt;/StorageHints\u0026gt;\n\u0026lt;/Filesystem\u0026gt;           "
},
{
	"uri": "/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "       "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/",
	"title": "OrangeFS Overview",
	"tags": [],
	"description": "",
	"content": " OrangeFS OrangeFS, a scale-out network file system designed for use on high-end computing (HEC) systems that provides very high-performance access to multi-server-based disk storage, in parallel. The OrangeFS server and client are user-level code, making them very easy to install and manage. OrangeFS has optimized MPI-IO support for parallel and distributed applications, and it is leveraged in production installations and used as a research platform for distributed and parallel storage.\nOrangeFS is now part of the Linux kernel as of version 4.6. As this version of the kernel becomes widely available, it will simplify the use of parallel storage by Linux applications through OrangeFS.\n"
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]