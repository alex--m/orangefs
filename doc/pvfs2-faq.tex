\documentclass[11pt,letterpaper]{article}
\usepackage{html}
\usepackage{charter}
\pagestyle{empty}

%
% GET THE MARGINS RIGHT, THE UGLY WAY
%
\topmargin 0.0in
\textwidth 6.5in
\textheight 9.0in
\columnsep 0.25in
\oddsidemargin 0.0in
\evensidemargin 0.0in
\headsep 0.0in
\headheight 0.0in


\title{Frequently Asked Questions about PVFS2}
\author{ PVFS2 Development Team }
% \date{Last Updated: March 2004}

%
% BEGINNING OF DOCUMENT
%
\begin{document}
\maketitle

\tableofcontents

\thispagestyle{empty}

%
% BASICS
%
\section{Basics}

This section covers some basic questions about what PVFS2 is and where it can
be used.

\subsection{What is PVFS2?}

PVFS2 is an open-source, scalable parallel file system targeted at production
parallel computation environments.  It is designed specifically to scale to
very large numbers of clients and servers.  The architecture is very modular,
allowing for easy inclusion of new hardware support and new algorithms.  This
makes PVFS2 a perfect research testbed as well.

\subsection{What architectures does PVFS2 support?}
\label{sec:supported-architectures}

The majority of PVFS2 is POSIX-compliant C code that runs in user space.  As
such, much of PVFS2 could run on most available systems.

However, the part of PVFS2 that hooks to the operating system on clients must
be written specifically for the particular operating system.  This piece of
PVFS2 has only been written for the Linux kernel, version 2.6.xx.

We encourage porting of this component of PVFS2 to other operating systems.
At this time we have no plans for porting this component to operating systems
other than Linux.

\subsection{Does PVFS2 work across heterogeneous architectures?}

Yes.  The ``language'' that PVFS2 uses to talk between clients and servers is
encoded in a architecture-independent format (little-endian with fixed byte
length parameters).  This allows different PVFS2 components to interact
seamlessly regardless of architecture.

\subsection{Does PVFS2 require any particular hardware?}

Other than hardware supported by the Linux OS, no.  PVFS2 uses existing
network infrastructure for communication and can currently operate over TCP,
Myrinet, and InfiniBand.  Disk local to servers is used for PVFS2 storage, so
no storage area network (SAN) is required either.

\subsection{What are the components of PVFS2 that I should know about?}

The PVFS2 Guide (\url{http://www.pvfs.org/pvfs2/pvfs2-guide.html}) has more
information on all of these components, plus a discussion of the system as a
whole, the code tree, and more.

%
% INSTALLATION
%
\section{Installation}

This section covers issues related to installing and configuring PVFS2.

\subsection{How do I install PVFS2?}

The PVFS2 Quick Start Guide
(\url{http://www.pvfs.org/pvfs2/pvfs2-quickstart.html}) provides an overview
of both a simple, single-server installation, and a more complicated,
multi-server configuration.

\subsection{How can I store PVFS2 data on multiple disks on a single node?}
\label{sec:multiple-disks}

There are at least two ways to do this.

In general the best solution to this problem is going to be to get the disks
logically organized into a single unit by some other OS component, then build
a file system on that single logical unit for use by the PVFS2 server on that
node.

There are a wide array of hardware RAID controllers that are capable of
performing this task.
%
The Multiple Devices (MD) driver is a software component of Linux that can be
used to combine multiple disk drives into a single logical unit, complete with
RAID for fault tolerance.
%
Using the Logical Volume Management (LVM) component of the Linux OS is another
option for this (see the HOWTO at
\url{http://www.tldp.org/HOWTO/LVM-HOWTO.html}).  LVM would also allow you to
add or remove drives at a later time, which can be quite convenient.  You
can of course combine the MD and LVM components in interesting ways as well,
but that's outside the scope of this FAQ.
%
There's an EVMS program that can be used for managing local storage; this
might be useful for setting up complicated configurations of local storage
prior to starting up PVFS2 servers.

A second solution would be to use more than one server on the same node, each
using a different file system to store its data.

\subsection{How can I run multiple PVFS2 servers on the same node?}

Running more than one PVFS2 server on the same node is as simple as setting up
servers on different nodes.  Each will need its own entry in the list of
Aliases and its own server-specific configuration file, as described in the
Quick Start (\url{http://www.pvfs.org/pvfs2/pvfs2-quickstart.html}).

\subsection{Can I use multiple metadata servers in PVFS2?}

Absolutely!  Any PVFS2 server can store either metadata, data, or both.
Simply allocate unique MetaHandleRanges for each server that you would like to
store metadata; the clients will handle the rest.

%
% REPORTING PROBLEMS
%
\section{Reporting Problems}

This section outlines some steps that will help the developers figure out what
has happened when you have a problem.

\subsection{Where can I find documentation?}

The best place to look for documentation on PVFS2 is the PVFS2 web site at
\url{http://www.pvfs.org/pvfs2}.  Documentation (including this FAQ) is also
available in the \texttt{doc} subdirectory of the PVFS2 source distribution.

\subsection{What should I do if I have a problem?}

The first thing to do is to check out the existing documentation and see if it
addresses your problem.  We are constantly updating documentation to clarify
sections that users have found confusing and to add to this document answers
to questions that we have seen.

The next thing to do is to check out the PVFS2 mailing list archives at
\url{http://www.pvfs.org/pvfs2/lists.html}.  It is likely that you are not
the first person to see a particular problem, so searching this list will
often result in an immediate answer.

If you still haven't found an answer, the next thing to do is to mail the
mailing list and report your problem.

\subsection{How do I report a problem with PVFS2?}

First you will need to join the PVFS2 Users Mailing list at
\url{http://www.beowulf-underground.org/mailman/listinfo/pvfs2-users}.  You
must be a user to post to the list; this is necessary to keep down the amount
of spam on the list.

Next you should gather up some information regarding your system:
\begin{itemize}
\item Version of PVFS2
\item Version of MPI and MPI-IO (if you're using them)
\item Version of Linux kernel (if you're using the VFS interface)
\item Hardware architecture, including CPU, network, storage
\item Any logs that might be useful to the developers
\end{itemize}
Including this information in your first message will help the developers most
quickly help you.  You are almost guaranteed that if you do not include this
information in your first message, you will be asked to provide it in the
first reply, slowing down the process.

You should be aware that you are also likely to be asked to try the newest
stable version if you are not running that version.  We understand that this
is not always possible, but if it is, please do.

\emph{Note:} Please do not send your message to both the PVFS2 Users List and
the PVFS2 Developers List; the lists serve different purposes.  Also, please
do not send your message directly to particular developers.  By keeping
discussion of problems on the mailing lists we ensure that the discussion is
archived and that everyone has a chance to respond.

%
% PERFORMANCE
%
\section{Performance}

This section covers issues related to the performance of PVFS2.

\subsection{I ran Bonnie and the performance is terrible. Why? Is there
            anything I can do?}

\subsection{Why is program XXX so slow?}

%
% REDUNDANCY
%
\section{Fault Tolerance}

This section covers issues related to fault tolerance in the context of PVFS2.

\subsection{Does PVFS2 support some form of fault tolerance?}

Systems can be set up to handle many types of failures for PVFS2.  Currently
the only failure mode that cannot be handled well is server failure.

\subsection{Can PVFS2 tolerate client failures?}

Yes.  One of the benefits of the PVFS2 design is that client failures are not a
significant event in the system.  Because there is no locking system in PVFS2,
and no shared state stored on clients in general, a client failure does not
affect either the servers or other clients.

\subsection{Can PVFS2 tolerate disk failures?}

Yes, if configured to do so.  Multiple disks on each server may be used to
form redundant storage for that server, allowing servers to continue operating
in the event of a disk failure.  See section \ref{sec:multiple-disks} for more
information on this approach.

\subsection{Can PVFS2 tolerate network failures?}

Yes, if your network has redundant links.  Because PVFS2 uses standard
networks, the same approaches for providing multiple network connections to a
server may be used with PVFS2.  \emph{Need a reference of some sort.}

\subsection{Can PVFS2 tolerate server failures?}

At this time we do not have a solution for this problem.  We are currently
experimenting with clustering of servers for failover, but we do not have a
cookbook recipe for setting this up.  We will update this are more information
becomes available.

%
% INTERFACES
%
\section{Interfaces}

This section covers issues related to accessing PVFS2 file systems.

\subsection{How do I get MPI-IO for PVFS2?}

The ROMIO MPI-IO implementation, as provided with MPICH2 and others, supports
PVFS2.

\emph{Add pointer to notes on installing?}

\subsection{Can I directly manipulate PVFS2 files on the PVFS2 servers
            without going through some client interface?}

You can, yes, but you probably should not.  The PVFS2 developers are not
likely to help you out if you do this and something gets messed up...

%
% MANAGEMENT
%
\section{Management}

This section covers questions about managing PVFS2 file systems.

\subsection{How can I back up my PVFS2 file system?}

The default storage implementation for PVFS2 (called Trove DBPF for ``DB Plus
Files'') stores all file system data held by a single server in a single
subdirectory.  In that subdirectory is a directory tree containing UNIX files
with file data and metadata.
%
This entire directory tree can be backed up in any manner you like and
restored if problems occur.

As a side note, this was not possible in PVFS1, and is one of the many
improvements present in the new system.

\subsection{Can I add, remove, or change the order of the PVFS2 servers
            on an existing PVFS2 file system?}

You can add and change the order of PVFS2 servers for an existing PVFS2 file
system.  At this time, you must stop all the servers in order to do so.

To add a new server:
\begin{enumerate}
\item Unmount all clients
\item Stop all servers
\item Edit your config file to:
  \begin{enumerate}
  \item Add a new Alias for the new server
  \item Add a new DataHandleRange for the new server (picking a range you
        didn't previously use)
  \end{enumerate}
\item Deploy the new config file to all the servers, including the new one
\item Create the storage space on the new server
\item Start all servers
\item Remount clients
\end{enumerate}

To reorder the servers (causing round-robin to occur in a different relative
order):
\begin{enumerate}
\item Unmount all clients
\item Stop all servers
\item Edit your config file to reorder the DataHandleRange entries
\item Deploy the new config file to all the servers
\item Start all servers
\item Remount clients
\end{enumerate}

Note that adding a new server will \emph{not} cause existing datafiles to be
placed on the new server, although new ones will be (by default).  Migration
tools are necessary to move existing datafiles (see
Section~\ref{sec:migration}) both in the case of a new server, or if you
wanted to migrate data off a server before removing it.

\subsection{Are there tools for migrating data between servers?}
\label{sec:migration}

Not at this time, no.

\subsection{Why does df show less free space than I think it should? What
            can I do about that?}

PVFS2 uses a particular algorithm for calculating the free space on a file
system that takes the minimum amount of space free on a single server and
multiplies this value by the number of servers storing file data.
%
This algorithm was chosen because it provides a lower-bound on the amount of
data that could be stored on the system at that point in time.

If this value seems low, it is likely that one of your servers has less space
than the others (either physical space, or because someone has put some other
data on the same local file system on which PVFS2 data is stored).  The
\texttt{pvfs2-statfs} utility, included with PVFS2, can be used to check the
amount of free space on each server, as can the \texttt{karma} GUI.

\subsection{Does PVFS2 have a maximum file system size? If so, what is it?}

PVFS2 uses a 64-bit value for describing the offsets into files, so
theoretically file sizes are virtually unlimited.  However, in practice other
system constraints place upper bounds on the size of files and file systems.

To best calculate maximum file and file system sizes, you should determine the
maximum file and file system sizes for the local file system type that you are
using for PVFS2 server storage and multiply these values by the number of
servers you are using.

%
% MISSING FEATURES
%
\section{Missing Features}

This section discusses features that are not present in PVFS2 that are present
in some other file systems.

\subsection{Why don't hardlinks work under PVFS2?}

We didn't implement hardlinks, and there is no plan to do so.  Symlinks are
implemented.

\subsection{Can I \texttt{mmap} a PVFS2 file?}

Private, read-only mmapping of files is supported.  Shared mmapping of files
is not.  Supporting this would force a great deal of additional infrastructure
into PVFS2 that would compromise the design goals of simplicity and
robustness.  This ``feature'' was intentionally left out, and it will remain
so.

\subsection{Will PVFS2 store new files on servers with more space, allowing
            files to be stored when one server runs out of space?}

No.  Currently PVFS2 does not intelligently place new files based on free
space.  It's a good idea, and possible, but we have not done this yet.  See
Section~\ref{sec:contributing} for notes on how you could help get this
feature in place.

%
% HELPING OUT
%
\section{Helping Out}

This section covers ways one could contibute to the PVFS2 project.

\subsection{How can I contribute to the PVFS2 project?}
\label{sec:contributing}

There are lots of ways to directly or indirectly contribute to the PVFS2
project.  Reporting bugs helps us make the system better, and describing your
use of the PVFS2 system helps us better understand where and how PVFS2 is
being deployed.

Even better, patches that fix bugs, add features, or support new hardware are
very welcome!  The PVFS community has historically been a friendly one, and we
encourage users to discuss issues and exchange ideas on the mailing lists.

If you're interested in this type of exchange, we suggest joining the PVFS2
Developers List, grabbing the newest CVS version of the code, and seeing what
is new in PVFS2.  See \url{http://www.pvfs.org/pvfs2/developers.html} for more
details.

%
% IMPLEMENTATION DETAILS
%
\section{Implementation Details}

This section answers questions regarding specific components of the
implementation.  It is most useful for people interested in augmenting or
modifying PVFS2.

\subsection{BMI}

This section specifically covers questions about the BMI interface and
implementations.

\subsubsection{What is the maximum packet size for BMI?}

Each BMI module is allowed to define its own maximum message size.  See
\texttt{BMI\_tcp\_get\_info}, \texttt{BMI\_gm\_get\_info}, and
\texttt{BMI\_ib\_get\_info} for examples of the maximum sizes that each of the
existing modules support.  The maximum should be reported when you issue a
\texttt{get\_info} call with the option set to \texttt{BMI\_CHECK\_MAXSIZE}.
Higher level components of PVFS2 perform these checks in order to make sure
that they don't choose buffer sizes that are too large for the underlying
network.

\subsubsection{What happens if I try to match a BMI send with a BMI receive
               that has too small a buffer?}

If the receive buffer is too small for the incoming message, then the
communication will fail and an error will be reported if possible.  We
don't support any semantics for receiving partial messages or anything like
that.  Its ok if the receive buffer is too big, though.
    
\end{document}
