%
% flow design
%

\documentclass[12pt]{article} % FORMAT CHANGE
\usepackage[dvips]{graphicx}
\usepackage{times}

\graphicspath{{./}{figs/}} 

%
% GET THE MARGINS RIGHT, THE UGLY WAY
%
% \topmargin 0.2in
% \textwidth 6.5in
% \textheight 8.75in
% \columnsep 0.25in
% \oddsidemargin 0.0in
% \evensidemargin 0.0in
% \headsep 0.0in
% \headheight 0.0in

\pagestyle{plain}

\addtolength{\hoffset}{-2cm}
\addtolength{\textwidth}{4cm}

\addtolength{\voffset}{-1.5cm}
\addtolength{\textheight}{3cm}

\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

\title{PVFS2 Handle and Bucket Design Document}
\author{PVFS Development Team}
\date{August 2002}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Introduction and terminology}

\emph{Handles} are opaque identifiers that are used to identify objects stored
on PVFS2 servers.  Objects include data files, meta files, directories,
and symlinks.  File systems are made up of a logical collection of these
objects.

Almost all file system operations consist of manipulating these objects
in some manner.  For example, changing the permissions of a PVFS2
file requires modifying a meta data object.  Reading from a PVFS2 file
requires reading data from a set of data files.  This means that several
file system components (such as the server, system interface, and
trove storage interface) must be aware of handles to some extent in
order to carry out these operations on objects.

Every handle must be unique so that there is no ambiguity when
manipulating file system objects.  We must therefore take care to insure
that there are no collisions when objects and their associated handles
are created.  This is a non trivial problem since PVFS2 objects are
distributed across multiple servers, with no central repository of
handle information.

To overcome this problem, we must introduce a few more advanced handle 
concepts.  First of all, we will use the term \emph{handle space} to
refer to the set of values which handles may assume.  Some values
in the handle space are reserved to have special meaning.  For example,
the 0 or NULL handle value is reserved to represent an uninitialized
handle.

In order to insure that there are no handle collisions when multiple
servers are creating objects, we must partition the handle space so 
that each PVFS2 server can control its own range within the space.
We can therefore guarantee that if a server assigns a value from that range,
it will not collide with handles from any other server.

The term \emph{bucket} is used to describe a range of the handle space
that has been assigned to a particular PVFS2 server.  The handle space
will be evenly divided into a set of N buckets.  The number of buckets
in the handle space \emph{does not} have to correspond to the number of
servers in the file system.  Some buckets may be unused (reserved for
future servers to be added to the system), or some servers may control
multiple buckets at once.

The file system will manage a mapping of buckets to servers.  This mapping
will be static for a running file system, but may be modified while it
is offline.  It provides a means by which an arbitrary handle
can be mapped back to the server which is responsible for it.  The mapping
concept will be covered in more detail in section \ref{sec:client}.

\subsection{Implementation details}

Handles will be implemented using 64 bit unsigned integer types.
Buckets can then be thought of as divisions of that 64 bit space.  For
example, the most significant 16 bits may represent the bucket, and the
least significant 48 bits may indicate the handle value within that
bucket.  This division will be configurable, however.

Handle values are generated by the trove storage interface.  However,
trove must be informed of which part of the handle space has already
been reserved to specify the bucket.  In order to do this, we will use
a \emph{handle mask}.  The mask is a value which indicates how many bits
of the handle space have been reserved to represent the bucket
information.  

The bucket will be specified using the most significant bits of the
handle.  The ``zero'' bucket will always be set aside to use for
special reserved values in the handle space.

\subsubsection{8 bit handle example}
\label{sec:example}

Suppose that the handle space is only 8 bits wide for a simplified
example.  Now assume that 4 bits of this space specifies the
bucket (ie, the handle mask = 4).

The ``zero'' bucket will be set aside for reserved values.  That leaves
15 possible buckets.

Bucket 1 includes handles in the range 00010000 to 00011111 if written
in binary format.  Note that the bucket number (1 in this case) is
shifted to the 4 most significant bits.  The 4 least significant bits
are then varied to present a total of 16 possible handle values within
the bucket.  Similarly, bucket 2 includes the range 00100000 to 00101111
and bucket 3 includes the range 00110000 to 00111111.

Note that our choice to place the bucket bits in the most significant
position results in handles being numbered linearly within any given bucket.

Also note that a ``real'' handle space should be much larger to support
the number of objects which may exist in the system.  PVFS2
will use a 64 bit handle space.

\section{Trove point of view}

Trove is the low level interface that stores and accesses PVFS2 objects
on each server.  The objects are stored as dataspaces in trove (for more
details, see the storageint and trove-dbpf documents).  These dataspaces
are referenced by way of the handles described in this document.

Trove is \emph{not} aware of the concept of buckets.  Buckets are an
abstraction that exists above the trove interface.

When a new dataspace is created in trove, it is assigned a new handle
that has not been used yet in that storage instance.  However, trove
allows for a portion of the handle to have already been filled in ahead
of time, and for the size of that portion to be specified with a bitmask
as defined in the preceeding text.

\subsection{Trove handle creation example}

We will use the same assumptions as in section \ref{sec:example}, with
an 8 bit handle space.

Suppose that we wish to create a new object in trove, and that we want
the handle to come from bucket 5.  In binary format, 5 is represented as
101.  If we place this into the 4 most significant bits of an 8 bit
number the result is 01010000.

Therefore, when we call trove\_dspace\_create(), we will pass in a handle
value of 01010000 (or 80 in decimal notation) and a handle mask of 4.
If the creation succeeds, then the resulting handle will be filled in
with its final (full) value.  For example, the resulting handle may be
01010011.  Note that the 4 most significant bits did not change, but
that the 4 least significant bits were filled in by trove.  This handle
now uniquely identifies the new data space within trove.

\section{Server point of view}

The PVFS2 server handles two important tasks related to handle management.
First of all, it acts as the intermediate between the client
and the trove interfaces.  Secondly, it stores the table of mappings
between buckets and servers.

The former task is simple in terms of handle management.  When a client
requests that a new file system object be created, the client will provide the
initial handle value (with bucket bits filled in) and the handle mask.
The server must simply pass this information along to trove (without
modification) when it requests that the trove object be created.
Likewise, when a client wishes to manipulate an object, it will specify
the handle to manipulate in the request without any server intervention.

The table of mappings between buckets and servers will be kept in a
configuration file on each server.  This configuration information must
be sent to clients in text format when requested with a ``getconfig''
server request (see reqproto design document for details).

This configuration information must include the handle mask (which will
be global for any given file system), a list of servers for the file
system, and the range of buckets assigned to each server.

For example, if we used the sample 8 bit handle space assumptions given
in section \ref{sec:example}, the config file information may look like
this:

\begin{verbatim}
HandleMask 4
<BucketTable>
Server "tcp://host1:3334" 1-2
Server "tcp://host2:3334" 3-5
Server "tcp://host3:3334" 6
</BucketTable>
\end{verbatim}

In this case there are three servers.  The first server controls buckets
1 and 2; the second controls buckets 3, 4, and 5; the third controls
bucket 6.  The name of each server is given in BMI URL format, which is
covered in the BMI design document.

This information may reside in the server's primary configuration file,
or in a seperate configuration file.  It also may use different keywords
or delimiters; this is not the final config file format.

\section{Client point of view}
\label{sec:client}

The primary underlying client library is known as the system interface
(see the sysint design document for details).  The system interface
carries out file system operations by issuing one or more server requests
(over the network) and interpreting their responses.  It will need to be
able to map existing handles back to the servers that control them in
order to know where to issue requests to.  It will also need to choose
servers to place new objects on when creating file system entities.

We will provide the above functionality using an API known as the
\emph{bucket table interface}, or BTI.  This API will be visible only to
the system interface, and will be tailored specifically to its needs.

\subsection{Bucket tables}

The bucket table interface is a set of functions used
(internally) by the system interface to query and manipulate the
tables of mappings between handles and PVFS2 servers.  It keeps up
with seperate mappings for the meta servers and I/O servers, but
both are to be accessed from this same interface.

\begin{itemize}
\item \textbf{bt\_initialize()}:
This initializes the bucket table interface.
\item \textbf{bt\_load\_mapping(char* meta\_mapping, int meta\_count,
char* io\_mapping, int io\_count, PVFS\_handle handle\_mask, PVFS\_fs\_id fsid)}: Loads a table
of meta and I/O server mappings into the bucket table interface.
It's arguments are taken from information provided in response to the
GETCONFIG server request.  There is a mapping for meta servers and a
mapping for I/O servers given in string format.  The interface
will parse these text format mappings and create some internal data structure that it can
quickly search through when needed.  Note that multiple sets of tables
may be loaded into the same bucket table interface instance.  They are
differentiated by the fsid argument and represent multiple file systems
which are mounted at once.
\item \textbf{bt\_finalize()}: tears down whatever was done by
bt\_initialize and frees any loaded tables.
\item \textbf{bt\_get\_next\_meta\_bucket(PVFS\_fs\_id fsid, char*
meta\_name, PVFS\_handle *bucket, PVFS\_handle *handle\_mask)}:  This is used by the system interface to pick a
bucket and associated meta server to use when creating a new high level
object (file, directory, symlink).  The bt\_XXX interface may internally
keep a static variable that tracks which meta server was used last so
that
all meta servers are used fairly in a round robin fashion.  meta\_name,
bucket, and handle\_mask are output arguments that tell the caller the name of the server
(in BMI's url style string format) as well as the bucket and mask to use
when requesting that the object be created on that server.  
\item \textbf{bt\_get\_next\_io\_bucket\_array(PVFS\_fs\_id fsid,
int num\_servers, char** io\_name\_array, PVFS\_handle *bucket\_array,
PVFS\_handle* handle\_mask)}:
This is analogous to the bt\_get\_next\_meta\_bucket()
function, except that it provides a list of I/O servers and
buckets rather than providing a single meta server.  It will be
called when the system interface wants to create a set of datafiles and
needs to know where to put them.  The caller must specify how many I/O
servers it wants to use.  The function will try to fairly distribute
among I/O servers on successive calls, and in doing so will pick
different starting I/O servers for each set (analagous to the
"random base"
option in pvfs1).
\item \textbf{bt\_map\_bucket\_to\_server(char* server\_name,
PVFS\_handle bucket PVFS\_fs\_id fsid)}:
given a bucket and an fsid, this function returns the name of the server
that is responsible for it.  Useful for informing the system interface
who it should send a request to when it wants to manipulate a particular
object for which it only has the handle.
\item \textbf{bt\_map\_server\_to\_bucket\_array(char* server\_name,
PVFS\_handle *bucket\_array, PVFS\_handle *handle\_mask)}: given a particular server name, this function will
return a list of the buckets that map to that server.
Will probably only be useful for diagnostics, debugging, etc.
\item \textbf{bt\_get\_num\_meta(PVFS\_fs\_id fsid)}: queries to
find out the number of meta buckets available
\item \textbf{bt\_get\_num\_io(PVFS\_fs\_id fsid)}:
queries to find the number of io buckets available
\end{itemize}

Note that buckets use the same underlying type as handles.  At the trove
level, buckets are simply handles that have already been partially filled in.

Also note that the bucket table interface must perform the conversion of
bucket numberings (starting with decimal number 1) to the partially
filled handle format.  Using the 8 bit handle space example from section
\ref{sec:example}, bucket 1 becomes 00010000 in binary format or 16 in
decimal format.  bucket 2 becomes 00100000 or 32, etc.

\end{document}


